{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "solution.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04d48892"
      },
      "source": [
        "## Importy"
      ],
      "id": "04d48892"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d53e2b2d"
      },
      "source": [
        "import torch, torchvision\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.functional as F\n",
        "import torch.utils.data as data\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib\n",
        "import random\n",
        "import seaborn as sns"
      ],
      "id": "d53e2b2d",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42dde052"
      },
      "source": [
        "## Ustawienia"
      ],
      "id": "42dde052"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac1f40b6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "464307cf-add4-4e9e-e795-f66065664dec"
      },
      "source": [
        "random.seed(42)\n",
        "pd.set_option('display.max_columns', None)   # wyświetlanie wszystkich kolumn\n",
        "\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "device"
      ],
      "id": "ac1f40b6",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54414fe1"
      },
      "source": [
        "## Analiza dostarczonych danych"
      ],
      "id": "54414fe1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7063f517"
      },
      "source": [
        "Jak wyglądają dane?"
      ],
      "id": "7063f517"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "0ea6fec6",
        "outputId": "5a3b9c3e-5ad2-488a-fd83-0bff0b5744c8"
      },
      "source": [
        "raw_data = pd.read_csv('train_data.csv')\n",
        "raw_data.head()"
      ],
      "id": "0ea6fec6",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SalePrice</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>MonthSold</th>\n",
              "      <th>Size(sqf)</th>\n",
              "      <th>Floor</th>\n",
              "      <th>HallwayType</th>\n",
              "      <th>HeatingType</th>\n",
              "      <th>AptManageType</th>\n",
              "      <th>N_Parkinglot(Ground)</th>\n",
              "      <th>N_Parkinglot(Basement)</th>\n",
              "      <th>TimeToBusStop</th>\n",
              "      <th>TimeToSubway</th>\n",
              "      <th>N_APT</th>\n",
              "      <th>N_manager</th>\n",
              "      <th>N_elevators</th>\n",
              "      <th>SubwayStation</th>\n",
              "      <th>N_FacilitiesNearBy(PublicOffice)</th>\n",
              "      <th>N_FacilitiesNearBy(Hospital)</th>\n",
              "      <th>N_FacilitiesNearBy(Dpartmentstore)</th>\n",
              "      <th>N_FacilitiesNearBy(Mall)</th>\n",
              "      <th>N_FacilitiesNearBy(ETC)</th>\n",
              "      <th>N_FacilitiesNearBy(Park)</th>\n",
              "      <th>N_SchoolNearBy(Elementary)</th>\n",
              "      <th>N_SchoolNearBy(Middle)</th>\n",
              "      <th>N_SchoolNearBy(High)</th>\n",
              "      <th>N_SchoolNearBy(University)</th>\n",
              "      <th>N_FacilitiesInApt</th>\n",
              "      <th>N_FacilitiesNearBy(Total)</th>\n",
              "      <th>N_SchoolNearBy(Total)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>51327</td>\n",
              "      <td>1985</td>\n",
              "      <td>2007</td>\n",
              "      <td>8</td>\n",
              "      <td>587</td>\n",
              "      <td>8</td>\n",
              "      <td>corridor</td>\n",
              "      <td>individual_heating</td>\n",
              "      <td>self_management</td>\n",
              "      <td>80.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0~5min</td>\n",
              "      <td>5min~10min</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Daegu</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>48672</td>\n",
              "      <td>1985</td>\n",
              "      <td>2007</td>\n",
              "      <td>8</td>\n",
              "      <td>587</td>\n",
              "      <td>6</td>\n",
              "      <td>corridor</td>\n",
              "      <td>individual_heating</td>\n",
              "      <td>self_management</td>\n",
              "      <td>80.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0~5min</td>\n",
              "      <td>5min~10min</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Daegu</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>380530</td>\n",
              "      <td>2006</td>\n",
              "      <td>2007</td>\n",
              "      <td>8</td>\n",
              "      <td>2056</td>\n",
              "      <td>8</td>\n",
              "      <td>terraced</td>\n",
              "      <td>individual_heating</td>\n",
              "      <td>management_in_trust</td>\n",
              "      <td>249.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>0~5min</td>\n",
              "      <td>0-5min</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>Sin-nam</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>221238</td>\n",
              "      <td>1993</td>\n",
              "      <td>2007</td>\n",
              "      <td>8</td>\n",
              "      <td>1761</td>\n",
              "      <td>3</td>\n",
              "      <td>mixed</td>\n",
              "      <td>individual_heating</td>\n",
              "      <td>management_in_trust</td>\n",
              "      <td>523.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>0~5min</td>\n",
              "      <td>15min~20min</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>Myung-duk</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4</td>\n",
              "      <td>14.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>35840</td>\n",
              "      <td>1992</td>\n",
              "      <td>2007</td>\n",
              "      <td>8</td>\n",
              "      <td>355</td>\n",
              "      <td>5</td>\n",
              "      <td>corridor</td>\n",
              "      <td>individual_heating</td>\n",
              "      <td>management_in_trust</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5min~10min</td>\n",
              "      <td>10min~15min</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Myung-duk</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "      <td>16.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   SalePrice  YearBuilt  YrSold  MonthSold  Size(sqf)  Floor HallwayType  \\\n",
              "0      51327       1985    2007          8        587      8    corridor   \n",
              "1      48672       1985    2007          8        587      6    corridor   \n",
              "2     380530       2006    2007          8       2056      8    terraced   \n",
              "3     221238       1993    2007          8       1761      3       mixed   \n",
              "4      35840       1992    2007          8        355      5    corridor   \n",
              "\n",
              "          HeatingType        AptManageType  N_Parkinglot(Ground)  \\\n",
              "0  individual_heating      self_management                  80.0   \n",
              "1  individual_heating      self_management                  80.0   \n",
              "2  individual_heating  management_in_trust                 249.0   \n",
              "3  individual_heating  management_in_trust                 523.0   \n",
              "4  individual_heating  management_in_trust                 200.0   \n",
              "\n",
              "   N_Parkinglot(Basement) TimeToBusStop TimeToSubway  N_APT  N_manager  \\\n",
              "0                    76.0        0~5min   5min~10min    1.0        2.0   \n",
              "1                    76.0        0~5min   5min~10min    1.0        2.0   \n",
              "2                   536.0        0~5min       0-5min    6.0        5.0   \n",
              "3                   536.0        0~5min  15min~20min    8.0        8.0   \n",
              "4                     0.0    5min~10min  10min~15min    3.0        5.0   \n",
              "\n",
              "   N_elevators SubwayStation  N_FacilitiesNearBy(PublicOffice)  \\\n",
              "0          2.0         Daegu                               5.0   \n",
              "1          2.0         Daegu                               5.0   \n",
              "2         11.0       Sin-nam                               1.0   \n",
              "3         20.0     Myung-duk                               6.0   \n",
              "4         10.0     Myung-duk                               7.0   \n",
              "\n",
              "   N_FacilitiesNearBy(Hospital)  N_FacilitiesNearBy(Dpartmentstore)  \\\n",
              "0                             1                                 2.0   \n",
              "1                             1                                 2.0   \n",
              "2                             1                                 0.0   \n",
              "3                             2                                 0.0   \n",
              "4                             1                                 1.0   \n",
              "\n",
              "   N_FacilitiesNearBy(Mall)  N_FacilitiesNearBy(ETC)  \\\n",
              "0                       1.0                      2.0   \n",
              "1                       1.0                      2.0   \n",
              "2                       1.0                      0.0   \n",
              "3                       1.0                      5.0   \n",
              "4                       1.0                      5.0   \n",
              "\n",
              "   N_FacilitiesNearBy(Park)  N_SchoolNearBy(Elementary)  \\\n",
              "0                       1.0                         2.0   \n",
              "1                       1.0                         2.0   \n",
              "2                       0.0                         2.0   \n",
              "3                       0.0                         4.0   \n",
              "4                       1.0                         4.0   \n",
              "\n",
              "   N_SchoolNearBy(Middle)  N_SchoolNearBy(High)  N_SchoolNearBy(University)  \\\n",
              "0                     1.0                   1.0                         0.0   \n",
              "1                     1.0                   1.0                         0.0   \n",
              "2                     2.0                   1.0                         2.0   \n",
              "3                     3.0                   5.0                         5.0   \n",
              "4                     3.0                   5.0                         5.0   \n",
              "\n",
              "   N_FacilitiesInApt  N_FacilitiesNearBy(Total)  N_SchoolNearBy(Total)  \n",
              "0                  3                       12.0                    4.0  \n",
              "1                  3                       12.0                    4.0  \n",
              "2                  5                        3.0                    7.0  \n",
              "3                  4                       14.0                   17.0  \n",
              "4                  3                       16.0                   17.0  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "erJKRCZxASFO",
        "outputId": "bc93534f-f494-47df-99d2-d6d57332c6b1"
      },
      "source": [
        "raw_data.describe()"
      ],
      "id": "erJKRCZxASFO",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SalePrice</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>MonthSold</th>\n",
              "      <th>Size(sqf)</th>\n",
              "      <th>Floor</th>\n",
              "      <th>N_Parkinglot(Ground)</th>\n",
              "      <th>N_Parkinglot(Basement)</th>\n",
              "      <th>N_APT</th>\n",
              "      <th>N_manager</th>\n",
              "      <th>N_elevators</th>\n",
              "      <th>N_FacilitiesNearBy(PublicOffice)</th>\n",
              "      <th>N_FacilitiesNearBy(Hospital)</th>\n",
              "      <th>N_FacilitiesNearBy(Dpartmentstore)</th>\n",
              "      <th>N_FacilitiesNearBy(Mall)</th>\n",
              "      <th>N_FacilitiesNearBy(ETC)</th>\n",
              "      <th>N_FacilitiesNearBy(Park)</th>\n",
              "      <th>N_SchoolNearBy(Elementary)</th>\n",
              "      <th>N_SchoolNearBy(Middle)</th>\n",
              "      <th>N_SchoolNearBy(High)</th>\n",
              "      <th>N_SchoolNearBy(University)</th>\n",
              "      <th>N_FacilitiesInApt</th>\n",
              "      <th>N_FacilitiesNearBy(Total)</th>\n",
              "      <th>N_SchoolNearBy(Total)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "      <td>4124.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>221564.653249</td>\n",
              "      <td>2002.907129</td>\n",
              "      <td>2012.684772</td>\n",
              "      <td>6.201261</td>\n",
              "      <td>960.484239</td>\n",
              "      <td>11.994908</td>\n",
              "      <td>195.616392</td>\n",
              "      <td>572.357905</td>\n",
              "      <td>5.607177</td>\n",
              "      <td>6.333172</td>\n",
              "      <td>11.151552</td>\n",
              "      <td>4.141125</td>\n",
              "      <td>1.298982</td>\n",
              "      <td>0.912464</td>\n",
              "      <td>0.947381</td>\n",
              "      <td>1.932590</td>\n",
              "      <td>0.658341</td>\n",
              "      <td>3.018914</td>\n",
              "      <td>2.425800</td>\n",
              "      <td>2.663191</td>\n",
              "      <td>2.753637</td>\n",
              "      <td>5.801164</td>\n",
              "      <td>9.890883</td>\n",
              "      <td>10.861542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>106676.053778</td>\n",
              "      <td>8.825764</td>\n",
              "      <td>2.917335</td>\n",
              "      <td>3.398540</td>\n",
              "      <td>386.804458</td>\n",
              "      <td>7.548805</td>\n",
              "      <td>218.919683</td>\n",
              "      <td>409.246602</td>\n",
              "      <td>2.818877</td>\n",
              "      <td>3.193502</td>\n",
              "      <td>7.810642</td>\n",
              "      <td>1.775126</td>\n",
              "      <td>0.478587</td>\n",
              "      <td>0.814821</td>\n",
              "      <td>0.396927</td>\n",
              "      <td>2.199886</td>\n",
              "      <td>0.661033</td>\n",
              "      <td>0.940444</td>\n",
              "      <td>1.032846</td>\n",
              "      <td>1.547938</td>\n",
              "      <td>1.491970</td>\n",
              "      <td>2.340055</td>\n",
              "      <td>3.403815</td>\n",
              "      <td>4.417403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>34070.000000</td>\n",
              "      <td>1978.000000</td>\n",
              "      <td>2007.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>135.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>144247.000000</td>\n",
              "      <td>1993.000000</td>\n",
              "      <td>2010.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>644.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>184.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>207964.000000</td>\n",
              "      <td>2006.000000</td>\n",
              "      <td>2013.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>910.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>536.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>289380.000000</td>\n",
              "      <td>2007.000000</td>\n",
              "      <td>2015.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>1160.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>249.000000</td>\n",
              "      <td>798.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>15.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>585840.000000</td>\n",
              "      <td>2015.000000</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>2337.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>713.000000</td>\n",
              "      <td>1321.000000</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>17.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           SalePrice    YearBuilt       YrSold    MonthSold    Size(sqf)  \\\n",
              "count    4124.000000  4124.000000  4124.000000  4124.000000  4124.000000   \n",
              "mean   221564.653249  2002.907129  2012.684772     6.201261   960.484239   \n",
              "std    106676.053778     8.825764     2.917335     3.398540   386.804458   \n",
              "min     34070.000000  1978.000000  2007.000000     1.000000   135.000000   \n",
              "25%    144247.000000  1993.000000  2010.000000     3.000000   644.000000   \n",
              "50%    207964.000000  2006.000000  2013.000000     6.000000   910.000000   \n",
              "75%    289380.000000  2007.000000  2015.000000     9.000000  1160.000000   \n",
              "max    585840.000000  2015.000000  2017.000000    12.000000  2337.000000   \n",
              "\n",
              "             Floor  N_Parkinglot(Ground)  N_Parkinglot(Basement)        N_APT  \\\n",
              "count  4124.000000           4124.000000             4124.000000  4124.000000   \n",
              "mean     11.994908            195.616392              572.357905     5.607177   \n",
              "std       7.548805            218.919683              409.246602     2.818877   \n",
              "min       1.000000              0.000000                0.000000     1.000000   \n",
              "25%       6.000000             11.000000              184.000000     3.000000   \n",
              "50%      11.000000            100.000000              536.000000     7.000000   \n",
              "75%      17.000000            249.000000              798.000000     8.000000   \n",
              "max      43.000000            713.000000             1321.000000    13.000000   \n",
              "\n",
              "         N_manager  N_elevators  N_FacilitiesNearBy(PublicOffice)  \\\n",
              "count  4124.000000  4124.000000                       4124.000000   \n",
              "mean      6.333172    11.151552                          4.141125   \n",
              "std       3.193502     7.810642                          1.775126   \n",
              "min       1.000000     0.000000                          0.000000   \n",
              "25%       5.000000     5.000000                          3.000000   \n",
              "50%       6.000000    11.000000                          5.000000   \n",
              "75%       8.000000    16.000000                          5.000000   \n",
              "max      14.000000    27.000000                          7.000000   \n",
              "\n",
              "       N_FacilitiesNearBy(Hospital)  N_FacilitiesNearBy(Dpartmentstore)  \\\n",
              "count                   4124.000000                         4124.000000   \n",
              "mean                       1.298982                            0.912464   \n",
              "std                        0.478587                            0.814821   \n",
              "min                        0.000000                            0.000000   \n",
              "25%                        1.000000                            0.000000   \n",
              "50%                        1.000000                            1.000000   \n",
              "75%                        2.000000                            2.000000   \n",
              "max                        2.000000                            2.000000   \n",
              "\n",
              "       N_FacilitiesNearBy(Mall)  N_FacilitiesNearBy(ETC)  \\\n",
              "count               4124.000000              4124.000000   \n",
              "mean                   0.947381                 1.932590   \n",
              "std                    0.396927                 2.199886   \n",
              "min                    0.000000                 0.000000   \n",
              "25%                    1.000000                 0.000000   \n",
              "50%                    1.000000                 1.000000   \n",
              "75%                    1.000000                 5.000000   \n",
              "max                    2.000000                 5.000000   \n",
              "\n",
              "       N_FacilitiesNearBy(Park)  N_SchoolNearBy(Elementary)  \\\n",
              "count               4124.000000                 4124.000000   \n",
              "mean                   0.658341                    3.018914   \n",
              "std                    0.661033                    0.940444   \n",
              "min                    0.000000                    0.000000   \n",
              "25%                    0.000000                    2.000000   \n",
              "50%                    1.000000                    3.000000   \n",
              "75%                    1.000000                    4.000000   \n",
              "max                    2.000000                    6.000000   \n",
              "\n",
              "       N_SchoolNearBy(Middle)  N_SchoolNearBy(High)  \\\n",
              "count             4124.000000           4124.000000   \n",
              "mean                 2.425800              2.663191   \n",
              "std                  1.032846              1.547938   \n",
              "min                  0.000000              0.000000   \n",
              "25%                  2.000000              1.000000   \n",
              "50%                  3.000000              2.000000   \n",
              "75%                  3.000000              4.000000   \n",
              "max                  4.000000              5.000000   \n",
              "\n",
              "       N_SchoolNearBy(University)  N_FacilitiesInApt  \\\n",
              "count                 4124.000000        4124.000000   \n",
              "mean                     2.753637           5.801164   \n",
              "std                      1.491970           2.340055   \n",
              "min                      0.000000           1.000000   \n",
              "25%                      2.000000           4.000000   \n",
              "50%                      2.000000           5.000000   \n",
              "75%                      4.000000           7.000000   \n",
              "max                      5.000000          10.000000   \n",
              "\n",
              "       N_FacilitiesNearBy(Total)  N_SchoolNearBy(Total)  \n",
              "count                4124.000000            4124.000000  \n",
              "mean                    9.890883              10.861542  \n",
              "std                     3.403815               4.417403  \n",
              "min                     0.000000               0.000000  \n",
              "25%                     8.000000               7.000000  \n",
              "50%                     9.000000              10.000000  \n",
              "75%                    13.000000              15.000000  \n",
              "max                    16.000000              17.000000  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmHth_1bAZy1",
        "outputId": "ea2c2d06-e19c-419e-bc0d-6c2da9d263d7"
      },
      "source": [
        "raw_data.info()"
      ],
      "id": "mmHth_1bAZy1",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4124 entries, 0 to 4123\n",
            "Data columns (total 30 columns):\n",
            " #   Column                              Non-Null Count  Dtype  \n",
            "---  ------                              --------------  -----  \n",
            " 0   SalePrice                           4124 non-null   int64  \n",
            " 1   YearBuilt                           4124 non-null   int64  \n",
            " 2   YrSold                              4124 non-null   int64  \n",
            " 3   MonthSold                           4124 non-null   int64  \n",
            " 4   Size(sqf)                           4124 non-null   int64  \n",
            " 5   Floor                               4124 non-null   int64  \n",
            " 6   HallwayType                         4124 non-null   object \n",
            " 7   HeatingType                         4124 non-null   object \n",
            " 8   AptManageType                       4124 non-null   object \n",
            " 9   N_Parkinglot(Ground)                4124 non-null   float64\n",
            " 10  N_Parkinglot(Basement)              4124 non-null   float64\n",
            " 11  TimeToBusStop                       4124 non-null   object \n",
            " 12  TimeToSubway                        4124 non-null   object \n",
            " 13  N_APT                               4124 non-null   float64\n",
            " 14  N_manager                           4124 non-null   float64\n",
            " 15  N_elevators                         4124 non-null   float64\n",
            " 16  SubwayStation                       4124 non-null   object \n",
            " 17  N_FacilitiesNearBy(PublicOffice)    4124 non-null   float64\n",
            " 18  N_FacilitiesNearBy(Hospital)        4124 non-null   int64  \n",
            " 19  N_FacilitiesNearBy(Dpartmentstore)  4124 non-null   float64\n",
            " 20  N_FacilitiesNearBy(Mall)            4124 non-null   float64\n",
            " 21  N_FacilitiesNearBy(ETC)             4124 non-null   float64\n",
            " 22  N_FacilitiesNearBy(Park)            4124 non-null   float64\n",
            " 23  N_SchoolNearBy(Elementary)          4124 non-null   float64\n",
            " 24  N_SchoolNearBy(Middle)              4124 non-null   float64\n",
            " 25  N_SchoolNearBy(High)                4124 non-null   float64\n",
            " 26  N_SchoolNearBy(University)          4124 non-null   float64\n",
            " 27  N_FacilitiesInApt                   4124 non-null   int64  \n",
            " 28  N_FacilitiesNearBy(Total)           4124 non-null   float64\n",
            " 29  N_SchoolNearBy(Total)               4124 non-null   float64\n",
            "dtypes: float64(16), int64(8), object(6)\n",
            "memory usage: 966.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwrP19LeKgD0"
      },
      "source": [
        "Zamiana danych:"
      ],
      "id": "DwrP19LeKgD0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ef692e50",
        "outputId": "6bf83d48-bd14-4bce-ec78-73d4222d2794"
      },
      "source": [
        "categories = ['HallwayType', 'HeatingType', 'AptManageType', 'TimeToBusStop', 'TimeToSubway', 'SubwayStation']\n",
        "for cat in categories:\n",
        "    print(raw_data[cat].astype('category').cat.categories)"
      ],
      "id": "ef692e50",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['corridor', 'mixed', 'terraced'], dtype='object')\n",
            "Index(['central_heating', 'individual_heating'], dtype='object')\n",
            "Index(['management_in_trust', 'self_management'], dtype='object')\n",
            "Index(['0~5min', '10min~15min', '5min~10min'], dtype='object')\n",
            "Index(['0-5min', '10min~15min', '15min~20min', '5min~10min',\n",
            "       'no_bus_stop_nearby'],\n",
            "      dtype='object')\n",
            "Index(['Bangoge', 'Banwoldang', 'Chil-sung-market', 'Daegu',\n",
            "       'Kyungbuk_uni_hospital', 'Myung-duk', 'Sin-nam', 'no_subway_nearby'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87cff21d"
      },
      "source": [
        "targ = raw_data['SalePrice']\n",
        "raw_data = raw_data.drop(['SalePrice'], axis=1)"
      ],
      "id": "87cff21d",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e34204b5"
      },
      "source": [
        "ht = raw_data[\"HallwayType\"].astype(\"category\")\n",
        "ht = pd.get_dummies(ht)"
      ],
      "id": "e34204b5",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6da4dab7"
      },
      "source": [
        "substation = raw_data[\"SubwayStation\"].astype(\"category\")\n",
        "substation = pd.get_dummies(substation)"
      ],
      "id": "6da4dab7",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a7dde8c"
      },
      "source": [
        "raw_data['HeatingType'] = raw_data['HeatingType'].replace(['central_heating', 'individual_heating'], [0, 1])"
      ],
      "id": "5a7dde8c",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bebee00"
      },
      "source": [
        "raw_data['AptManageType'] = raw_data['AptManageType'].replace(['management_in_trust', 'self_management'], [0, 1])"
      ],
      "id": "9bebee00",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9030ef1"
      },
      "source": [
        "raw_data['TimeToBusStop'] = raw_data['TimeToBusStop'].replace(['0~5min', '10min~15min', '5min~10min'], [0, 2, 1])"
      ],
      "id": "a9030ef1",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08d38952"
      },
      "source": [
        "raw_data['TimeToSubway'] = raw_data['TimeToSubway'].replace(['0-5min', '10min~15min', '15min~20min', '5min~10min',\n",
        "       'no_bus_stop_nearby'], [1, 3, 4, 2, 0])"
      ],
      "id": "08d38952",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "a629fb5c"
      },
      "source": [
        "raw_data = raw_data.drop(['HallwayType', 'SubwayStation'], axis=1)"
      ],
      "id": "a629fb5c",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vD2a4vFVBY9v"
      },
      "source": [
        "normalizacja danych:"
      ],
      "id": "vD2a4vFVBY9v"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fI96undnBfWo"
      },
      "source": [
        "means, maxs, mins = dict(), dict(), dict()\n",
        "mean_targ, max_targ, min_targ = targ.mean(), targ.max(), targ.min()\n",
        "\n",
        "for col in raw_data:\n",
        "    means[col] = raw_data[col].mean()\n",
        "    maxs[col] = raw_data[col].max()\n",
        "    mins[col] = raw_data[col].min()"
      ],
      "id": "fI96undnBfWo",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "LNmW3_LaIAn5",
        "outputId": "98efb2ef-4d44-4489-e0e0-8052060e9580"
      },
      "source": [
        "raw_data.head()"
      ],
      "id": "LNmW3_LaIAn5",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>MonthSold</th>\n",
              "      <th>Size(sqf)</th>\n",
              "      <th>Floor</th>\n",
              "      <th>HeatingType</th>\n",
              "      <th>AptManageType</th>\n",
              "      <th>N_Parkinglot(Ground)</th>\n",
              "      <th>N_Parkinglot(Basement)</th>\n",
              "      <th>TimeToBusStop</th>\n",
              "      <th>TimeToSubway</th>\n",
              "      <th>N_APT</th>\n",
              "      <th>N_manager</th>\n",
              "      <th>N_elevators</th>\n",
              "      <th>N_FacilitiesNearBy(PublicOffice)</th>\n",
              "      <th>N_FacilitiesNearBy(Hospital)</th>\n",
              "      <th>N_FacilitiesNearBy(Dpartmentstore)</th>\n",
              "      <th>N_FacilitiesNearBy(Mall)</th>\n",
              "      <th>N_FacilitiesNearBy(ETC)</th>\n",
              "      <th>N_FacilitiesNearBy(Park)</th>\n",
              "      <th>N_SchoolNearBy(Elementary)</th>\n",
              "      <th>N_SchoolNearBy(Middle)</th>\n",
              "      <th>N_SchoolNearBy(High)</th>\n",
              "      <th>N_SchoolNearBy(University)</th>\n",
              "      <th>N_FacilitiesInApt</th>\n",
              "      <th>N_FacilitiesNearBy(Total)</th>\n",
              "      <th>N_SchoolNearBy(Total)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1985</td>\n",
              "      <td>2007</td>\n",
              "      <td>8</td>\n",
              "      <td>587</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>80.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1985</td>\n",
              "      <td>2007</td>\n",
              "      <td>8</td>\n",
              "      <td>587</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>80.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3</td>\n",
              "      <td>12.0</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2006</td>\n",
              "      <td>2007</td>\n",
              "      <td>8</td>\n",
              "      <td>2056</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>249.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1993</td>\n",
              "      <td>2007</td>\n",
              "      <td>8</td>\n",
              "      <td>1761</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>523.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>8.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4</td>\n",
              "      <td>14.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1992</td>\n",
              "      <td>2007</td>\n",
              "      <td>8</td>\n",
              "      <td>355</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3</td>\n",
              "      <td>16.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   YearBuilt  YrSold  MonthSold  Size(sqf)  Floor  HeatingType  AptManageType  \\\n",
              "0       1985    2007          8        587      8            1              1   \n",
              "1       1985    2007          8        587      6            1              1   \n",
              "2       2006    2007          8       2056      8            1              0   \n",
              "3       1993    2007          8       1761      3            1              0   \n",
              "4       1992    2007          8        355      5            1              0   \n",
              "\n",
              "   N_Parkinglot(Ground)  N_Parkinglot(Basement)  TimeToBusStop  TimeToSubway  \\\n",
              "0                  80.0                    76.0              0             2   \n",
              "1                  80.0                    76.0              0             2   \n",
              "2                 249.0                   536.0              0             1   \n",
              "3                 523.0                   536.0              0             4   \n",
              "4                 200.0                     0.0              1             3   \n",
              "\n",
              "   N_APT  N_manager  N_elevators  N_FacilitiesNearBy(PublicOffice)  \\\n",
              "0    1.0        2.0          2.0                               5.0   \n",
              "1    1.0        2.0          2.0                               5.0   \n",
              "2    6.0        5.0         11.0                               1.0   \n",
              "3    8.0        8.0         20.0                               6.0   \n",
              "4    3.0        5.0         10.0                               7.0   \n",
              "\n",
              "   N_FacilitiesNearBy(Hospital)  N_FacilitiesNearBy(Dpartmentstore)  \\\n",
              "0                             1                                 2.0   \n",
              "1                             1                                 2.0   \n",
              "2                             1                                 0.0   \n",
              "3                             2                                 0.0   \n",
              "4                             1                                 1.0   \n",
              "\n",
              "   N_FacilitiesNearBy(Mall)  N_FacilitiesNearBy(ETC)  \\\n",
              "0                       1.0                      2.0   \n",
              "1                       1.0                      2.0   \n",
              "2                       1.0                      0.0   \n",
              "3                       1.0                      5.0   \n",
              "4                       1.0                      5.0   \n",
              "\n",
              "   N_FacilitiesNearBy(Park)  N_SchoolNearBy(Elementary)  \\\n",
              "0                       1.0                         2.0   \n",
              "1                       1.0                         2.0   \n",
              "2                       0.0                         2.0   \n",
              "3                       0.0                         4.0   \n",
              "4                       1.0                         4.0   \n",
              "\n",
              "   N_SchoolNearBy(Middle)  N_SchoolNearBy(High)  N_SchoolNearBy(University)  \\\n",
              "0                     1.0                   1.0                         0.0   \n",
              "1                     1.0                   1.0                         0.0   \n",
              "2                     2.0                   1.0                         2.0   \n",
              "3                     3.0                   5.0                         5.0   \n",
              "4                     3.0                   5.0                         5.0   \n",
              "\n",
              "   N_FacilitiesInApt  N_FacilitiesNearBy(Total)  N_SchoolNearBy(Total)  \n",
              "0                  3                       12.0                    4.0  \n",
              "1                  3                       12.0                    4.0  \n",
              "2                  5                        3.0                    7.0  \n",
              "3                  4                       14.0                   17.0  \n",
              "4                  3                       16.0                   17.0  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hGkKAymIROJ",
        "outputId": "ccdc89fe-0e7b-4bdf-f829-2d1f3c2c3d0e"
      },
      "source": [
        "targ.head()"
      ],
      "id": "9hGkKAymIROJ",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     51327\n",
              "1     48672\n",
              "2    380530\n",
              "3    221238\n",
              "4     35840\n",
              "Name: SalePrice, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "lu52mx13HrFj",
        "outputId": "239b1b0c-cdf6-460f-b64d-af2841003649"
      },
      "source": [
        "for col in raw_data:\n",
        "  raw_data[col] = (raw_data[col] - means[col]) / (maxs[col] - mins[col])\n",
        "raw_data.head()"
      ],
      "id": "lu52mx13HrFj",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>YrSold</th>\n",
              "      <th>MonthSold</th>\n",
              "      <th>Size(sqf)</th>\n",
              "      <th>Floor</th>\n",
              "      <th>HeatingType</th>\n",
              "      <th>AptManageType</th>\n",
              "      <th>N_Parkinglot(Ground)</th>\n",
              "      <th>N_Parkinglot(Basement)</th>\n",
              "      <th>TimeToBusStop</th>\n",
              "      <th>TimeToSubway</th>\n",
              "      <th>N_APT</th>\n",
              "      <th>N_manager</th>\n",
              "      <th>N_elevators</th>\n",
              "      <th>N_FacilitiesNearBy(PublicOffice)</th>\n",
              "      <th>N_FacilitiesNearBy(Hospital)</th>\n",
              "      <th>N_FacilitiesNearBy(Dpartmentstore)</th>\n",
              "      <th>N_FacilitiesNearBy(Mall)</th>\n",
              "      <th>N_FacilitiesNearBy(ETC)</th>\n",
              "      <th>N_FacilitiesNearBy(Park)</th>\n",
              "      <th>N_SchoolNearBy(Elementary)</th>\n",
              "      <th>N_SchoolNearBy(Middle)</th>\n",
              "      <th>N_SchoolNearBy(High)</th>\n",
              "      <th>N_SchoolNearBy(University)</th>\n",
              "      <th>N_FacilitiesInApt</th>\n",
              "      <th>N_FacilitiesNearBy(Total)</th>\n",
              "      <th>N_SchoolNearBy(Total)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.483976</td>\n",
              "      <td>-0.568477</td>\n",
              "      <td>0.163522</td>\n",
              "      <td>-0.169611</td>\n",
              "      <td>-0.095117</td>\n",
              "      <td>0.050921</td>\n",
              "      <td>0.938167</td>\n",
              "      <td>-0.162155</td>\n",
              "      <td>-0.375744</td>\n",
              "      <td>-0.120635</td>\n",
              "      <td>0.021945</td>\n",
              "      <td>-0.383931</td>\n",
              "      <td>-0.333321</td>\n",
              "      <td>-0.338946</td>\n",
              "      <td>0.122696</td>\n",
              "      <td>-0.149491</td>\n",
              "      <td>0.543768</td>\n",
              "      <td>0.026309</td>\n",
              "      <td>0.013482</td>\n",
              "      <td>0.170829</td>\n",
              "      <td>-0.169819</td>\n",
              "      <td>-0.35645</td>\n",
              "      <td>-0.332638</td>\n",
              "      <td>-0.550727</td>\n",
              "      <td>-0.311240</td>\n",
              "      <td>0.13182</td>\n",
              "      <td>-0.403620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.483976</td>\n",
              "      <td>-0.568477</td>\n",
              "      <td>0.163522</td>\n",
              "      <td>-0.169611</td>\n",
              "      <td>-0.142736</td>\n",
              "      <td>0.050921</td>\n",
              "      <td>0.938167</td>\n",
              "      <td>-0.162155</td>\n",
              "      <td>-0.375744</td>\n",
              "      <td>-0.120635</td>\n",
              "      <td>0.021945</td>\n",
              "      <td>-0.383931</td>\n",
              "      <td>-0.333321</td>\n",
              "      <td>-0.338946</td>\n",
              "      <td>0.122696</td>\n",
              "      <td>-0.149491</td>\n",
              "      <td>0.543768</td>\n",
              "      <td>0.026309</td>\n",
              "      <td>0.013482</td>\n",
              "      <td>0.170829</td>\n",
              "      <td>-0.169819</td>\n",
              "      <td>-0.35645</td>\n",
              "      <td>-0.332638</td>\n",
              "      <td>-0.550727</td>\n",
              "      <td>-0.311240</td>\n",
              "      <td>0.13182</td>\n",
              "      <td>-0.403620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.083591</td>\n",
              "      <td>-0.568477</td>\n",
              "      <td>0.163522</td>\n",
              "      <td>0.497509</td>\n",
              "      <td>-0.095117</td>\n",
              "      <td>0.050921</td>\n",
              "      <td>-0.061833</td>\n",
              "      <td>0.074872</td>\n",
              "      <td>-0.027523</td>\n",
              "      <td>-0.120635</td>\n",
              "      <td>-0.228055</td>\n",
              "      <td>0.032735</td>\n",
              "      <td>-0.102552</td>\n",
              "      <td>-0.005613</td>\n",
              "      <td>-0.448732</td>\n",
              "      <td>-0.149491</td>\n",
              "      <td>-0.456232</td>\n",
              "      <td>0.026309</td>\n",
              "      <td>-0.386518</td>\n",
              "      <td>-0.329171</td>\n",
              "      <td>-0.169819</td>\n",
              "      <td>-0.10645</td>\n",
              "      <td>-0.332638</td>\n",
              "      <td>-0.150727</td>\n",
              "      <td>-0.089018</td>\n",
              "      <td>-0.43068</td>\n",
              "      <td>-0.227150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.267760</td>\n",
              "      <td>-0.568477</td>\n",
              "      <td>0.163522</td>\n",
              "      <td>0.363540</td>\n",
              "      <td>-0.214164</td>\n",
              "      <td>0.050921</td>\n",
              "      <td>-0.061833</td>\n",
              "      <td>0.459164</td>\n",
              "      <td>-0.027523</td>\n",
              "      <td>-0.120635</td>\n",
              "      <td>0.521945</td>\n",
              "      <td>0.199402</td>\n",
              "      <td>0.128218</td>\n",
              "      <td>0.327720</td>\n",
              "      <td>0.265554</td>\n",
              "      <td>0.350509</td>\n",
              "      <td>-0.456232</td>\n",
              "      <td>0.026309</td>\n",
              "      <td>0.613482</td>\n",
              "      <td>-0.329171</td>\n",
              "      <td>0.163514</td>\n",
              "      <td>0.14355</td>\n",
              "      <td>0.467362</td>\n",
              "      <td>0.449273</td>\n",
              "      <td>-0.200129</td>\n",
              "      <td>0.25682</td>\n",
              "      <td>0.361086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.294787</td>\n",
              "      <td>-0.568477</td>\n",
              "      <td>0.163522</td>\n",
              "      <td>-0.274970</td>\n",
              "      <td>-0.166545</td>\n",
              "      <td>0.050921</td>\n",
              "      <td>-0.061833</td>\n",
              "      <td>0.006148</td>\n",
              "      <td>-0.433276</td>\n",
              "      <td>0.379365</td>\n",
              "      <td>0.271945</td>\n",
              "      <td>-0.217265</td>\n",
              "      <td>-0.102552</td>\n",
              "      <td>-0.042650</td>\n",
              "      <td>0.408411</td>\n",
              "      <td>-0.149491</td>\n",
              "      <td>0.043768</td>\n",
              "      <td>0.026309</td>\n",
              "      <td>0.613482</td>\n",
              "      <td>0.170829</td>\n",
              "      <td>0.163514</td>\n",
              "      <td>0.14355</td>\n",
              "      <td>0.467362</td>\n",
              "      <td>0.449273</td>\n",
              "      <td>-0.311240</td>\n",
              "      <td>0.38182</td>\n",
              "      <td>0.361086</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   YearBuilt    YrSold  MonthSold  Size(sqf)     Floor  HeatingType  \\\n",
              "0  -0.483976 -0.568477   0.163522  -0.169611 -0.095117     0.050921   \n",
              "1  -0.483976 -0.568477   0.163522  -0.169611 -0.142736     0.050921   \n",
              "2   0.083591 -0.568477   0.163522   0.497509 -0.095117     0.050921   \n",
              "3  -0.267760 -0.568477   0.163522   0.363540 -0.214164     0.050921   \n",
              "4  -0.294787 -0.568477   0.163522  -0.274970 -0.166545     0.050921   \n",
              "\n",
              "   AptManageType  N_Parkinglot(Ground)  N_Parkinglot(Basement)  TimeToBusStop  \\\n",
              "0       0.938167             -0.162155               -0.375744      -0.120635   \n",
              "1       0.938167             -0.162155               -0.375744      -0.120635   \n",
              "2      -0.061833              0.074872               -0.027523      -0.120635   \n",
              "3      -0.061833              0.459164               -0.027523      -0.120635   \n",
              "4      -0.061833              0.006148               -0.433276       0.379365   \n",
              "\n",
              "   TimeToSubway     N_APT  N_manager  N_elevators  \\\n",
              "0      0.021945 -0.383931  -0.333321    -0.338946   \n",
              "1      0.021945 -0.383931  -0.333321    -0.338946   \n",
              "2     -0.228055  0.032735  -0.102552    -0.005613   \n",
              "3      0.521945  0.199402   0.128218     0.327720   \n",
              "4      0.271945 -0.217265  -0.102552    -0.042650   \n",
              "\n",
              "   N_FacilitiesNearBy(PublicOffice)  N_FacilitiesNearBy(Hospital)  \\\n",
              "0                          0.122696                     -0.149491   \n",
              "1                          0.122696                     -0.149491   \n",
              "2                         -0.448732                     -0.149491   \n",
              "3                          0.265554                      0.350509   \n",
              "4                          0.408411                     -0.149491   \n",
              "\n",
              "   N_FacilitiesNearBy(Dpartmentstore)  N_FacilitiesNearBy(Mall)  \\\n",
              "0                            0.543768                  0.026309   \n",
              "1                            0.543768                  0.026309   \n",
              "2                           -0.456232                  0.026309   \n",
              "3                           -0.456232                  0.026309   \n",
              "4                            0.043768                  0.026309   \n",
              "\n",
              "   N_FacilitiesNearBy(ETC)  N_FacilitiesNearBy(Park)  \\\n",
              "0                 0.013482                  0.170829   \n",
              "1                 0.013482                  0.170829   \n",
              "2                -0.386518                 -0.329171   \n",
              "3                 0.613482                 -0.329171   \n",
              "4                 0.613482                  0.170829   \n",
              "\n",
              "   N_SchoolNearBy(Elementary)  N_SchoolNearBy(Middle)  N_SchoolNearBy(High)  \\\n",
              "0                   -0.169819                -0.35645             -0.332638   \n",
              "1                   -0.169819                -0.35645             -0.332638   \n",
              "2                   -0.169819                -0.10645             -0.332638   \n",
              "3                    0.163514                 0.14355              0.467362   \n",
              "4                    0.163514                 0.14355              0.467362   \n",
              "\n",
              "   N_SchoolNearBy(University)  N_FacilitiesInApt  N_FacilitiesNearBy(Total)  \\\n",
              "0                   -0.550727          -0.311240                    0.13182   \n",
              "1                   -0.550727          -0.311240                    0.13182   \n",
              "2                   -0.150727          -0.089018                   -0.43068   \n",
              "3                    0.449273          -0.200129                    0.25682   \n",
              "4                    0.449273          -0.311240                    0.38182   \n",
              "\n",
              "   N_SchoolNearBy(Total)  \n",
              "0              -0.403620  \n",
              "1              -0.403620  \n",
              "2              -0.227150  \n",
              "3               0.361086  \n",
              "4               0.361086  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv-uTsgLIh8N",
        "outputId": "d1e310a9-a066-433e-c7d9-5db06bb57bd4"
      },
      "source": [
        "targ = (targ - mean_targ) / (max_targ - min_targ)\n",
        "targ.head()"
      ],
      "id": "mv-uTsgLIh8N",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0   -0.308530\n",
              "1   -0.313342\n",
              "2    0.288101\n",
              "3   -0.000592\n",
              "4   -0.336598\n",
              "Name: SalePrice, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-vwfMFELUT0"
      },
      "source": [
        "podział danych:"
      ],
      "id": "Q-vwfMFELUT0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8gfnh5KLYnT"
      },
      "source": [
        "train_indicates = np.random.rand(len(raw_data)) > 0.3"
      ],
      "id": "T8gfnh5KLYnT",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY05Bx3sLfOz"
      },
      "source": [
        "numerical_data = torch.from_numpy(raw_data.values[train_indicates]).float()\n",
        "categorical_ht_data = torch.from_numpy(ht.values[train_indicates]).float()\n",
        "categorical_substation_data = torch.from_numpy(substation.values[train_indicates]).float()\n",
        "targets = torch.from_numpy(targ.values[train_indicates]).float()\n",
        "\n",
        "test_numerical_data = torch.from_numpy(raw_data.values[~train_indicates]).float()\n",
        "test_categorical_ht_data = torch.from_numpy(ht.values[~train_indicates]).float()\n",
        "test_categorical_substation_data = torch.from_numpy(substation.values[~train_indicates]).float()\n",
        "test_targets = torch.from_numpy(targ.values[~train_indicates]).float()"
      ],
      "id": "fY05Bx3sLfOz",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76b30972"
      },
      "source": [
        "## Budowanie sieci"
      ],
      "id": "76b30972"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99f987ee"
      },
      "source": [
        "train_dataset = data.TensorDataset(numerical_data, categorical_ht_data, categorical_substation_data, targets)\n",
        "test_dataset = data.TensorDataset(test_numerical_data, test_categorical_ht_data, test_categorical_substation_data, test_targets)"
      ],
      "id": "99f987ee",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqSNaprLsWqU",
        "outputId": "1ca8ae2d-3145-4d8a-c13d-377e5a3b14f0"
      },
      "source": [
        "numerical_data.shape[1] + categorical_ht_data.shape[1] + categorical_substation_data.shape[1]"
      ],
      "id": "JqSNaprLsWqU",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ce39dd2b"
      },
      "source": [
        "class Price_classifier(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Price_classifier, self).__init__()\n",
        "        self.layer1 = nn.Linear(numerical_data.shape[1] + categorical_ht_data.shape[1] + categorical_substation_data.shape[1], 300)\n",
        "        self.bn1 = nn.BatchNorm1d(300)\n",
        "        self.act_1 = nn.Sigmoid()\n",
        "        self.layer2 = nn.Linear(300, 500)\n",
        "        self.bn2 = nn.BatchNorm1d(500)\n",
        "        self.act_2 = nn.Sigmoid()\n",
        "        self.layer5 = nn.Linear(500, 50)\n",
        "        self.bn5 = nn.BatchNorm1d(50)\n",
        "        self.act_5 = nn.ReLU()\n",
        "        self.layer6 = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x, cat_ht_x, cat_substation_x):\n",
        "        x = torch.cat([x, cat_ht_x, cat_substation_x], dim=1)\n",
        "        activation1 = self.act_1(self.bn1(self.layer1(x)))\n",
        "        activation2 = self.act_2(self.bn2(self.layer2(activation1)))\n",
        "        activation5 = self.act_5(self.bn5(self.layer5(activation2)))\n",
        "        output = self.layer6(activation5)\n",
        "        return output"
      ],
      "id": "ce39dd2b",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "371f5bae"
      },
      "source": [
        "threshold = 300000"
      ],
      "id": "371f5bae",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03MchmO7i31U"
      },
      "source": [
        "def evaluate(model, data, targets, scale):\n",
        "  model.eval()\n",
        "  pred = model(data[0].to(device), data[1].to(device), data[2].to(device))\n",
        "  pred = pred*(scale['max_val'] - scale['min_val']) + scale['mean_val'] > threshold\n",
        "  real = targets*(scale['max_val'] - scale['min_val']) + scale['mean_val'] > 300000\n",
        "  return (pred.squeeze().to(device) == real.squeeze().to(device)).sum().item() / real.shape[0]"
      ],
      "id": "03MchmO7i31U",
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9EKPnGX8hGm"
      },
      "source": [
        "scale = {'max_val': max_targ, 'min_val': min_targ, 'mean_val': mean_targ}"
      ],
      "id": "t9EKPnGX8hGm",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b85b43b",
        "outputId": "9970439b-6483-4ae6-cf7f-bb16c3e60a04"
      },
      "source": [
        "model = Price_classifier().to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "iters = []\n",
        "losses = []\n",
        "train_acc = []\n",
        "val_acc = []\n",
        "for n in range(2000):\n",
        "    epoch_losses = []\n",
        "    for x, cat_ht_x, cat_substation_x, y in iter(train_loader):\n",
        "        x, cat_ht_x, cat_substation_x, y = x.to(device), cat_ht_x.to(device), cat_substation_x.to(device), y.to(device)\n",
        "        model.train()\n",
        "        out = model(x, cat_ht_x, cat_substation_x).squeeze()\n",
        "\n",
        "        loss = criterion(out, y)\n",
        "        loss.backward()\n",
        "        epoch_losses.append(loss.item())\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "    loss_mean = np.array(epoch_losses).mean()\n",
        "    train_precision = evaluate(model, [numerical_data, categorical_ht_data, categorical_substation_data], targets, scale)\n",
        "    test_precision = evaluate(model, [test_numerical_data, test_categorical_ht_data, test_categorical_substation_data], test_targets, scale)\n",
        "    iters.append(n)\n",
        "    losses.append(loss_mean)\n",
        "    print(f\"Epoch: {n},\\t loss: {loss_mean:.4},\\t\\t train precision: {train_precision:.4},\\t\\t test precision: {test_precision:.4}\")\n"
      ],
      "id": "5b85b43b",
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0,\t loss: 0.01876,\t\t train precision: 0.9213,\t\t test precision: 0.9259\n",
            "Epoch: 1,\t loss: 0.006371,\t\t train precision: 0.9344,\t\t test precision: 0.9185\n",
            "Epoch: 2,\t loss: 0.005317,\t\t train precision: 0.9326,\t\t test precision: 0.9308\n",
            "Epoch: 3,\t loss: 0.004901,\t\t train precision: 0.91,\t\t test precision: 0.9209\n",
            "Epoch: 4,\t loss: 0.004164,\t\t train precision: 0.9519,\t\t test precision: 0.9572\n",
            "Epoch: 5,\t loss: 0.004091,\t\t train precision: 0.9447,\t\t test precision: 0.9489\n",
            "Epoch: 6,\t loss: 0.004,\t\t train precision: 0.9519,\t\t test precision: 0.9481\n",
            "Epoch: 7,\t loss: 0.003826,\t\t train precision: 0.9505,\t\t test precision: 0.9498\n",
            "Epoch: 8,\t loss: 0.003355,\t\t train precision: 0.9457,\t\t test precision: 0.9506\n",
            "Epoch: 9,\t loss: 0.003262,\t\t train precision: 0.9509,\t\t test precision: 0.9465\n",
            "Epoch: 10,\t loss: 0.00318,\t\t train precision: 0.9584,\t\t test precision: 0.9596\n",
            "Epoch: 11,\t loss: 0.002974,\t\t train precision: 0.9471,\t\t test precision: 0.944\n",
            "Epoch: 12,\t loss: 0.003096,\t\t train precision: 0.9543,\t\t test precision: 0.9448\n",
            "Epoch: 13,\t loss: 0.002838,\t\t train precision: 0.9615,\t\t test precision: 0.958\n",
            "Epoch: 14,\t loss: 0.002809,\t\t train precision: 0.966,\t\t test precision: 0.9654\n",
            "Epoch: 15,\t loss: 0.002928,\t\t train precision: 0.9619,\t\t test precision: 0.9539\n",
            "Epoch: 16,\t loss: 0.002714,\t\t train precision: 0.9584,\t\t test precision: 0.9539\n",
            "Epoch: 17,\t loss: 0.002647,\t\t train precision: 0.9643,\t\t test precision: 0.9572\n",
            "Epoch: 18,\t loss: 0.002369,\t\t train precision: 0.9674,\t\t test precision: 0.9613\n",
            "Epoch: 19,\t loss: 0.002638,\t\t train precision: 0.9677,\t\t test precision: 0.9613\n",
            "Epoch: 20,\t loss: 0.002481,\t\t train precision: 0.9646,\t\t test precision: 0.9596\n",
            "Epoch: 21,\t loss: 0.002559,\t\t train precision: 0.9619,\t\t test precision: 0.9563\n",
            "Epoch: 22,\t loss: 0.002837,\t\t train precision: 0.9694,\t\t test precision: 0.9621\n",
            "Epoch: 23,\t loss: 0.002571,\t\t train precision: 0.9667,\t\t test precision: 0.9547\n",
            "Epoch: 24,\t loss: 0.002522,\t\t train precision: 0.9625,\t\t test precision: 0.944\n",
            "Epoch: 25,\t loss: 0.002341,\t\t train precision: 0.9691,\t\t test precision: 0.9605\n",
            "Epoch: 26,\t loss: 0.002378,\t\t train precision: 0.9612,\t\t test precision: 0.9465\n",
            "Epoch: 27,\t loss: 0.002481,\t\t train precision: 0.9436,\t\t test precision: 0.9481\n",
            "Epoch: 28,\t loss: 0.002428,\t\t train precision: 0.9701,\t\t test precision: 0.9646\n",
            "Epoch: 29,\t loss: 0.002342,\t\t train precision: 0.9646,\t\t test precision: 0.9605\n",
            "Epoch: 30,\t loss: 0.002244,\t\t train precision: 0.9608,\t\t test precision: 0.9572\n",
            "Epoch: 31,\t loss: 0.002351,\t\t train precision: 0.9588,\t\t test precision: 0.9605\n",
            "Epoch: 32,\t loss: 0.002312,\t\t train precision: 0.966,\t\t test precision: 0.9613\n",
            "Epoch: 33,\t loss: 0.00241,\t\t train precision: 0.9715,\t\t test precision: 0.9621\n",
            "Epoch: 34,\t loss: 0.002138,\t\t train precision: 0.9722,\t\t test precision: 0.9605\n",
            "Epoch: 35,\t loss: 0.002107,\t\t train precision: 0.9711,\t\t test precision: 0.9621\n",
            "Epoch: 36,\t loss: 0.002391,\t\t train precision: 0.9725,\t\t test precision: 0.9596\n",
            "Epoch: 37,\t loss: 0.00206,\t\t train precision: 0.9653,\t\t test precision: 0.9621\n",
            "Epoch: 38,\t loss: 0.002102,\t\t train precision: 0.9722,\t\t test precision: 0.9629\n",
            "Epoch: 39,\t loss: 0.002039,\t\t train precision: 0.9687,\t\t test precision: 0.9662\n",
            "Epoch: 40,\t loss: 0.001957,\t\t train precision: 0.9684,\t\t test precision: 0.9547\n",
            "Epoch: 41,\t loss: 0.002153,\t\t train precision: 0.9663,\t\t test precision: 0.9572\n",
            "Epoch: 42,\t loss: 0.002131,\t\t train precision: 0.9622,\t\t test precision: 0.9605\n",
            "Epoch: 43,\t loss: 0.002167,\t\t train precision: 0.9649,\t\t test precision: 0.958\n",
            "Epoch: 44,\t loss: 0.002013,\t\t train precision: 0.966,\t\t test precision: 0.9695\n",
            "Epoch: 45,\t loss: 0.002094,\t\t train precision: 0.9722,\t\t test precision: 0.9679\n",
            "Epoch: 46,\t loss: 0.00199,\t\t train precision: 0.967,\t\t test precision: 0.9621\n",
            "Epoch: 47,\t loss: 0.001993,\t\t train precision: 0.9715,\t\t test precision: 0.9662\n",
            "Epoch: 48,\t loss: 0.00204,\t\t train precision: 0.9674,\t\t test precision: 0.9563\n",
            "Epoch: 49,\t loss: 0.00226,\t\t train precision: 0.9636,\t\t test precision: 0.9638\n",
            "Epoch: 50,\t loss: 0.001903,\t\t train precision: 0.9698,\t\t test precision: 0.9588\n",
            "Epoch: 51,\t loss: 0.001971,\t\t train precision: 0.9715,\t\t test precision: 0.9662\n",
            "Epoch: 52,\t loss: 0.00201,\t\t train precision: 0.9557,\t\t test precision: 0.9432\n",
            "Epoch: 53,\t loss: 0.002187,\t\t train precision: 0.9694,\t\t test precision: 0.9613\n",
            "Epoch: 54,\t loss: 0.002069,\t\t train precision: 0.9704,\t\t test precision: 0.9662\n",
            "Epoch: 55,\t loss: 0.002139,\t\t train precision: 0.9698,\t\t test precision: 0.9605\n",
            "Epoch: 56,\t loss: 0.001881,\t\t train precision: 0.9732,\t\t test precision: 0.9638\n",
            "Epoch: 57,\t loss: 0.001867,\t\t train precision: 0.9729,\t\t test precision: 0.9679\n",
            "Epoch: 58,\t loss: 0.001726,\t\t train precision: 0.9756,\t\t test precision: 0.9712\n",
            "Epoch: 59,\t loss: 0.001949,\t\t train precision: 0.9632,\t\t test precision: 0.9563\n",
            "Epoch: 60,\t loss: 0.001984,\t\t train precision: 0.9674,\t\t test precision: 0.9547\n",
            "Epoch: 61,\t loss: 0.001884,\t\t train precision: 0.9698,\t\t test precision: 0.9687\n",
            "Epoch: 62,\t loss: 0.002141,\t\t train precision: 0.9722,\t\t test precision: 0.9671\n",
            "Epoch: 63,\t loss: 0.001787,\t\t train precision: 0.9704,\t\t test precision: 0.9621\n",
            "Epoch: 64,\t loss: 0.001994,\t\t train precision: 0.9732,\t\t test precision: 0.9654\n",
            "Epoch: 65,\t loss: 0.001811,\t\t train precision: 0.9701,\t\t test precision: 0.9638\n",
            "Epoch: 66,\t loss: 0.001883,\t\t train precision: 0.9601,\t\t test precision: 0.9563\n",
            "Epoch: 67,\t loss: 0.001936,\t\t train precision: 0.9701,\t\t test precision: 0.9605\n",
            "Epoch: 68,\t loss: 0.001827,\t\t train precision: 0.9718,\t\t test precision: 0.9613\n",
            "Epoch: 69,\t loss: 0.001924,\t\t train precision: 0.9715,\t\t test precision: 0.9671\n",
            "Epoch: 70,\t loss: 0.00189,\t\t train precision: 0.968,\t\t test precision: 0.9605\n",
            "Epoch: 71,\t loss: 0.001793,\t\t train precision: 0.9691,\t\t test precision: 0.9572\n",
            "Epoch: 72,\t loss: 0.001901,\t\t train precision: 0.9742,\t\t test precision: 0.972\n",
            "Epoch: 73,\t loss: 0.001771,\t\t train precision: 0.9722,\t\t test precision: 0.9646\n",
            "Epoch: 74,\t loss: 0.001899,\t\t train precision: 0.9708,\t\t test precision: 0.9687\n",
            "Epoch: 75,\t loss: 0.001835,\t\t train precision: 0.9718,\t\t test precision: 0.9638\n",
            "Epoch: 76,\t loss: 0.00184,\t\t train precision: 0.9694,\t\t test precision: 0.9654\n",
            "Epoch: 77,\t loss: 0.001727,\t\t train precision: 0.9694,\t\t test precision: 0.9654\n",
            "Epoch: 78,\t loss: 0.001791,\t\t train precision: 0.9735,\t\t test precision: 0.9679\n",
            "Epoch: 79,\t loss: 0.001962,\t\t train precision: 0.9725,\t\t test precision: 0.9712\n",
            "Epoch: 80,\t loss: 0.001877,\t\t train precision: 0.9698,\t\t test precision: 0.9613\n",
            "Epoch: 81,\t loss: 0.001862,\t\t train precision: 0.9746,\t\t test precision: 0.9703\n",
            "Epoch: 82,\t loss: 0.001725,\t\t train precision: 0.9718,\t\t test precision: 0.9613\n",
            "Epoch: 83,\t loss: 0.001739,\t\t train precision: 0.968,\t\t test precision: 0.9613\n",
            "Epoch: 84,\t loss: 0.001828,\t\t train precision: 0.9708,\t\t test precision: 0.9695\n",
            "Epoch: 85,\t loss: 0.001796,\t\t train precision: 0.968,\t\t test precision: 0.9563\n",
            "Epoch: 86,\t loss: 0.002019,\t\t train precision: 0.9677,\t\t test precision: 0.9671\n",
            "Epoch: 87,\t loss: 0.001755,\t\t train precision: 0.9722,\t\t test precision: 0.9671\n",
            "Epoch: 88,\t loss: 0.001656,\t\t train precision: 0.9601,\t\t test precision: 0.9596\n",
            "Epoch: 89,\t loss: 0.001785,\t\t train precision: 0.9718,\t\t test precision: 0.9629\n",
            "Epoch: 90,\t loss: 0.001708,\t\t train precision: 0.9698,\t\t test precision: 0.9629\n",
            "Epoch: 91,\t loss: 0.001753,\t\t train precision: 0.9687,\t\t test precision: 0.9662\n",
            "Epoch: 92,\t loss: 0.001785,\t\t train precision: 0.968,\t\t test precision: 0.9662\n",
            "Epoch: 93,\t loss: 0.001665,\t\t train precision: 0.968,\t\t test precision: 0.9629\n",
            "Epoch: 94,\t loss: 0.001646,\t\t train precision: 0.9735,\t\t test precision: 0.9703\n",
            "Epoch: 95,\t loss: 0.001895,\t\t train precision: 0.9694,\t\t test precision: 0.9687\n",
            "Epoch: 96,\t loss: 0.001754,\t\t train precision: 0.9612,\t\t test precision: 0.9646\n",
            "Epoch: 97,\t loss: 0.001689,\t\t train precision: 0.968,\t\t test precision: 0.9629\n",
            "Epoch: 98,\t loss: 0.001717,\t\t train precision: 0.9687,\t\t test precision: 0.9662\n",
            "Epoch: 99,\t loss: 0.001627,\t\t train precision: 0.9674,\t\t test precision: 0.9662\n",
            "Epoch: 100,\t loss: 0.001635,\t\t train precision: 0.9732,\t\t test precision: 0.972\n",
            "Epoch: 101,\t loss: 0.001785,\t\t train precision: 0.9735,\t\t test precision: 0.9695\n",
            "Epoch: 102,\t loss: 0.001619,\t\t train precision: 0.9729,\t\t test precision: 0.9671\n",
            "Epoch: 103,\t loss: 0.001724,\t\t train precision: 0.967,\t\t test precision: 0.9646\n",
            "Epoch: 104,\t loss: 0.001829,\t\t train precision: 0.9773,\t\t test precision: 0.9703\n",
            "Epoch: 105,\t loss: 0.001883,\t\t train precision: 0.9711,\t\t test precision: 0.9662\n",
            "Epoch: 106,\t loss: 0.001638,\t\t train precision: 0.9722,\t\t test precision: 0.972\n",
            "Epoch: 107,\t loss: 0.001773,\t\t train precision: 0.9667,\t\t test precision: 0.9572\n",
            "Epoch: 108,\t loss: 0.00169,\t\t train precision: 0.9694,\t\t test precision: 0.9745\n",
            "Epoch: 109,\t loss: 0.001713,\t\t train precision: 0.9625,\t\t test precision: 0.958\n",
            "Epoch: 110,\t loss: 0.001654,\t\t train precision: 0.9732,\t\t test precision: 0.9671\n",
            "Epoch: 111,\t loss: 0.001677,\t\t train precision: 0.9732,\t\t test precision: 0.972\n",
            "Epoch: 112,\t loss: 0.001594,\t\t train precision: 0.9691,\t\t test precision: 0.9621\n",
            "Epoch: 113,\t loss: 0.001596,\t\t train precision: 0.9735,\t\t test precision: 0.9687\n",
            "Epoch: 114,\t loss: 0.001561,\t\t train precision: 0.9704,\t\t test precision: 0.9695\n",
            "Epoch: 115,\t loss: 0.00168,\t\t train precision: 0.9704,\t\t test precision: 0.9695\n",
            "Epoch: 116,\t loss: 0.001537,\t\t train precision: 0.9698,\t\t test precision: 0.9638\n",
            "Epoch: 117,\t loss: 0.001476,\t\t train precision: 0.9722,\t\t test precision: 0.9695\n",
            "Epoch: 118,\t loss: 0.001623,\t\t train precision: 0.9663,\t\t test precision: 0.972\n",
            "Epoch: 119,\t loss: 0.001661,\t\t train precision: 0.9753,\t\t test precision: 0.9712\n",
            "Epoch: 120,\t loss: 0.001557,\t\t train precision: 0.9808,\t\t test precision: 0.9736\n",
            "Epoch: 121,\t loss: 0.001623,\t\t train precision: 0.9653,\t\t test precision: 0.9662\n",
            "Epoch: 122,\t loss: 0.001607,\t\t train precision: 0.9715,\t\t test precision: 0.9703\n",
            "Epoch: 123,\t loss: 0.001773,\t\t train precision: 0.9766,\t\t test precision: 0.9662\n",
            "Epoch: 124,\t loss: 0.001802,\t\t train precision: 0.9749,\t\t test precision: 0.9712\n",
            "Epoch: 125,\t loss: 0.001719,\t\t train precision: 0.9704,\t\t test precision: 0.972\n",
            "Epoch: 126,\t loss: 0.001611,\t\t train precision: 0.9739,\t\t test precision: 0.9662\n",
            "Epoch: 127,\t loss: 0.001706,\t\t train precision: 0.9687,\t\t test precision: 0.9613\n",
            "Epoch: 128,\t loss: 0.001427,\t\t train precision: 0.9729,\t\t test precision: 0.9671\n",
            "Epoch: 129,\t loss: 0.001656,\t\t train precision: 0.9732,\t\t test precision: 0.9728\n",
            "Epoch: 130,\t loss: 0.001589,\t\t train precision: 0.9711,\t\t test precision: 0.9695\n",
            "Epoch: 131,\t loss: 0.001593,\t\t train precision: 0.9694,\t\t test precision: 0.9596\n",
            "Epoch: 132,\t loss: 0.001681,\t\t train precision: 0.9715,\t\t test precision: 0.9687\n",
            "Epoch: 133,\t loss: 0.001482,\t\t train precision: 0.9766,\t\t test precision: 0.9712\n",
            "Epoch: 134,\t loss: 0.001513,\t\t train precision: 0.9756,\t\t test precision: 0.9671\n",
            "Epoch: 135,\t loss: 0.001546,\t\t train precision: 0.9742,\t\t test precision: 0.972\n",
            "Epoch: 136,\t loss: 0.001768,\t\t train precision: 0.9739,\t\t test precision: 0.9695\n",
            "Epoch: 137,\t loss: 0.001592,\t\t train precision: 0.9763,\t\t test precision: 0.972\n",
            "Epoch: 138,\t loss: 0.001434,\t\t train precision: 0.9729,\t\t test precision: 0.9671\n",
            "Epoch: 139,\t loss: 0.001472,\t\t train precision: 0.9742,\t\t test precision: 0.9638\n",
            "Epoch: 140,\t loss: 0.001656,\t\t train precision: 0.9667,\t\t test precision: 0.9662\n",
            "Epoch: 141,\t loss: 0.001613,\t\t train precision: 0.9701,\t\t test precision: 0.9679\n",
            "Epoch: 142,\t loss: 0.001602,\t\t train precision: 0.9711,\t\t test precision: 0.9671\n",
            "Epoch: 143,\t loss: 0.001445,\t\t train precision: 0.9746,\t\t test precision: 0.9695\n",
            "Epoch: 144,\t loss: 0.001483,\t\t train precision: 0.9773,\t\t test precision: 0.9687\n",
            "Epoch: 145,\t loss: 0.001467,\t\t train precision: 0.9763,\t\t test precision: 0.9687\n",
            "Epoch: 146,\t loss: 0.001416,\t\t train precision: 0.9739,\t\t test precision: 0.9687\n",
            "Epoch: 147,\t loss: 0.00151,\t\t train precision: 0.9749,\t\t test precision: 0.9687\n",
            "Epoch: 148,\t loss: 0.001434,\t\t train precision: 0.977,\t\t test precision: 0.9695\n",
            "Epoch: 149,\t loss: 0.001478,\t\t train precision: 0.9725,\t\t test precision: 0.9671\n",
            "Epoch: 150,\t loss: 0.001511,\t\t train precision: 0.9691,\t\t test precision: 0.9629\n",
            "Epoch: 151,\t loss: 0.00148,\t\t train precision: 0.978,\t\t test precision: 0.9695\n",
            "Epoch: 152,\t loss: 0.001386,\t\t train precision: 0.9763,\t\t test precision: 0.9687\n",
            "Epoch: 153,\t loss: 0.001447,\t\t train precision: 0.9794,\t\t test precision: 0.9695\n",
            "Epoch: 154,\t loss: 0.001395,\t\t train precision: 0.9684,\t\t test precision: 0.9687\n",
            "Epoch: 155,\t loss: 0.001463,\t\t train precision: 0.9794,\t\t test precision: 0.9712\n",
            "Epoch: 156,\t loss: 0.001529,\t\t train precision: 0.9773,\t\t test precision: 0.9712\n",
            "Epoch: 157,\t loss: 0.001475,\t\t train precision: 0.9698,\t\t test precision: 0.9687\n",
            "Epoch: 158,\t loss: 0.0016,\t\t train precision: 0.9701,\t\t test precision: 0.9621\n",
            "Epoch: 159,\t loss: 0.001557,\t\t train precision: 0.9759,\t\t test precision: 0.9736\n",
            "Epoch: 160,\t loss: 0.001463,\t\t train precision: 0.9701,\t\t test precision: 0.9605\n",
            "Epoch: 161,\t loss: 0.001535,\t\t train precision: 0.9749,\t\t test precision: 0.9662\n",
            "Epoch: 162,\t loss: 0.001583,\t\t train precision: 0.9735,\t\t test precision: 0.9629\n",
            "Epoch: 163,\t loss: 0.001515,\t\t train precision: 0.9787,\t\t test precision: 0.9687\n",
            "Epoch: 164,\t loss: 0.001542,\t\t train precision: 0.9701,\t\t test precision: 0.9605\n",
            "Epoch: 165,\t loss: 0.00151,\t\t train precision: 0.968,\t\t test precision: 0.9662\n",
            "Epoch: 166,\t loss: 0.001578,\t\t train precision: 0.9742,\t\t test precision: 0.9728\n",
            "Epoch: 167,\t loss: 0.001397,\t\t train precision: 0.9773,\t\t test precision: 0.972\n",
            "Epoch: 168,\t loss: 0.001566,\t\t train precision: 0.9766,\t\t test precision: 0.9736\n",
            "Epoch: 169,\t loss: 0.001393,\t\t train precision: 0.9698,\t\t test precision: 0.9728\n",
            "Epoch: 170,\t loss: 0.001562,\t\t train precision: 0.9773,\t\t test precision: 0.9712\n",
            "Epoch: 171,\t loss: 0.00152,\t\t train precision: 0.9674,\t\t test precision: 0.9646\n",
            "Epoch: 172,\t loss: 0.001377,\t\t train precision: 0.9735,\t\t test precision: 0.9687\n",
            "Epoch: 173,\t loss: 0.001569,\t\t train precision: 0.9687,\t\t test precision: 0.9736\n",
            "Epoch: 174,\t loss: 0.001611,\t\t train precision: 0.9684,\t\t test precision: 0.9712\n",
            "Epoch: 175,\t loss: 0.001544,\t\t train precision: 0.9759,\t\t test precision: 0.9695\n",
            "Epoch: 176,\t loss: 0.001464,\t\t train precision: 0.9773,\t\t test precision: 0.9712\n",
            "Epoch: 177,\t loss: 0.001405,\t\t train precision: 0.9756,\t\t test precision: 0.9703\n",
            "Epoch: 178,\t loss: 0.00142,\t\t train precision: 0.9704,\t\t test precision: 0.9728\n",
            "Epoch: 179,\t loss: 0.001431,\t\t train precision: 0.9722,\t\t test precision: 0.9687\n",
            "Epoch: 180,\t loss: 0.00128,\t\t train precision: 0.9735,\t\t test precision: 0.9712\n",
            "Epoch: 181,\t loss: 0.001468,\t\t train precision: 0.977,\t\t test precision: 0.9703\n",
            "Epoch: 182,\t loss: 0.001453,\t\t train precision: 0.9759,\t\t test precision: 0.9745\n",
            "Epoch: 183,\t loss: 0.001403,\t\t train precision: 0.979,\t\t test precision: 0.9745\n",
            "Epoch: 184,\t loss: 0.001503,\t\t train precision: 0.9722,\t\t test precision: 0.9728\n",
            "Epoch: 185,\t loss: 0.00134,\t\t train precision: 0.9766,\t\t test precision: 0.9687\n",
            "Epoch: 186,\t loss: 0.001571,\t\t train precision: 0.9729,\t\t test precision: 0.9687\n",
            "Epoch: 187,\t loss: 0.001364,\t\t train precision: 0.9732,\t\t test precision: 0.9654\n",
            "Epoch: 188,\t loss: 0.001474,\t\t train precision: 0.9739,\t\t test precision: 0.9712\n",
            "Epoch: 189,\t loss: 0.001387,\t\t train precision: 0.978,\t\t test precision: 0.9745\n",
            "Epoch: 190,\t loss: 0.001471,\t\t train precision: 0.9759,\t\t test precision: 0.9728\n",
            "Epoch: 191,\t loss: 0.001345,\t\t train precision: 0.9763,\t\t test precision: 0.9712\n",
            "Epoch: 192,\t loss: 0.001356,\t\t train precision: 0.9701,\t\t test precision: 0.9671\n",
            "Epoch: 193,\t loss: 0.001524,\t\t train precision: 0.978,\t\t test precision: 0.9728\n",
            "Epoch: 194,\t loss: 0.001452,\t\t train precision: 0.9759,\t\t test precision: 0.9703\n",
            "Epoch: 195,\t loss: 0.001479,\t\t train precision: 0.9749,\t\t test precision: 0.9703\n",
            "Epoch: 196,\t loss: 0.001386,\t\t train precision: 0.9759,\t\t test precision: 0.9687\n",
            "Epoch: 197,\t loss: 0.001419,\t\t train precision: 0.9735,\t\t test precision: 0.9687\n",
            "Epoch: 198,\t loss: 0.001348,\t\t train precision: 0.9739,\t\t test precision: 0.972\n",
            "Epoch: 199,\t loss: 0.00144,\t\t train precision: 0.9694,\t\t test precision: 0.9654\n",
            "Epoch: 200,\t loss: 0.001413,\t\t train precision: 0.9759,\t\t test precision: 0.9753\n",
            "Epoch: 201,\t loss: 0.001394,\t\t train precision: 0.9732,\t\t test precision: 0.9654\n",
            "Epoch: 202,\t loss: 0.001383,\t\t train precision: 0.9787,\t\t test precision: 0.9753\n",
            "Epoch: 203,\t loss: 0.001352,\t\t train precision: 0.9742,\t\t test precision: 0.9687\n",
            "Epoch: 204,\t loss: 0.001387,\t\t train precision: 0.9759,\t\t test precision: 0.9687\n",
            "Epoch: 205,\t loss: 0.001299,\t\t train precision: 0.9784,\t\t test precision: 0.9687\n",
            "Epoch: 206,\t loss: 0.001359,\t\t train precision: 0.9818,\t\t test precision: 0.9728\n",
            "Epoch: 207,\t loss: 0.001289,\t\t train precision: 0.9722,\t\t test precision: 0.9687\n",
            "Epoch: 208,\t loss: 0.001413,\t\t train precision: 0.977,\t\t test precision: 0.9745\n",
            "Epoch: 209,\t loss: 0.001306,\t\t train precision: 0.9715,\t\t test precision: 0.9687\n",
            "Epoch: 210,\t loss: 0.001445,\t\t train precision: 0.9718,\t\t test precision: 0.9629\n",
            "Epoch: 211,\t loss: 0.001466,\t\t train precision: 0.9756,\t\t test precision: 0.9687\n",
            "Epoch: 212,\t loss: 0.001532,\t\t train precision: 0.9801,\t\t test precision: 0.9703\n",
            "Epoch: 213,\t loss: 0.001455,\t\t train precision: 0.9735,\t\t test precision: 0.9695\n",
            "Epoch: 214,\t loss: 0.001372,\t\t train precision: 0.9759,\t\t test precision: 0.972\n",
            "Epoch: 215,\t loss: 0.001293,\t\t train precision: 0.9777,\t\t test precision: 0.9736\n",
            "Epoch: 216,\t loss: 0.001381,\t\t train precision: 0.9732,\t\t test precision: 0.9703\n",
            "Epoch: 217,\t loss: 0.001399,\t\t train precision: 0.9704,\t\t test precision: 0.9712\n",
            "Epoch: 218,\t loss: 0.001501,\t\t train precision: 0.9711,\t\t test precision: 0.9712\n",
            "Epoch: 219,\t loss: 0.001352,\t\t train precision: 0.9777,\t\t test precision: 0.9703\n",
            "Epoch: 220,\t loss: 0.001352,\t\t train precision: 0.9759,\t\t test precision: 0.972\n",
            "Epoch: 221,\t loss: 0.001396,\t\t train precision: 0.9735,\t\t test precision: 0.9769\n",
            "Epoch: 222,\t loss: 0.001418,\t\t train precision: 0.9801,\t\t test precision: 0.972\n",
            "Epoch: 223,\t loss: 0.001334,\t\t train precision: 0.977,\t\t test precision: 0.9769\n",
            "Epoch: 224,\t loss: 0.001277,\t\t train precision: 0.9749,\t\t test precision: 0.9712\n",
            "Epoch: 225,\t loss: 0.001289,\t\t train precision: 0.977,\t\t test precision: 0.972\n",
            "Epoch: 226,\t loss: 0.001413,\t\t train precision: 0.9766,\t\t test precision: 0.9712\n",
            "Epoch: 227,\t loss: 0.00137,\t\t train precision: 0.9787,\t\t test precision: 0.9745\n",
            "Epoch: 228,\t loss: 0.00131,\t\t train precision: 0.9749,\t\t test precision: 0.9703\n",
            "Epoch: 229,\t loss: 0.001328,\t\t train precision: 0.9722,\t\t test precision: 0.9662\n",
            "Epoch: 230,\t loss: 0.001416,\t\t train precision: 0.9701,\t\t test precision: 0.9638\n",
            "Epoch: 231,\t loss: 0.001359,\t\t train precision: 0.9763,\t\t test precision: 0.9703\n",
            "Epoch: 232,\t loss: 0.001334,\t\t train precision: 0.9753,\t\t test precision: 0.9695\n",
            "Epoch: 233,\t loss: 0.001427,\t\t train precision: 0.978,\t\t test precision: 0.9695\n",
            "Epoch: 234,\t loss: 0.001521,\t\t train precision: 0.9784,\t\t test precision: 0.972\n",
            "Epoch: 235,\t loss: 0.001463,\t\t train precision: 0.9704,\t\t test precision: 0.9728\n",
            "Epoch: 236,\t loss: 0.001273,\t\t train precision: 0.9739,\t\t test precision: 0.9712\n",
            "Epoch: 237,\t loss: 0.001301,\t\t train precision: 0.9742,\t\t test precision: 0.9728\n",
            "Epoch: 238,\t loss: 0.001325,\t\t train precision: 0.9756,\t\t test precision: 0.9761\n",
            "Epoch: 239,\t loss: 0.001291,\t\t train precision: 0.9735,\t\t test precision: 0.9671\n",
            "Epoch: 240,\t loss: 0.001353,\t\t train precision: 0.9739,\t\t test precision: 0.9703\n",
            "Epoch: 241,\t loss: 0.001351,\t\t train precision: 0.9784,\t\t test precision: 0.9736\n",
            "Epoch: 242,\t loss: 0.00138,\t\t train precision: 0.9787,\t\t test precision: 0.9662\n",
            "Epoch: 243,\t loss: 0.001365,\t\t train precision: 0.9787,\t\t test precision: 0.9736\n",
            "Epoch: 244,\t loss: 0.001396,\t\t train precision: 0.9759,\t\t test precision: 0.972\n",
            "Epoch: 245,\t loss: 0.001332,\t\t train precision: 0.9677,\t\t test precision: 0.9712\n",
            "Epoch: 246,\t loss: 0.001322,\t\t train precision: 0.9766,\t\t test precision: 0.9761\n",
            "Epoch: 247,\t loss: 0.001387,\t\t train precision: 0.9756,\t\t test precision: 0.9695\n",
            "Epoch: 248,\t loss: 0.001305,\t\t train precision: 0.978,\t\t test precision: 0.9753\n",
            "Epoch: 249,\t loss: 0.001392,\t\t train precision: 0.9753,\t\t test precision: 0.9728\n",
            "Epoch: 250,\t loss: 0.001374,\t\t train precision: 0.9749,\t\t test precision: 0.9671\n",
            "Epoch: 251,\t loss: 0.001318,\t\t train precision: 0.9777,\t\t test precision: 0.9728\n",
            "Epoch: 252,\t loss: 0.001365,\t\t train precision: 0.979,\t\t test precision: 0.9745\n",
            "Epoch: 253,\t loss: 0.001418,\t\t train precision: 0.9804,\t\t test precision: 0.9728\n",
            "Epoch: 254,\t loss: 0.001342,\t\t train precision: 0.9797,\t\t test precision: 0.9736\n",
            "Epoch: 255,\t loss: 0.001321,\t\t train precision: 0.9804,\t\t test precision: 0.9745\n",
            "Epoch: 256,\t loss: 0.001214,\t\t train precision: 0.9742,\t\t test precision: 0.9778\n",
            "Epoch: 257,\t loss: 0.001318,\t\t train precision: 0.9797,\t\t test precision: 0.9712\n",
            "Epoch: 258,\t loss: 0.001324,\t\t train precision: 0.9735,\t\t test precision: 0.972\n",
            "Epoch: 259,\t loss: 0.001319,\t\t train precision: 0.9725,\t\t test precision: 0.9695\n",
            "Epoch: 260,\t loss: 0.001335,\t\t train precision: 0.9759,\t\t test precision: 0.9703\n",
            "Epoch: 261,\t loss: 0.001298,\t\t train precision: 0.9766,\t\t test precision: 0.9753\n",
            "Epoch: 262,\t loss: 0.001291,\t\t train precision: 0.9718,\t\t test precision: 0.9703\n",
            "Epoch: 263,\t loss: 0.001375,\t\t train precision: 0.9718,\t\t test precision: 0.9703\n",
            "Epoch: 264,\t loss: 0.001334,\t\t train precision: 0.9763,\t\t test precision: 0.9745\n",
            "Epoch: 265,\t loss: 0.001198,\t\t train precision: 0.978,\t\t test precision: 0.9712\n",
            "Epoch: 266,\t loss: 0.001369,\t\t train precision: 0.9756,\t\t test precision: 0.9703\n",
            "Epoch: 267,\t loss: 0.001381,\t\t train precision: 0.979,\t\t test precision: 0.972\n",
            "Epoch: 268,\t loss: 0.001322,\t\t train precision: 0.9674,\t\t test precision: 0.9646\n",
            "Epoch: 269,\t loss: 0.001412,\t\t train precision: 0.9746,\t\t test precision: 0.9629\n",
            "Epoch: 270,\t loss: 0.001308,\t\t train precision: 0.9763,\t\t test precision: 0.9703\n",
            "Epoch: 271,\t loss: 0.001408,\t\t train precision: 0.9715,\t\t test precision: 0.9695\n",
            "Epoch: 272,\t loss: 0.001389,\t\t train precision: 0.9711,\t\t test precision: 0.972\n",
            "Epoch: 273,\t loss: 0.001408,\t\t train precision: 0.979,\t\t test precision: 0.9703\n",
            "Epoch: 274,\t loss: 0.001415,\t\t train precision: 0.9759,\t\t test precision: 0.9728\n",
            "Epoch: 275,\t loss: 0.001342,\t\t train precision: 0.9794,\t\t test precision: 0.9736\n",
            "Epoch: 276,\t loss: 0.001257,\t\t train precision: 0.9749,\t\t test precision: 0.9687\n",
            "Epoch: 277,\t loss: 0.001237,\t\t train precision: 0.9763,\t\t test precision: 0.9712\n",
            "Epoch: 278,\t loss: 0.001381,\t\t train precision: 0.9784,\t\t test precision: 0.9728\n",
            "Epoch: 279,\t loss: 0.001353,\t\t train precision: 0.9773,\t\t test precision: 0.9736\n",
            "Epoch: 280,\t loss: 0.001317,\t\t train precision: 0.9784,\t\t test precision: 0.9753\n",
            "Epoch: 281,\t loss: 0.001308,\t\t train precision: 0.9749,\t\t test precision: 0.9703\n",
            "Epoch: 282,\t loss: 0.001328,\t\t train precision: 0.979,\t\t test precision: 0.9728\n",
            "Epoch: 283,\t loss: 0.001334,\t\t train precision: 0.9739,\t\t test precision: 0.9703\n",
            "Epoch: 284,\t loss: 0.001178,\t\t train precision: 0.9811,\t\t test precision: 0.9728\n",
            "Epoch: 285,\t loss: 0.0012,\t\t train precision: 0.977,\t\t test precision: 0.9687\n",
            "Epoch: 286,\t loss: 0.001134,\t\t train precision: 0.9825,\t\t test precision: 0.9736\n",
            "Epoch: 287,\t loss: 0.001185,\t\t train precision: 0.9742,\t\t test precision: 0.9703\n",
            "Epoch: 288,\t loss: 0.001557,\t\t train precision: 0.9797,\t\t test precision: 0.9695\n",
            "Epoch: 289,\t loss: 0.001318,\t\t train precision: 0.9784,\t\t test precision: 0.9712\n",
            "Epoch: 290,\t loss: 0.001234,\t\t train precision: 0.979,\t\t test precision: 0.9662\n",
            "Epoch: 291,\t loss: 0.001251,\t\t train precision: 0.9759,\t\t test precision: 0.9703\n",
            "Epoch: 292,\t loss: 0.00131,\t\t train precision: 0.9735,\t\t test precision: 0.9679\n",
            "Epoch: 293,\t loss: 0.001287,\t\t train precision: 0.9732,\t\t test precision: 0.9687\n",
            "Epoch: 294,\t loss: 0.001227,\t\t train precision: 0.9797,\t\t test precision: 0.972\n",
            "Epoch: 295,\t loss: 0.001254,\t\t train precision: 0.9801,\t\t test precision: 0.9736\n",
            "Epoch: 296,\t loss: 0.00127,\t\t train precision: 0.9735,\t\t test precision: 0.9703\n",
            "Epoch: 297,\t loss: 0.001187,\t\t train precision: 0.9794,\t\t test precision: 0.9745\n",
            "Epoch: 298,\t loss: 0.001196,\t\t train precision: 0.9801,\t\t test precision: 0.9728\n",
            "Epoch: 299,\t loss: 0.001269,\t\t train precision: 0.978,\t\t test precision: 0.972\n",
            "Epoch: 300,\t loss: 0.00137,\t\t train precision: 0.9763,\t\t test precision: 0.9736\n",
            "Epoch: 301,\t loss: 0.001395,\t\t train precision: 0.9773,\t\t test precision: 0.9703\n",
            "Epoch: 302,\t loss: 0.001189,\t\t train precision: 0.9784,\t\t test precision: 0.9728\n",
            "Epoch: 303,\t loss: 0.001262,\t\t train precision: 0.979,\t\t test precision: 0.9761\n",
            "Epoch: 304,\t loss: 0.001278,\t\t train precision: 0.9777,\t\t test precision: 0.9687\n",
            "Epoch: 305,\t loss: 0.001321,\t\t train precision: 0.9698,\t\t test precision: 0.9679\n",
            "Epoch: 306,\t loss: 0.001136,\t\t train precision: 0.9746,\t\t test precision: 0.972\n",
            "Epoch: 307,\t loss: 0.001243,\t\t train precision: 0.9763,\t\t test precision: 0.9712\n",
            "Epoch: 308,\t loss: 0.001253,\t\t train precision: 0.9766,\t\t test precision: 0.9712\n",
            "Epoch: 309,\t loss: 0.001371,\t\t train precision: 0.977,\t\t test precision: 0.9736\n",
            "Epoch: 310,\t loss: 0.001177,\t\t train precision: 0.9773,\t\t test precision: 0.972\n",
            "Epoch: 311,\t loss: 0.001191,\t\t train precision: 0.979,\t\t test precision: 0.972\n",
            "Epoch: 312,\t loss: 0.001151,\t\t train precision: 0.978,\t\t test precision: 0.9712\n",
            "Epoch: 313,\t loss: 0.001304,\t\t train precision: 0.977,\t\t test precision: 0.9736\n",
            "Epoch: 314,\t loss: 0.001175,\t\t train precision: 0.979,\t\t test precision: 0.9728\n",
            "Epoch: 315,\t loss: 0.001204,\t\t train precision: 0.9773,\t\t test precision: 0.972\n",
            "Epoch: 316,\t loss: 0.001381,\t\t train precision: 0.9739,\t\t test precision: 0.9695\n",
            "Epoch: 317,\t loss: 0.001147,\t\t train precision: 0.9801,\t\t test precision: 0.9753\n",
            "Epoch: 318,\t loss: 0.001255,\t\t train precision: 0.9763,\t\t test precision: 0.9712\n",
            "Epoch: 319,\t loss: 0.001242,\t\t train precision: 0.978,\t\t test precision: 0.9695\n",
            "Epoch: 320,\t loss: 0.001157,\t\t train precision: 0.9794,\t\t test precision: 0.9736\n",
            "Epoch: 321,\t loss: 0.001336,\t\t train precision: 0.977,\t\t test precision: 0.9769\n",
            "Epoch: 322,\t loss: 0.00131,\t\t train precision: 0.9787,\t\t test precision: 0.9671\n",
            "Epoch: 323,\t loss: 0.001126,\t\t train precision: 0.9777,\t\t test precision: 0.972\n",
            "Epoch: 324,\t loss: 0.001274,\t\t train precision: 0.9763,\t\t test precision: 0.9745\n",
            "Epoch: 325,\t loss: 0.001184,\t\t train precision: 0.978,\t\t test precision: 0.9745\n",
            "Epoch: 326,\t loss: 0.001231,\t\t train precision: 0.9808,\t\t test precision: 0.9728\n",
            "Epoch: 327,\t loss: 0.001305,\t\t train precision: 0.9773,\t\t test precision: 0.9712\n",
            "Epoch: 328,\t loss: 0.001309,\t\t train precision: 0.9777,\t\t test precision: 0.9679\n",
            "Epoch: 329,\t loss: 0.001166,\t\t train precision: 0.9821,\t\t test precision: 0.9736\n",
            "Epoch: 330,\t loss: 0.001272,\t\t train precision: 0.979,\t\t test precision: 0.9728\n",
            "Epoch: 331,\t loss: 0.001288,\t\t train precision: 0.9746,\t\t test precision: 0.9671\n",
            "Epoch: 332,\t loss: 0.001277,\t\t train precision: 0.9794,\t\t test precision: 0.9695\n",
            "Epoch: 333,\t loss: 0.001318,\t\t train precision: 0.9801,\t\t test precision: 0.9712\n",
            "Epoch: 334,\t loss: 0.001205,\t\t train precision: 0.9763,\t\t test precision: 0.9728\n",
            "Epoch: 335,\t loss: 0.001223,\t\t train precision: 0.9787,\t\t test precision: 0.9703\n",
            "Epoch: 336,\t loss: 0.001303,\t\t train precision: 0.9835,\t\t test precision: 0.9703\n",
            "Epoch: 337,\t loss: 0.001259,\t\t train precision: 0.979,\t\t test precision: 0.972\n",
            "Epoch: 338,\t loss: 0.001295,\t\t train precision: 0.9756,\t\t test precision: 0.9679\n",
            "Epoch: 339,\t loss: 0.001247,\t\t train precision: 0.9773,\t\t test precision: 0.9728\n",
            "Epoch: 340,\t loss: 0.001214,\t\t train precision: 0.9808,\t\t test precision: 0.9769\n",
            "Epoch: 341,\t loss: 0.001159,\t\t train precision: 0.978,\t\t test precision: 0.9728\n",
            "Epoch: 342,\t loss: 0.001229,\t\t train precision: 0.979,\t\t test precision: 0.972\n",
            "Epoch: 343,\t loss: 0.001196,\t\t train precision: 0.977,\t\t test precision: 0.9695\n",
            "Epoch: 344,\t loss: 0.001162,\t\t train precision: 0.9759,\t\t test precision: 0.9712\n",
            "Epoch: 345,\t loss: 0.001273,\t\t train precision: 0.9801,\t\t test precision: 0.9778\n",
            "Epoch: 346,\t loss: 0.001188,\t\t train precision: 0.9794,\t\t test precision: 0.972\n",
            "Epoch: 347,\t loss: 0.001178,\t\t train precision: 0.9766,\t\t test precision: 0.9712\n",
            "Epoch: 348,\t loss: 0.001354,\t\t train precision: 0.9766,\t\t test precision: 0.9703\n",
            "Epoch: 349,\t loss: 0.001267,\t\t train precision: 0.9749,\t\t test precision: 0.9736\n",
            "Epoch: 350,\t loss: 0.001196,\t\t train precision: 0.977,\t\t test precision: 0.9761\n",
            "Epoch: 351,\t loss: 0.001232,\t\t train precision: 0.9773,\t\t test precision: 0.972\n",
            "Epoch: 352,\t loss: 0.001198,\t\t train precision: 0.977,\t\t test precision: 0.9736\n",
            "Epoch: 353,\t loss: 0.001284,\t\t train precision: 0.9818,\t\t test precision: 0.9736\n",
            "Epoch: 354,\t loss: 0.001245,\t\t train precision: 0.9742,\t\t test precision: 0.972\n",
            "Epoch: 355,\t loss: 0.001148,\t\t train precision: 0.978,\t\t test precision: 0.9695\n",
            "Epoch: 356,\t loss: 0.001212,\t\t train precision: 0.9787,\t\t test precision: 0.9703\n",
            "Epoch: 357,\t loss: 0.001256,\t\t train precision: 0.9756,\t\t test precision: 0.9671\n",
            "Epoch: 358,\t loss: 0.001148,\t\t train precision: 0.9777,\t\t test precision: 0.9687\n",
            "Epoch: 359,\t loss: 0.001315,\t\t train precision: 0.9784,\t\t test precision: 0.9728\n",
            "Epoch: 360,\t loss: 0.001134,\t\t train precision: 0.9725,\t\t test precision: 0.9662\n",
            "Epoch: 361,\t loss: 0.001307,\t\t train precision: 0.9828,\t\t test precision: 0.9728\n",
            "Epoch: 362,\t loss: 0.001252,\t\t train precision: 0.9821,\t\t test precision: 0.9728\n",
            "Epoch: 363,\t loss: 0.001131,\t\t train precision: 0.9811,\t\t test precision: 0.9736\n",
            "Epoch: 364,\t loss: 0.001269,\t\t train precision: 0.9773,\t\t test precision: 0.9728\n",
            "Epoch: 365,\t loss: 0.001334,\t\t train precision: 0.9804,\t\t test precision: 0.9761\n",
            "Epoch: 366,\t loss: 0.001297,\t\t train precision: 0.9787,\t\t test precision: 0.9712\n",
            "Epoch: 367,\t loss: 0.001176,\t\t train precision: 0.9684,\t\t test precision: 0.9671\n",
            "Epoch: 368,\t loss: 0.001258,\t\t train precision: 0.9801,\t\t test precision: 0.9671\n",
            "Epoch: 369,\t loss: 0.001155,\t\t train precision: 0.978,\t\t test precision: 0.9687\n",
            "Epoch: 370,\t loss: 0.00116,\t\t train precision: 0.9766,\t\t test precision: 0.9695\n",
            "Epoch: 371,\t loss: 0.001185,\t\t train precision: 0.9753,\t\t test precision: 0.9662\n",
            "Epoch: 372,\t loss: 0.001154,\t\t train precision: 0.9804,\t\t test precision: 0.9736\n",
            "Epoch: 373,\t loss: 0.001148,\t\t train precision: 0.9777,\t\t test precision: 0.972\n",
            "Epoch: 374,\t loss: 0.001337,\t\t train precision: 0.9784,\t\t test precision: 0.9736\n",
            "Epoch: 375,\t loss: 0.001146,\t\t train precision: 0.9773,\t\t test precision: 0.9695\n",
            "Epoch: 376,\t loss: 0.001234,\t\t train precision: 0.9732,\t\t test precision: 0.9712\n",
            "Epoch: 377,\t loss: 0.001321,\t\t train precision: 0.9749,\t\t test precision: 0.9753\n",
            "Epoch: 378,\t loss: 0.001245,\t\t train precision: 0.9725,\t\t test precision: 0.9671\n",
            "Epoch: 379,\t loss: 0.001139,\t\t train precision: 0.9763,\t\t test precision: 0.9728\n",
            "Epoch: 380,\t loss: 0.001273,\t\t train precision: 0.9828,\t\t test precision: 0.9761\n",
            "Epoch: 381,\t loss: 0.001212,\t\t train precision: 0.9801,\t\t test precision: 0.9728\n",
            "Epoch: 382,\t loss: 0.001176,\t\t train precision: 0.9794,\t\t test precision: 0.972\n",
            "Epoch: 383,\t loss: 0.001224,\t\t train precision: 0.9787,\t\t test precision: 0.9687\n",
            "Epoch: 384,\t loss: 0.001267,\t\t train precision: 0.9797,\t\t test precision: 0.9703\n",
            "Epoch: 385,\t loss: 0.001235,\t\t train precision: 0.9787,\t\t test precision: 0.9687\n",
            "Epoch: 386,\t loss: 0.001235,\t\t train precision: 0.9759,\t\t test precision: 0.9695\n",
            "Epoch: 387,\t loss: 0.001151,\t\t train precision: 0.9787,\t\t test precision: 0.9745\n",
            "Epoch: 388,\t loss: 0.001231,\t\t train precision: 0.979,\t\t test precision: 0.9745\n",
            "Epoch: 389,\t loss: 0.001107,\t\t train precision: 0.9722,\t\t test precision: 0.9687\n",
            "Epoch: 390,\t loss: 0.001184,\t\t train precision: 0.978,\t\t test precision: 0.9712\n",
            "Epoch: 391,\t loss: 0.001266,\t\t train precision: 0.9825,\t\t test precision: 0.9736\n",
            "Epoch: 392,\t loss: 0.001187,\t\t train precision: 0.9766,\t\t test precision: 0.9728\n",
            "Epoch: 393,\t loss: 0.001152,\t\t train precision: 0.9759,\t\t test precision: 0.9703\n",
            "Epoch: 394,\t loss: 0.001268,\t\t train precision: 0.979,\t\t test precision: 0.9695\n",
            "Epoch: 395,\t loss: 0.001208,\t\t train precision: 0.9811,\t\t test precision: 0.9728\n",
            "Epoch: 396,\t loss: 0.001064,\t\t train precision: 0.9777,\t\t test precision: 0.9703\n",
            "Epoch: 397,\t loss: 0.00127,\t\t train precision: 0.978,\t\t test precision: 0.972\n",
            "Epoch: 398,\t loss: 0.001095,\t\t train precision: 0.9773,\t\t test precision: 0.9712\n",
            "Epoch: 399,\t loss: 0.001123,\t\t train precision: 0.9735,\t\t test precision: 0.9646\n",
            "Epoch: 400,\t loss: 0.001275,\t\t train precision: 0.9777,\t\t test precision: 0.9695\n",
            "Epoch: 401,\t loss: 0.001149,\t\t train precision: 0.978,\t\t test precision: 0.9712\n",
            "Epoch: 402,\t loss: 0.001082,\t\t train precision: 0.978,\t\t test precision: 0.9728\n",
            "Epoch: 403,\t loss: 0.001166,\t\t train precision: 0.9801,\t\t test precision: 0.9687\n",
            "Epoch: 404,\t loss: 0.001165,\t\t train precision: 0.9729,\t\t test precision: 0.9687\n",
            "Epoch: 405,\t loss: 0.001188,\t\t train precision: 0.978,\t\t test precision: 0.9703\n",
            "Epoch: 406,\t loss: 0.001227,\t\t train precision: 0.9763,\t\t test precision: 0.9736\n",
            "Epoch: 407,\t loss: 0.001218,\t\t train precision: 0.9746,\t\t test precision: 0.9695\n",
            "Epoch: 408,\t loss: 0.001266,\t\t train precision: 0.978,\t\t test precision: 0.9712\n",
            "Epoch: 409,\t loss: 0.001188,\t\t train precision: 0.9711,\t\t test precision: 0.9703\n",
            "Epoch: 410,\t loss: 0.001249,\t\t train precision: 0.9797,\t\t test precision: 0.9712\n",
            "Epoch: 411,\t loss: 0.001223,\t\t train precision: 0.9814,\t\t test precision: 0.9703\n",
            "Epoch: 412,\t loss: 0.001106,\t\t train precision: 0.9784,\t\t test precision: 0.9728\n",
            "Epoch: 413,\t loss: 0.001174,\t\t train precision: 0.9794,\t\t test precision: 0.9695\n",
            "Epoch: 414,\t loss: 0.001189,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 415,\t loss: 0.001128,\t\t train precision: 0.9777,\t\t test precision: 0.9679\n",
            "Epoch: 416,\t loss: 0.00112,\t\t train precision: 0.9766,\t\t test precision: 0.9671\n",
            "Epoch: 417,\t loss: 0.001181,\t\t train precision: 0.9797,\t\t test precision: 0.972\n",
            "Epoch: 418,\t loss: 0.001198,\t\t train precision: 0.9784,\t\t test precision: 0.9736\n",
            "Epoch: 419,\t loss: 0.00117,\t\t train precision: 0.9777,\t\t test precision: 0.9728\n",
            "Epoch: 420,\t loss: 0.001199,\t\t train precision: 0.9749,\t\t test precision: 0.9662\n",
            "Epoch: 421,\t loss: 0.001183,\t\t train precision: 0.9777,\t\t test precision: 0.9753\n",
            "Epoch: 422,\t loss: 0.001283,\t\t train precision: 0.9777,\t\t test precision: 0.9695\n",
            "Epoch: 423,\t loss: 0.001095,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 424,\t loss: 0.001149,\t\t train precision: 0.9784,\t\t test precision: 0.9753\n",
            "Epoch: 425,\t loss: 0.001146,\t\t train precision: 0.9777,\t\t test precision: 0.9728\n",
            "Epoch: 426,\t loss: 0.001157,\t\t train precision: 0.9804,\t\t test precision: 0.9736\n",
            "Epoch: 427,\t loss: 0.001174,\t\t train precision: 0.9777,\t\t test precision: 0.972\n",
            "Epoch: 428,\t loss: 0.001167,\t\t train precision: 0.9808,\t\t test precision: 0.9745\n",
            "Epoch: 429,\t loss: 0.001093,\t\t train precision: 0.9787,\t\t test precision: 0.9712\n",
            "Epoch: 430,\t loss: 0.001064,\t\t train precision: 0.9808,\t\t test precision: 0.9753\n",
            "Epoch: 431,\t loss: 0.001234,\t\t train precision: 0.9808,\t\t test precision: 0.9728\n",
            "Epoch: 432,\t loss: 0.00111,\t\t train precision: 0.9801,\t\t test precision: 0.9736\n",
            "Epoch: 433,\t loss: 0.001261,\t\t train precision: 0.9801,\t\t test precision: 0.9728\n",
            "Epoch: 434,\t loss: 0.001089,\t\t train precision: 0.9759,\t\t test precision: 0.9712\n",
            "Epoch: 435,\t loss: 0.001117,\t\t train precision: 0.9749,\t\t test precision: 0.9679\n",
            "Epoch: 436,\t loss: 0.001124,\t\t train precision: 0.9808,\t\t test precision: 0.9769\n",
            "Epoch: 437,\t loss: 0.001281,\t\t train precision: 0.978,\t\t test precision: 0.9736\n",
            "Epoch: 438,\t loss: 0.001211,\t\t train precision: 0.9828,\t\t test precision: 0.9769\n",
            "Epoch: 439,\t loss: 0.001243,\t\t train precision: 0.9777,\t\t test precision: 0.9679\n",
            "Epoch: 440,\t loss: 0.001338,\t\t train precision: 0.9794,\t\t test precision: 0.9712\n",
            "Epoch: 441,\t loss: 0.001174,\t\t train precision: 0.9787,\t\t test precision: 0.9687\n",
            "Epoch: 442,\t loss: 0.001254,\t\t train precision: 0.9797,\t\t test precision: 0.9761\n",
            "Epoch: 443,\t loss: 0.001104,\t\t train precision: 0.9766,\t\t test precision: 0.9736\n",
            "Epoch: 444,\t loss: 0.001125,\t\t train precision: 0.9797,\t\t test precision: 0.9745\n",
            "Epoch: 445,\t loss: 0.001119,\t\t train precision: 0.9787,\t\t test precision: 0.9761\n",
            "Epoch: 446,\t loss: 0.001279,\t\t train precision: 0.9773,\t\t test precision: 0.9745\n",
            "Epoch: 447,\t loss: 0.001223,\t\t train precision: 0.977,\t\t test precision: 0.9703\n",
            "Epoch: 448,\t loss: 0.001222,\t\t train precision: 0.9784,\t\t test precision: 0.9695\n",
            "Epoch: 449,\t loss: 0.001255,\t\t train precision: 0.978,\t\t test precision: 0.9728\n",
            "Epoch: 450,\t loss: 0.001153,\t\t train precision: 0.9797,\t\t test precision: 0.9703\n",
            "Epoch: 451,\t loss: 0.001037,\t\t train precision: 0.9787,\t\t test precision: 0.9736\n",
            "Epoch: 452,\t loss: 0.001215,\t\t train precision: 0.9759,\t\t test precision: 0.9736\n",
            "Epoch: 453,\t loss: 0.001277,\t\t train precision: 0.9766,\t\t test precision: 0.9736\n",
            "Epoch: 454,\t loss: 0.001144,\t\t train precision: 0.9749,\t\t test precision: 0.9712\n",
            "Epoch: 455,\t loss: 0.00125,\t\t train precision: 0.977,\t\t test precision: 0.972\n",
            "Epoch: 456,\t loss: 0.001224,\t\t train precision: 0.9835,\t\t test precision: 0.9753\n",
            "Epoch: 457,\t loss: 0.001036,\t\t train precision: 0.9821,\t\t test precision: 0.9736\n",
            "Epoch: 458,\t loss: 0.001149,\t\t train precision: 0.9818,\t\t test precision: 0.9761\n",
            "Epoch: 459,\t loss: 0.001115,\t\t train precision: 0.9773,\t\t test precision: 0.9695\n",
            "Epoch: 460,\t loss: 0.001083,\t\t train precision: 0.9794,\t\t test precision: 0.9728\n",
            "Epoch: 461,\t loss: 0.001101,\t\t train precision: 0.9784,\t\t test precision: 0.9745\n",
            "Epoch: 462,\t loss: 0.001363,\t\t train precision: 0.9808,\t\t test precision: 0.9753\n",
            "Epoch: 463,\t loss: 0.001151,\t\t train precision: 0.9808,\t\t test precision: 0.9728\n",
            "Epoch: 464,\t loss: 0.001207,\t\t train precision: 0.9797,\t\t test precision: 0.9736\n",
            "Epoch: 465,\t loss: 0.001171,\t\t train precision: 0.9814,\t\t test precision: 0.9753\n",
            "Epoch: 466,\t loss: 0.001134,\t\t train precision: 0.9811,\t\t test precision: 0.9769\n",
            "Epoch: 467,\t loss: 0.001098,\t\t train precision: 0.9804,\t\t test precision: 0.9728\n",
            "Epoch: 468,\t loss: 0.001073,\t\t train precision: 0.9797,\t\t test precision: 0.9745\n",
            "Epoch: 469,\t loss: 0.001007,\t\t train precision: 0.9797,\t\t test precision: 0.9736\n",
            "Epoch: 470,\t loss: 0.001107,\t\t train precision: 0.978,\t\t test precision: 0.9753\n",
            "Epoch: 471,\t loss: 0.001144,\t\t train precision: 0.9804,\t\t test precision: 0.9736\n",
            "Epoch: 472,\t loss: 0.001242,\t\t train precision: 0.9777,\t\t test precision: 0.9712\n",
            "Epoch: 473,\t loss: 0.001187,\t\t train precision: 0.9773,\t\t test precision: 0.9712\n",
            "Epoch: 474,\t loss: 0.001164,\t\t train precision: 0.9759,\t\t test precision: 0.9712\n",
            "Epoch: 475,\t loss: 0.001085,\t\t train precision: 0.9766,\t\t test precision: 0.9736\n",
            "Epoch: 476,\t loss: 0.001169,\t\t train precision: 0.9828,\t\t test precision: 0.9778\n",
            "Epoch: 477,\t loss: 0.001067,\t\t train precision: 0.977,\t\t test precision: 0.9736\n",
            "Epoch: 478,\t loss: 0.001049,\t\t train precision: 0.9777,\t\t test precision: 0.9745\n",
            "Epoch: 479,\t loss: 0.001136,\t\t train precision: 0.9832,\t\t test precision: 0.9728\n",
            "Epoch: 480,\t loss: 0.001207,\t\t train precision: 0.978,\t\t test precision: 0.9736\n",
            "Epoch: 481,\t loss: 0.00105,\t\t train precision: 0.9801,\t\t test precision: 0.9728\n",
            "Epoch: 482,\t loss: 0.001192,\t\t train precision: 0.977,\t\t test precision: 0.9736\n",
            "Epoch: 483,\t loss: 0.0011,\t\t train precision: 0.9763,\t\t test precision: 0.9695\n",
            "Epoch: 484,\t loss: 0.001318,\t\t train precision: 0.978,\t\t test precision: 0.9736\n",
            "Epoch: 485,\t loss: 0.001143,\t\t train precision: 0.977,\t\t test precision: 0.9687\n",
            "Epoch: 486,\t loss: 0.00112,\t\t train precision: 0.978,\t\t test precision: 0.9745\n",
            "Epoch: 487,\t loss: 0.0012,\t\t train precision: 0.9756,\t\t test precision: 0.9712\n",
            "Epoch: 488,\t loss: 0.001188,\t\t train precision: 0.9756,\t\t test precision: 0.9679\n",
            "Epoch: 489,\t loss: 0.001212,\t\t train precision: 0.9794,\t\t test precision: 0.9712\n",
            "Epoch: 490,\t loss: 0.001078,\t\t train precision: 0.9825,\t\t test precision: 0.9786\n",
            "Epoch: 491,\t loss: 0.0009743,\t\t train precision: 0.9753,\t\t test precision: 0.9703\n",
            "Epoch: 492,\t loss: 0.001162,\t\t train precision: 0.9753,\t\t test precision: 0.972\n",
            "Epoch: 493,\t loss: 0.001084,\t\t train precision: 0.9794,\t\t test precision: 0.9753\n",
            "Epoch: 494,\t loss: 0.001115,\t\t train precision: 0.9818,\t\t test precision: 0.9769\n",
            "Epoch: 495,\t loss: 0.001109,\t\t train precision: 0.979,\t\t test precision: 0.9736\n",
            "Epoch: 496,\t loss: 0.001141,\t\t train precision: 0.9811,\t\t test precision: 0.9778\n",
            "Epoch: 497,\t loss: 0.001133,\t\t train precision: 0.9784,\t\t test precision: 0.9728\n",
            "Epoch: 498,\t loss: 0.001166,\t\t train precision: 0.9729,\t\t test precision: 0.9687\n",
            "Epoch: 499,\t loss: 0.001223,\t\t train precision: 0.978,\t\t test precision: 0.9703\n",
            "Epoch: 500,\t loss: 0.001133,\t\t train precision: 0.9787,\t\t test precision: 0.9728\n",
            "Epoch: 501,\t loss: 0.001308,\t\t train precision: 0.9759,\t\t test precision: 0.9695\n",
            "Epoch: 502,\t loss: 0.001253,\t\t train precision: 0.9777,\t\t test precision: 0.9712\n",
            "Epoch: 503,\t loss: 0.001116,\t\t train precision: 0.9784,\t\t test precision: 0.9778\n",
            "Epoch: 504,\t loss: 0.001113,\t\t train precision: 0.977,\t\t test precision: 0.9687\n",
            "Epoch: 505,\t loss: 0.001048,\t\t train precision: 0.9804,\t\t test precision: 0.9745\n",
            "Epoch: 506,\t loss: 0.001139,\t\t train precision: 0.9801,\t\t test precision: 0.9736\n",
            "Epoch: 507,\t loss: 0.001119,\t\t train precision: 0.979,\t\t test precision: 0.9728\n",
            "Epoch: 508,\t loss: 0.001069,\t\t train precision: 0.9756,\t\t test precision: 0.9769\n",
            "Epoch: 509,\t loss: 0.001078,\t\t train precision: 0.9797,\t\t test precision: 0.9671\n",
            "Epoch: 510,\t loss: 0.001099,\t\t train precision: 0.9808,\t\t test precision: 0.9753\n",
            "Epoch: 511,\t loss: 0.001139,\t\t train precision: 0.9828,\t\t test precision: 0.9769\n",
            "Epoch: 512,\t loss: 0.0009531,\t\t train precision: 0.9804,\t\t test precision: 0.9778\n",
            "Epoch: 513,\t loss: 0.001139,\t\t train precision: 0.9811,\t\t test precision: 0.9761\n",
            "Epoch: 514,\t loss: 0.001072,\t\t train precision: 0.9808,\t\t test precision: 0.9753\n",
            "Epoch: 515,\t loss: 0.001128,\t\t train precision: 0.9784,\t\t test precision: 0.9736\n",
            "Epoch: 516,\t loss: 0.001047,\t\t train precision: 0.9811,\t\t test precision: 0.9745\n",
            "Epoch: 517,\t loss: 0.0009582,\t\t train precision: 0.9801,\t\t test precision: 0.9753\n",
            "Epoch: 518,\t loss: 0.001077,\t\t train precision: 0.978,\t\t test precision: 0.9736\n",
            "Epoch: 519,\t loss: 0.001045,\t\t train precision: 0.9808,\t\t test precision: 0.9769\n",
            "Epoch: 520,\t loss: 0.001129,\t\t train precision: 0.9797,\t\t test precision: 0.9761\n",
            "Epoch: 521,\t loss: 0.001074,\t\t train precision: 0.9804,\t\t test precision: 0.9745\n",
            "Epoch: 522,\t loss: 0.001117,\t\t train precision: 0.9763,\t\t test precision: 0.9745\n",
            "Epoch: 523,\t loss: 0.001171,\t\t train precision: 0.9777,\t\t test precision: 0.9728\n",
            "Epoch: 524,\t loss: 0.001177,\t\t train precision: 0.9773,\t\t test precision: 0.972\n",
            "Epoch: 525,\t loss: 0.001036,\t\t train precision: 0.9804,\t\t test precision: 0.9736\n",
            "Epoch: 526,\t loss: 0.001097,\t\t train precision: 0.9742,\t\t test precision: 0.9728\n",
            "Epoch: 527,\t loss: 0.001066,\t\t train precision: 0.9735,\t\t test precision: 0.9753\n",
            "Epoch: 528,\t loss: 0.001187,\t\t train precision: 0.9766,\t\t test precision: 0.9745\n",
            "Epoch: 529,\t loss: 0.001061,\t\t train precision: 0.9784,\t\t test precision: 0.9745\n",
            "Epoch: 530,\t loss: 0.001077,\t\t train precision: 0.9814,\t\t test precision: 0.9753\n",
            "Epoch: 531,\t loss: 0.00111,\t\t train precision: 0.977,\t\t test precision: 0.9695\n",
            "Epoch: 532,\t loss: 0.001162,\t\t train precision: 0.9794,\t\t test precision: 0.9728\n",
            "Epoch: 533,\t loss: 0.001058,\t\t train precision: 0.9794,\t\t test precision: 0.9769\n",
            "Epoch: 534,\t loss: 0.001112,\t\t train precision: 0.9814,\t\t test precision: 0.9736\n",
            "Epoch: 535,\t loss: 0.001104,\t\t train precision: 0.9787,\t\t test precision: 0.9753\n",
            "Epoch: 536,\t loss: 0.001156,\t\t train precision: 0.9797,\t\t test precision: 0.9769\n",
            "Epoch: 537,\t loss: 0.001142,\t\t train precision: 0.9811,\t\t test precision: 0.9728\n",
            "Epoch: 538,\t loss: 0.00115,\t\t train precision: 0.9773,\t\t test precision: 0.9736\n",
            "Epoch: 539,\t loss: 0.001102,\t\t train precision: 0.9797,\t\t test precision: 0.9728\n",
            "Epoch: 540,\t loss: 0.001161,\t\t train precision: 0.9777,\t\t test precision: 0.9703\n",
            "Epoch: 541,\t loss: 0.001092,\t\t train precision: 0.9825,\t\t test precision: 0.9712\n",
            "Epoch: 542,\t loss: 0.001001,\t\t train precision: 0.9801,\t\t test precision: 0.9736\n",
            "Epoch: 543,\t loss: 0.00106,\t\t train precision: 0.979,\t\t test precision: 0.9753\n",
            "Epoch: 544,\t loss: 0.001202,\t\t train precision: 0.9739,\t\t test precision: 0.9695\n",
            "Epoch: 545,\t loss: 0.00111,\t\t train precision: 0.9825,\t\t test precision: 0.9778\n",
            "Epoch: 546,\t loss: 0.001005,\t\t train precision: 0.9814,\t\t test precision: 0.9778\n",
            "Epoch: 547,\t loss: 0.001059,\t\t train precision: 0.978,\t\t test precision: 0.9753\n",
            "Epoch: 548,\t loss: 0.001054,\t\t train precision: 0.9759,\t\t test precision: 0.9712\n",
            "Epoch: 549,\t loss: 0.001073,\t\t train precision: 0.9825,\t\t test precision: 0.9745\n",
            "Epoch: 550,\t loss: 0.001109,\t\t train precision: 0.9804,\t\t test precision: 0.9753\n",
            "Epoch: 551,\t loss: 0.001089,\t\t train precision: 0.9811,\t\t test precision: 0.9745\n",
            "Epoch: 552,\t loss: 0.001086,\t\t train precision: 0.979,\t\t test precision: 0.9728\n",
            "Epoch: 553,\t loss: 0.001147,\t\t train precision: 0.9808,\t\t test precision: 0.9745\n",
            "Epoch: 554,\t loss: 0.001165,\t\t train precision: 0.978,\t\t test precision: 0.9753\n",
            "Epoch: 555,\t loss: 0.001351,\t\t train precision: 0.9704,\t\t test precision: 0.9695\n",
            "Epoch: 556,\t loss: 0.001201,\t\t train precision: 0.9808,\t\t test precision: 0.9745\n",
            "Epoch: 557,\t loss: 0.00101,\t\t train precision: 0.9801,\t\t test precision: 0.9761\n",
            "Epoch: 558,\t loss: 0.001148,\t\t train precision: 0.9746,\t\t test precision: 0.972\n",
            "Epoch: 559,\t loss: 0.001142,\t\t train precision: 0.9832,\t\t test precision: 0.9761\n",
            "Epoch: 560,\t loss: 0.001109,\t\t train precision: 0.9784,\t\t test precision: 0.9745\n",
            "Epoch: 561,\t loss: 0.001052,\t\t train precision: 0.9773,\t\t test precision: 0.9761\n",
            "Epoch: 562,\t loss: 0.001023,\t\t train precision: 0.9811,\t\t test precision: 0.9753\n",
            "Epoch: 563,\t loss: 0.001096,\t\t train precision: 0.9732,\t\t test precision: 0.9728\n",
            "Epoch: 564,\t loss: 0.001204,\t\t train precision: 0.9801,\t\t test precision: 0.9769\n",
            "Epoch: 565,\t loss: 0.0009896,\t\t train precision: 0.9794,\t\t test precision: 0.9736\n",
            "Epoch: 566,\t loss: 0.001074,\t\t train precision: 0.979,\t\t test precision: 0.972\n",
            "Epoch: 567,\t loss: 0.00104,\t\t train precision: 0.9773,\t\t test precision: 0.9695\n",
            "Epoch: 568,\t loss: 0.001119,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 569,\t loss: 0.001045,\t\t train precision: 0.9787,\t\t test precision: 0.9745\n",
            "Epoch: 570,\t loss: 0.001095,\t\t train precision: 0.978,\t\t test precision: 0.9687\n",
            "Epoch: 571,\t loss: 0.001045,\t\t train precision: 0.9808,\t\t test precision: 0.9745\n",
            "Epoch: 572,\t loss: 0.001152,\t\t train precision: 0.9804,\t\t test precision: 0.9769\n",
            "Epoch: 573,\t loss: 0.001048,\t\t train precision: 0.9828,\t\t test precision: 0.9769\n",
            "Epoch: 574,\t loss: 0.001046,\t\t train precision: 0.9808,\t\t test precision: 0.9703\n",
            "Epoch: 575,\t loss: 0.001133,\t\t train precision: 0.9773,\t\t test precision: 0.9695\n",
            "Epoch: 576,\t loss: 0.0009755,\t\t train precision: 0.9808,\t\t test precision: 0.972\n",
            "Epoch: 577,\t loss: 0.001054,\t\t train precision: 0.9808,\t\t test precision: 0.9761\n",
            "Epoch: 578,\t loss: 0.0009969,\t\t train precision: 0.9773,\t\t test precision: 0.9703\n",
            "Epoch: 579,\t loss: 0.001131,\t\t train precision: 0.9811,\t\t test precision: 0.9761\n",
            "Epoch: 580,\t loss: 0.001117,\t\t train precision: 0.9766,\t\t test precision: 0.9728\n",
            "Epoch: 581,\t loss: 0.001067,\t\t train precision: 0.9784,\t\t test precision: 0.9728\n",
            "Epoch: 582,\t loss: 0.0009912,\t\t train precision: 0.9797,\t\t test precision: 0.9736\n",
            "Epoch: 583,\t loss: 0.001088,\t\t train precision: 0.9821,\t\t test precision: 0.9745\n",
            "Epoch: 584,\t loss: 0.001074,\t\t train precision: 0.978,\t\t test precision: 0.9695\n",
            "Epoch: 585,\t loss: 0.001003,\t\t train precision: 0.9742,\t\t test precision: 0.9703\n",
            "Epoch: 586,\t loss: 0.001043,\t\t train precision: 0.978,\t\t test precision: 0.972\n",
            "Epoch: 587,\t loss: 0.001111,\t\t train precision: 0.9797,\t\t test precision: 0.9736\n",
            "Epoch: 588,\t loss: 0.00105,\t\t train precision: 0.9746,\t\t test precision: 0.972\n",
            "Epoch: 589,\t loss: 0.001084,\t\t train precision: 0.9756,\t\t test precision: 0.9712\n",
            "Epoch: 590,\t loss: 0.001192,\t\t train precision: 0.9742,\t\t test precision: 0.972\n",
            "Epoch: 591,\t loss: 0.001146,\t\t train precision: 0.9828,\t\t test precision: 0.9753\n",
            "Epoch: 592,\t loss: 0.001188,\t\t train precision: 0.977,\t\t test precision: 0.9769\n",
            "Epoch: 593,\t loss: 0.001007,\t\t train precision: 0.979,\t\t test precision: 0.9753\n",
            "Epoch: 594,\t loss: 0.001034,\t\t train precision: 0.9801,\t\t test precision: 0.9736\n",
            "Epoch: 595,\t loss: 0.001029,\t\t train precision: 0.978,\t\t test precision: 0.9728\n",
            "Epoch: 596,\t loss: 0.00121,\t\t train precision: 0.9773,\t\t test precision: 0.9703\n",
            "Epoch: 597,\t loss: 0.001129,\t\t train precision: 0.9835,\t\t test precision: 0.9745\n",
            "Epoch: 598,\t loss: 0.001075,\t\t train precision: 0.9797,\t\t test precision: 0.972\n",
            "Epoch: 599,\t loss: 0.001116,\t\t train precision: 0.9811,\t\t test precision: 0.9761\n",
            "Epoch: 600,\t loss: 0.001041,\t\t train precision: 0.9814,\t\t test precision: 0.9736\n",
            "Epoch: 601,\t loss: 0.001121,\t\t train precision: 0.9821,\t\t test precision: 0.9745\n",
            "Epoch: 602,\t loss: 0.001214,\t\t train precision: 0.9808,\t\t test precision: 0.9761\n",
            "Epoch: 603,\t loss: 0.001148,\t\t train precision: 0.9811,\t\t test precision: 0.9703\n",
            "Epoch: 604,\t loss: 0.001152,\t\t train precision: 0.9763,\t\t test precision: 0.9745\n",
            "Epoch: 605,\t loss: 0.001109,\t\t train precision: 0.9832,\t\t test precision: 0.9753\n",
            "Epoch: 606,\t loss: 0.001107,\t\t train precision: 0.9773,\t\t test precision: 0.972\n",
            "Epoch: 607,\t loss: 0.001097,\t\t train precision: 0.9753,\t\t test precision: 0.9728\n",
            "Epoch: 608,\t loss: 0.00111,\t\t train precision: 0.979,\t\t test precision: 0.9753\n",
            "Epoch: 609,\t loss: 0.001102,\t\t train precision: 0.9814,\t\t test precision: 0.9761\n",
            "Epoch: 610,\t loss: 0.001262,\t\t train precision: 0.9801,\t\t test precision: 0.9736\n",
            "Epoch: 611,\t loss: 0.001128,\t\t train precision: 0.9832,\t\t test precision: 0.9728\n",
            "Epoch: 612,\t loss: 0.001129,\t\t train precision: 0.9804,\t\t test precision: 0.9761\n",
            "Epoch: 613,\t loss: 0.001065,\t\t train precision: 0.9801,\t\t test precision: 0.9745\n",
            "Epoch: 614,\t loss: 0.001099,\t\t train precision: 0.9759,\t\t test precision: 0.9761\n",
            "Epoch: 615,\t loss: 0.001056,\t\t train precision: 0.9773,\t\t test precision: 0.9703\n",
            "Epoch: 616,\t loss: 0.0009927,\t\t train precision: 0.9784,\t\t test precision: 0.972\n",
            "Epoch: 617,\t loss: 0.001074,\t\t train precision: 0.979,\t\t test precision: 0.9736\n",
            "Epoch: 618,\t loss: 0.001103,\t\t train precision: 0.9787,\t\t test precision: 0.9703\n",
            "Epoch: 619,\t loss: 0.000999,\t\t train precision: 0.977,\t\t test precision: 0.9703\n",
            "Epoch: 620,\t loss: 0.0009431,\t\t train precision: 0.9811,\t\t test precision: 0.9761\n",
            "Epoch: 621,\t loss: 0.000997,\t\t train precision: 0.9825,\t\t test precision: 0.9778\n",
            "Epoch: 622,\t loss: 0.001034,\t\t train precision: 0.9787,\t\t test precision: 0.9736\n",
            "Epoch: 623,\t loss: 0.001001,\t\t train precision: 0.978,\t\t test precision: 0.9753\n",
            "Epoch: 624,\t loss: 0.001042,\t\t train precision: 0.977,\t\t test precision: 0.9728\n",
            "Epoch: 625,\t loss: 0.001053,\t\t train precision: 0.9784,\t\t test precision: 0.9753\n",
            "Epoch: 626,\t loss: 0.001044,\t\t train precision: 0.9787,\t\t test precision: 0.9802\n",
            "Epoch: 627,\t loss: 0.001032,\t\t train precision: 0.9804,\t\t test precision: 0.9769\n",
            "Epoch: 628,\t loss: 0.001043,\t\t train precision: 0.9804,\t\t test precision: 0.972\n",
            "Epoch: 629,\t loss: 0.00106,\t\t train precision: 0.9777,\t\t test precision: 0.9703\n",
            "Epoch: 630,\t loss: 0.00102,\t\t train precision: 0.9811,\t\t test precision: 0.9778\n",
            "Epoch: 631,\t loss: 0.001048,\t\t train precision: 0.9756,\t\t test precision: 0.9778\n",
            "Epoch: 632,\t loss: 0.001008,\t\t train precision: 0.9787,\t\t test precision: 0.9712\n",
            "Epoch: 633,\t loss: 0.001016,\t\t train precision: 0.9797,\t\t test precision: 0.9745\n",
            "Epoch: 634,\t loss: 0.001009,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 635,\t loss: 0.001009,\t\t train precision: 0.9777,\t\t test precision: 0.9728\n",
            "Epoch: 636,\t loss: 0.001073,\t\t train precision: 0.9838,\t\t test precision: 0.9761\n",
            "Epoch: 637,\t loss: 0.0009769,\t\t train precision: 0.9797,\t\t test precision: 0.9761\n",
            "Epoch: 638,\t loss: 0.001084,\t\t train precision: 0.9777,\t\t test precision: 0.9745\n",
            "Epoch: 639,\t loss: 0.001184,\t\t train precision: 0.9749,\t\t test precision: 0.9736\n",
            "Epoch: 640,\t loss: 0.001067,\t\t train precision: 0.9787,\t\t test precision: 0.9736\n",
            "Epoch: 641,\t loss: 0.001012,\t\t train precision: 0.9735,\t\t test precision: 0.9671\n",
            "Epoch: 642,\t loss: 0.001075,\t\t train precision: 0.9777,\t\t test precision: 0.9712\n",
            "Epoch: 643,\t loss: 0.001032,\t\t train precision: 0.9794,\t\t test precision: 0.972\n",
            "Epoch: 644,\t loss: 0.001092,\t\t train precision: 0.9808,\t\t test precision: 0.9736\n",
            "Epoch: 645,\t loss: 0.001143,\t\t train precision: 0.9804,\t\t test precision: 0.9736\n",
            "Epoch: 646,\t loss: 0.001038,\t\t train precision: 0.9808,\t\t test precision: 0.9753\n",
            "Epoch: 647,\t loss: 0.00107,\t\t train precision: 0.9808,\t\t test precision: 0.9745\n",
            "Epoch: 648,\t loss: 0.0009679,\t\t train precision: 0.9821,\t\t test precision: 0.9769\n",
            "Epoch: 649,\t loss: 0.0009982,\t\t train precision: 0.9787,\t\t test precision: 0.9761\n",
            "Epoch: 650,\t loss: 0.001141,\t\t train precision: 0.979,\t\t test precision: 0.9753\n",
            "Epoch: 651,\t loss: 0.0009907,\t\t train precision: 0.979,\t\t test precision: 0.9712\n",
            "Epoch: 652,\t loss: 0.001086,\t\t train precision: 0.9838,\t\t test precision: 0.9753\n",
            "Epoch: 653,\t loss: 0.001082,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 654,\t loss: 0.001125,\t\t train precision: 0.9739,\t\t test precision: 0.9712\n",
            "Epoch: 655,\t loss: 0.00102,\t\t train precision: 0.9808,\t\t test precision: 0.9753\n",
            "Epoch: 656,\t loss: 0.0009849,\t\t train precision: 0.9787,\t\t test precision: 0.9736\n",
            "Epoch: 657,\t loss: 0.001002,\t\t train precision: 0.9818,\t\t test precision: 0.9761\n",
            "Epoch: 658,\t loss: 0.00107,\t\t train precision: 0.9732,\t\t test precision: 0.9662\n",
            "Epoch: 659,\t loss: 0.001082,\t\t train precision: 0.9797,\t\t test precision: 0.9778\n",
            "Epoch: 660,\t loss: 0.0009587,\t\t train precision: 0.9701,\t\t test precision: 0.9654\n",
            "Epoch: 661,\t loss: 0.001055,\t\t train precision: 0.9797,\t\t test precision: 0.9769\n",
            "Epoch: 662,\t loss: 0.001048,\t\t train precision: 0.9821,\t\t test precision: 0.9794\n",
            "Epoch: 663,\t loss: 0.001029,\t\t train precision: 0.9804,\t\t test precision: 0.9753\n",
            "Epoch: 664,\t loss: 0.001032,\t\t train precision: 0.9794,\t\t test precision: 0.9736\n",
            "Epoch: 665,\t loss: 0.001099,\t\t train precision: 0.9814,\t\t test precision: 0.9761\n",
            "Epoch: 666,\t loss: 0.00102,\t\t train precision: 0.9801,\t\t test precision: 0.9736\n",
            "Epoch: 667,\t loss: 0.0009694,\t\t train precision: 0.9814,\t\t test precision: 0.9736\n",
            "Epoch: 668,\t loss: 0.001038,\t\t train precision: 0.9763,\t\t test precision: 0.9712\n",
            "Epoch: 669,\t loss: 0.0009985,\t\t train precision: 0.979,\t\t test precision: 0.9728\n",
            "Epoch: 670,\t loss: 0.0009501,\t\t train precision: 0.9804,\t\t test precision: 0.972\n",
            "Epoch: 671,\t loss: 0.001026,\t\t train precision: 0.9787,\t\t test precision: 0.9736\n",
            "Epoch: 672,\t loss: 0.001075,\t\t train precision: 0.9811,\t\t test precision: 0.9753\n",
            "Epoch: 673,\t loss: 0.001094,\t\t train precision: 0.9825,\t\t test precision: 0.9761\n",
            "Epoch: 674,\t loss: 0.001055,\t\t train precision: 0.9749,\t\t test precision: 0.9703\n",
            "Epoch: 675,\t loss: 0.001012,\t\t train precision: 0.979,\t\t test precision: 0.9761\n",
            "Epoch: 676,\t loss: 0.001147,\t\t train precision: 0.9777,\t\t test precision: 0.9679\n",
            "Epoch: 677,\t loss: 0.00109,\t\t train precision: 0.9808,\t\t test precision: 0.9712\n",
            "Epoch: 678,\t loss: 0.001017,\t\t train precision: 0.9811,\t\t test precision: 0.9753\n",
            "Epoch: 679,\t loss: 0.001042,\t\t train precision: 0.9801,\t\t test precision: 0.9761\n",
            "Epoch: 680,\t loss: 0.000987,\t\t train precision: 0.9759,\t\t test precision: 0.9712\n",
            "Epoch: 681,\t loss: 0.001011,\t\t train precision: 0.9746,\t\t test precision: 0.9695\n",
            "Epoch: 682,\t loss: 0.001038,\t\t train precision: 0.9797,\t\t test precision: 0.9736\n",
            "Epoch: 683,\t loss: 0.001082,\t\t train precision: 0.9832,\t\t test precision: 0.9769\n",
            "Epoch: 684,\t loss: 0.001006,\t\t train precision: 0.9825,\t\t test precision: 0.9794\n",
            "Epoch: 685,\t loss: 0.0009803,\t\t train precision: 0.9739,\t\t test precision: 0.9712\n",
            "Epoch: 686,\t loss: 0.001037,\t\t train precision: 0.978,\t\t test precision: 0.9728\n",
            "Epoch: 687,\t loss: 0.001093,\t\t train precision: 0.9763,\t\t test precision: 0.9712\n",
            "Epoch: 688,\t loss: 0.001055,\t\t train precision: 0.9828,\t\t test precision: 0.9753\n",
            "Epoch: 689,\t loss: 0.001082,\t\t train precision: 0.9777,\t\t test precision: 0.9778\n",
            "Epoch: 690,\t loss: 0.001135,\t\t train precision: 0.9756,\t\t test precision: 0.972\n",
            "Epoch: 691,\t loss: 0.001072,\t\t train precision: 0.9804,\t\t test precision: 0.9712\n",
            "Epoch: 692,\t loss: 0.001017,\t\t train precision: 0.9797,\t\t test precision: 0.9761\n",
            "Epoch: 693,\t loss: 0.001069,\t\t train precision: 0.9787,\t\t test precision: 0.9753\n",
            "Epoch: 694,\t loss: 0.001004,\t\t train precision: 0.9773,\t\t test precision: 0.9745\n",
            "Epoch: 695,\t loss: 0.001015,\t\t train precision: 0.9766,\t\t test precision: 0.9745\n",
            "Epoch: 696,\t loss: 0.000985,\t\t train precision: 0.9811,\t\t test precision: 0.9769\n",
            "Epoch: 697,\t loss: 0.001082,\t\t train precision: 0.9739,\t\t test precision: 0.9679\n",
            "Epoch: 698,\t loss: 0.001111,\t\t train precision: 0.9766,\t\t test precision: 0.9712\n",
            "Epoch: 699,\t loss: 0.001009,\t\t train precision: 0.9808,\t\t test precision: 0.9736\n",
            "Epoch: 700,\t loss: 0.001006,\t\t train precision: 0.9825,\t\t test precision: 0.9786\n",
            "Epoch: 701,\t loss: 0.00101,\t\t train precision: 0.9838,\t\t test precision: 0.9761\n",
            "Epoch: 702,\t loss: 0.0009409,\t\t train precision: 0.9808,\t\t test precision: 0.9753\n",
            "Epoch: 703,\t loss: 0.00104,\t\t train precision: 0.9804,\t\t test precision: 0.9786\n",
            "Epoch: 704,\t loss: 0.001046,\t\t train precision: 0.9804,\t\t test precision: 0.9786\n",
            "Epoch: 705,\t loss: 0.001065,\t\t train precision: 0.9811,\t\t test precision: 0.9753\n",
            "Epoch: 706,\t loss: 0.001053,\t\t train precision: 0.9749,\t\t test precision: 0.9728\n",
            "Epoch: 707,\t loss: 0.001055,\t\t train precision: 0.9828,\t\t test precision: 0.9745\n",
            "Epoch: 708,\t loss: 0.001037,\t\t train precision: 0.9828,\t\t test precision: 0.9753\n",
            "Epoch: 709,\t loss: 0.001013,\t\t train precision: 0.9814,\t\t test precision: 0.9728\n",
            "Epoch: 710,\t loss: 0.001034,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 711,\t loss: 0.001043,\t\t train precision: 0.9804,\t\t test precision: 0.9778\n",
            "Epoch: 712,\t loss: 0.001022,\t\t train precision: 0.979,\t\t test precision: 0.9736\n",
            "Epoch: 713,\t loss: 0.001084,\t\t train precision: 0.9797,\t\t test precision: 0.9736\n",
            "Epoch: 714,\t loss: 0.00107,\t\t train precision: 0.9811,\t\t test precision: 0.9769\n",
            "Epoch: 715,\t loss: 0.001064,\t\t train precision: 0.9821,\t\t test precision: 0.9745\n",
            "Epoch: 716,\t loss: 0.00108,\t\t train precision: 0.9797,\t\t test precision: 0.9761\n",
            "Epoch: 717,\t loss: 0.0009987,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 718,\t loss: 0.001017,\t\t train precision: 0.9794,\t\t test precision: 0.9753\n",
            "Epoch: 719,\t loss: 0.000949,\t\t train precision: 0.9794,\t\t test precision: 0.9753\n",
            "Epoch: 720,\t loss: 0.00118,\t\t train precision: 0.9729,\t\t test precision: 0.9687\n",
            "Epoch: 721,\t loss: 0.001085,\t\t train precision: 0.9804,\t\t test precision: 0.9728\n",
            "Epoch: 722,\t loss: 0.0009916,\t\t train precision: 0.9794,\t\t test precision: 0.9745\n",
            "Epoch: 723,\t loss: 0.00103,\t\t train precision: 0.9801,\t\t test precision: 0.9778\n",
            "Epoch: 724,\t loss: 0.0009879,\t\t train precision: 0.9811,\t\t test precision: 0.9736\n",
            "Epoch: 725,\t loss: 0.001123,\t\t train precision: 0.9811,\t\t test precision: 0.9761\n",
            "Epoch: 726,\t loss: 0.001079,\t\t train precision: 0.9828,\t\t test precision: 0.9728\n",
            "Epoch: 727,\t loss: 0.001164,\t\t train precision: 0.9787,\t\t test precision: 0.9712\n",
            "Epoch: 728,\t loss: 0.001037,\t\t train precision: 0.9787,\t\t test precision: 0.9745\n",
            "Epoch: 729,\t loss: 0.0009911,\t\t train precision: 0.9811,\t\t test precision: 0.9778\n",
            "Epoch: 730,\t loss: 0.0009561,\t\t train precision: 0.9766,\t\t test precision: 0.9753\n",
            "Epoch: 731,\t loss: 0.001062,\t\t train precision: 0.9838,\t\t test precision: 0.9745\n",
            "Epoch: 732,\t loss: 0.001016,\t\t train precision: 0.979,\t\t test precision: 0.9728\n",
            "Epoch: 733,\t loss: 0.0009704,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 734,\t loss: 0.0009933,\t\t train precision: 0.9801,\t\t test precision: 0.9761\n",
            "Epoch: 735,\t loss: 0.0009979,\t\t train precision: 0.9804,\t\t test precision: 0.9761\n",
            "Epoch: 736,\t loss: 0.0009553,\t\t train precision: 0.9811,\t\t test precision: 0.9745\n",
            "Epoch: 737,\t loss: 0.0009515,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 738,\t loss: 0.0008978,\t\t train precision: 0.9777,\t\t test precision: 0.9745\n",
            "Epoch: 739,\t loss: 0.001153,\t\t train precision: 0.9821,\t\t test precision: 0.9745\n",
            "Epoch: 740,\t loss: 0.001069,\t\t train precision: 0.9797,\t\t test precision: 0.9736\n",
            "Epoch: 741,\t loss: 0.001037,\t\t train precision: 0.9804,\t\t test precision: 0.9745\n",
            "Epoch: 742,\t loss: 0.001052,\t\t train precision: 0.9801,\t\t test precision: 0.9745\n",
            "Epoch: 743,\t loss: 0.00109,\t\t train precision: 0.9821,\t\t test precision: 0.9753\n",
            "Epoch: 744,\t loss: 0.001025,\t\t train precision: 0.9818,\t\t test precision: 0.9761\n",
            "Epoch: 745,\t loss: 0.0009211,\t\t train precision: 0.9821,\t\t test precision: 0.9728\n",
            "Epoch: 746,\t loss: 0.001035,\t\t train precision: 0.9808,\t\t test precision: 0.9761\n",
            "Epoch: 747,\t loss: 0.0009941,\t\t train precision: 0.9828,\t\t test precision: 0.9761\n",
            "Epoch: 748,\t loss: 0.001008,\t\t train precision: 0.9811,\t\t test precision: 0.9712\n",
            "Epoch: 749,\t loss: 0.001041,\t\t train precision: 0.9759,\t\t test precision: 0.9712\n",
            "Epoch: 750,\t loss: 0.0009882,\t\t train precision: 0.9818,\t\t test precision: 0.9736\n",
            "Epoch: 751,\t loss: 0.0009934,\t\t train precision: 0.9746,\t\t test precision: 0.9703\n",
            "Epoch: 752,\t loss: 0.0009803,\t\t train precision: 0.9735,\t\t test precision: 0.9712\n",
            "Epoch: 753,\t loss: 0.0009092,\t\t train precision: 0.9784,\t\t test precision: 0.9761\n",
            "Epoch: 754,\t loss: 0.001078,\t\t train precision: 0.979,\t\t test precision: 0.9728\n",
            "Epoch: 755,\t loss: 0.0009237,\t\t train precision: 0.9838,\t\t test precision: 0.9761\n",
            "Epoch: 756,\t loss: 0.001035,\t\t train precision: 0.9742,\t\t test precision: 0.9687\n",
            "Epoch: 757,\t loss: 0.001095,\t\t train precision: 0.979,\t\t test precision: 0.9712\n",
            "Epoch: 758,\t loss: 0.001051,\t\t train precision: 0.9766,\t\t test precision: 0.972\n",
            "Epoch: 759,\t loss: 0.001113,\t\t train precision: 0.9801,\t\t test precision: 0.9753\n",
            "Epoch: 760,\t loss: 0.001147,\t\t train precision: 0.9835,\t\t test precision: 0.9753\n",
            "Epoch: 761,\t loss: 0.0009355,\t\t train precision: 0.9787,\t\t test precision: 0.9728\n",
            "Epoch: 762,\t loss: 0.001021,\t\t train precision: 0.9808,\t\t test precision: 0.9786\n",
            "Epoch: 763,\t loss: 0.0009152,\t\t train precision: 0.9814,\t\t test precision: 0.9761\n",
            "Epoch: 764,\t loss: 0.0009726,\t\t train precision: 0.9787,\t\t test precision: 0.972\n",
            "Epoch: 765,\t loss: 0.0009985,\t\t train precision: 0.9801,\t\t test precision: 0.9778\n",
            "Epoch: 766,\t loss: 0.0008984,\t\t train precision: 0.9794,\t\t test precision: 0.9753\n",
            "Epoch: 767,\t loss: 0.001091,\t\t train precision: 0.9749,\t\t test precision: 0.9654\n",
            "Epoch: 768,\t loss: 0.0009014,\t\t train precision: 0.9766,\t\t test precision: 0.972\n",
            "Epoch: 769,\t loss: 0.0009877,\t\t train precision: 0.9797,\t\t test precision: 0.9736\n",
            "Epoch: 770,\t loss: 0.001079,\t\t train precision: 0.9811,\t\t test precision: 0.9753\n",
            "Epoch: 771,\t loss: 0.001055,\t\t train precision: 0.9729,\t\t test precision: 0.9728\n",
            "Epoch: 772,\t loss: 0.0009906,\t\t train precision: 0.9814,\t\t test precision: 0.9786\n",
            "Epoch: 773,\t loss: 0.0009821,\t\t train precision: 0.9808,\t\t test precision: 0.9753\n",
            "Epoch: 774,\t loss: 0.001102,\t\t train precision: 0.9787,\t\t test precision: 0.9687\n",
            "Epoch: 775,\t loss: 0.001011,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 776,\t loss: 0.001014,\t\t train precision: 0.9804,\t\t test precision: 0.9761\n",
            "Epoch: 777,\t loss: 0.001038,\t\t train precision: 0.9794,\t\t test precision: 0.972\n",
            "Epoch: 778,\t loss: 0.001026,\t\t train precision: 0.9814,\t\t test precision: 0.9761\n",
            "Epoch: 779,\t loss: 0.0009836,\t\t train precision: 0.9801,\t\t test precision: 0.9736\n",
            "Epoch: 780,\t loss: 0.0009655,\t\t train precision: 0.9821,\t\t test precision: 0.9778\n",
            "Epoch: 781,\t loss: 0.001079,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 782,\t loss: 0.001015,\t\t train precision: 0.9797,\t\t test precision: 0.9736\n",
            "Epoch: 783,\t loss: 0.000978,\t\t train precision: 0.9845,\t\t test precision: 0.9786\n",
            "Epoch: 784,\t loss: 0.0009831,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 785,\t loss: 0.0009741,\t\t train precision: 0.9797,\t\t test precision: 0.9745\n",
            "Epoch: 786,\t loss: 0.0009884,\t\t train precision: 0.9832,\t\t test precision: 0.9753\n",
            "Epoch: 787,\t loss: 0.0009561,\t\t train precision: 0.9828,\t\t test precision: 0.9778\n",
            "Epoch: 788,\t loss: 0.0009799,\t\t train precision: 0.9825,\t\t test precision: 0.9728\n",
            "Epoch: 789,\t loss: 0.0009744,\t\t train precision: 0.9773,\t\t test precision: 0.9654\n",
            "Epoch: 790,\t loss: 0.0009967,\t\t train precision: 0.9797,\t\t test precision: 0.9695\n",
            "Epoch: 791,\t loss: 0.0009751,\t\t train precision: 0.9787,\t\t test precision: 0.9712\n",
            "Epoch: 792,\t loss: 0.001037,\t\t train precision: 0.9808,\t\t test precision: 0.9761\n",
            "Epoch: 793,\t loss: 0.0009826,\t\t train precision: 0.9821,\t\t test precision: 0.9769\n",
            "Epoch: 794,\t loss: 0.00104,\t\t train precision: 0.9801,\t\t test precision: 0.9736\n",
            "Epoch: 795,\t loss: 0.0009637,\t\t train precision: 0.9818,\t\t test precision: 0.9745\n",
            "Epoch: 796,\t loss: 0.001004,\t\t train precision: 0.9811,\t\t test precision: 0.9728\n",
            "Epoch: 797,\t loss: 0.0009717,\t\t train precision: 0.9777,\t\t test precision: 0.9703\n",
            "Epoch: 798,\t loss: 0.001004,\t\t train precision: 0.9756,\t\t test precision: 0.9712\n",
            "Epoch: 799,\t loss: 0.0009679,\t\t train precision: 0.979,\t\t test precision: 0.9703\n",
            "Epoch: 800,\t loss: 0.001058,\t\t train precision: 0.9749,\t\t test precision: 0.9703\n",
            "Epoch: 801,\t loss: 0.001019,\t\t train precision: 0.9814,\t\t test precision: 0.9736\n",
            "Epoch: 802,\t loss: 0.0009761,\t\t train precision: 0.9808,\t\t test precision: 0.9712\n",
            "Epoch: 803,\t loss: 0.0009403,\t\t train precision: 0.9797,\t\t test precision: 0.972\n",
            "Epoch: 804,\t loss: 0.0009613,\t\t train precision: 0.9773,\t\t test precision: 0.9761\n",
            "Epoch: 805,\t loss: 0.0009229,\t\t train precision: 0.9794,\t\t test precision: 0.9736\n",
            "Epoch: 806,\t loss: 0.0009316,\t\t train precision: 0.979,\t\t test precision: 0.9703\n",
            "Epoch: 807,\t loss: 0.001062,\t\t train precision: 0.9804,\t\t test precision: 0.9753\n",
            "Epoch: 808,\t loss: 0.0009586,\t\t train precision: 0.9811,\t\t test precision: 0.972\n",
            "Epoch: 809,\t loss: 0.0009992,\t\t train precision: 0.979,\t\t test precision: 0.972\n",
            "Epoch: 810,\t loss: 0.001011,\t\t train precision: 0.9794,\t\t test precision: 0.9712\n",
            "Epoch: 811,\t loss: 0.0009826,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 812,\t loss: 0.0009623,\t\t train precision: 0.9821,\t\t test precision: 0.9736\n",
            "Epoch: 813,\t loss: 0.0009988,\t\t train precision: 0.9825,\t\t test precision: 0.9769\n",
            "Epoch: 814,\t loss: 0.0009791,\t\t train precision: 0.9804,\t\t test precision: 0.9728\n",
            "Epoch: 815,\t loss: 0.001055,\t\t train precision: 0.9828,\t\t test precision: 0.9712\n",
            "Epoch: 816,\t loss: 0.0009991,\t\t train precision: 0.9801,\t\t test precision: 0.972\n",
            "Epoch: 817,\t loss: 0.0009402,\t\t train precision: 0.9808,\t\t test precision: 0.9761\n",
            "Epoch: 818,\t loss: 0.001071,\t\t train precision: 0.9814,\t\t test precision: 0.972\n",
            "Epoch: 819,\t loss: 0.001021,\t\t train precision: 0.9797,\t\t test precision: 0.9736\n",
            "Epoch: 820,\t loss: 0.0009848,\t\t train precision: 0.9797,\t\t test precision: 0.9703\n",
            "Epoch: 821,\t loss: 0.0009301,\t\t train precision: 0.9808,\t\t test precision: 0.9761\n",
            "Epoch: 822,\t loss: 0.0009835,\t\t train precision: 0.9777,\t\t test precision: 0.9703\n",
            "Epoch: 823,\t loss: 0.0009017,\t\t train precision: 0.9787,\t\t test precision: 0.9695\n",
            "Epoch: 824,\t loss: 0.001151,\t\t train precision: 0.9715,\t\t test precision: 0.9679\n",
            "Epoch: 825,\t loss: 0.001055,\t\t train precision: 0.9818,\t\t test precision: 0.9745\n",
            "Epoch: 826,\t loss: 0.0009926,\t\t train precision: 0.977,\t\t test precision: 0.9728\n",
            "Epoch: 827,\t loss: 0.0009847,\t\t train precision: 0.9821,\t\t test precision: 0.9753\n",
            "Epoch: 828,\t loss: 0.001003,\t\t train precision: 0.9735,\t\t test precision: 0.9703\n",
            "Epoch: 829,\t loss: 0.0009809,\t\t train precision: 0.9808,\t\t test precision: 0.9778\n",
            "Epoch: 830,\t loss: 0.001087,\t\t train precision: 0.9808,\t\t test precision: 0.9736\n",
            "Epoch: 831,\t loss: 0.0009474,\t\t train precision: 0.9801,\t\t test precision: 0.9745\n",
            "Epoch: 832,\t loss: 0.0009271,\t\t train precision: 0.9818,\t\t test precision: 0.9745\n",
            "Epoch: 833,\t loss: 0.001023,\t\t train precision: 0.977,\t\t test precision: 0.9662\n",
            "Epoch: 834,\t loss: 0.001037,\t\t train precision: 0.9773,\t\t test precision: 0.9703\n",
            "Epoch: 835,\t loss: 0.001148,\t\t train precision: 0.9832,\t\t test precision: 0.9728\n",
            "Epoch: 836,\t loss: 0.001016,\t\t train precision: 0.9784,\t\t test precision: 0.9712\n",
            "Epoch: 837,\t loss: 0.001116,\t\t train precision: 0.9818,\t\t test precision: 0.9745\n",
            "Epoch: 838,\t loss: 0.0009465,\t\t train precision: 0.9811,\t\t test precision: 0.9753\n",
            "Epoch: 839,\t loss: 0.001045,\t\t train precision: 0.977,\t\t test precision: 0.9687\n",
            "Epoch: 840,\t loss: 0.0009462,\t\t train precision: 0.9832,\t\t test precision: 0.9736\n",
            "Epoch: 841,\t loss: 0.0008884,\t\t train precision: 0.9825,\t\t test precision: 0.9778\n",
            "Epoch: 842,\t loss: 0.0008945,\t\t train precision: 0.9808,\t\t test precision: 0.9745\n",
            "Epoch: 843,\t loss: 0.0009498,\t\t train precision: 0.9811,\t\t test precision: 0.9745\n",
            "Epoch: 844,\t loss: 0.0009232,\t\t train precision: 0.9825,\t\t test precision: 0.9786\n",
            "Epoch: 845,\t loss: 0.0009557,\t\t train precision: 0.9804,\t\t test precision: 0.9712\n",
            "Epoch: 846,\t loss: 0.001012,\t\t train precision: 0.977,\t\t test precision: 0.9712\n",
            "Epoch: 847,\t loss: 0.001016,\t\t train precision: 0.979,\t\t test precision: 0.9736\n",
            "Epoch: 848,\t loss: 0.001031,\t\t train precision: 0.9777,\t\t test precision: 0.9794\n",
            "Epoch: 849,\t loss: 0.001049,\t\t train precision: 0.979,\t\t test precision: 0.9687\n",
            "Epoch: 850,\t loss: 0.0009707,\t\t train precision: 0.9777,\t\t test precision: 0.9712\n",
            "Epoch: 851,\t loss: 0.001048,\t\t train precision: 0.9808,\t\t test precision: 0.9736\n",
            "Epoch: 852,\t loss: 0.0009804,\t\t train precision: 0.9777,\t\t test precision: 0.9695\n",
            "Epoch: 853,\t loss: 0.0009798,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 854,\t loss: 0.001021,\t\t train precision: 0.9794,\t\t test precision: 0.972\n",
            "Epoch: 855,\t loss: 0.0009326,\t\t train precision: 0.9801,\t\t test precision: 0.9761\n",
            "Epoch: 856,\t loss: 0.0009939,\t\t train precision: 0.9797,\t\t test precision: 0.972\n",
            "Epoch: 857,\t loss: 0.0009796,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 858,\t loss: 0.0009737,\t\t train precision: 0.9804,\t\t test precision: 0.9745\n",
            "Epoch: 859,\t loss: 0.0009437,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 860,\t loss: 0.0009296,\t\t train precision: 0.9773,\t\t test precision: 0.9753\n",
            "Epoch: 861,\t loss: 0.001039,\t\t train precision: 0.9821,\t\t test precision: 0.9712\n",
            "Epoch: 862,\t loss: 0.0009793,\t\t train precision: 0.9784,\t\t test precision: 0.9712\n",
            "Epoch: 863,\t loss: 0.00102,\t\t train precision: 0.9804,\t\t test precision: 0.9736\n",
            "Epoch: 864,\t loss: 0.0009369,\t\t train precision: 0.9842,\t\t test precision: 0.9745\n",
            "Epoch: 865,\t loss: 0.001026,\t\t train precision: 0.9804,\t\t test precision: 0.972\n",
            "Epoch: 866,\t loss: 0.0009734,\t\t train precision: 0.9838,\t\t test precision: 0.9778\n",
            "Epoch: 867,\t loss: 0.0009422,\t\t train precision: 0.9808,\t\t test precision: 0.9736\n",
            "Epoch: 868,\t loss: 0.001021,\t\t train precision: 0.9801,\t\t test precision: 0.9712\n",
            "Epoch: 869,\t loss: 0.00111,\t\t train precision: 0.9794,\t\t test precision: 0.9745\n",
            "Epoch: 870,\t loss: 0.0009728,\t\t train precision: 0.9814,\t\t test precision: 0.972\n",
            "Epoch: 871,\t loss: 0.001022,\t\t train precision: 0.9804,\t\t test precision: 0.9712\n",
            "Epoch: 872,\t loss: 0.0009853,\t\t train precision: 0.9814,\t\t test precision: 0.9753\n",
            "Epoch: 873,\t loss: 0.0009477,\t\t train precision: 0.9763,\t\t test precision: 0.9695\n",
            "Epoch: 874,\t loss: 0.001011,\t\t train precision: 0.9825,\t\t test precision: 0.9761\n",
            "Epoch: 875,\t loss: 0.0009456,\t\t train precision: 0.9835,\t\t test precision: 0.9736\n",
            "Epoch: 876,\t loss: 0.001029,\t\t train precision: 0.9804,\t\t test precision: 0.9778\n",
            "Epoch: 877,\t loss: 0.0009105,\t\t train precision: 0.9784,\t\t test precision: 0.9778\n",
            "Epoch: 878,\t loss: 0.0009948,\t\t train precision: 0.9814,\t\t test precision: 0.972\n",
            "Epoch: 879,\t loss: 0.0009256,\t\t train precision: 0.9828,\t\t test precision: 0.9778\n",
            "Epoch: 880,\t loss: 0.0009044,\t\t train precision: 0.9811,\t\t test precision: 0.9728\n",
            "Epoch: 881,\t loss: 0.0009482,\t\t train precision: 0.9797,\t\t test precision: 0.9728\n",
            "Epoch: 882,\t loss: 0.0009486,\t\t train precision: 0.9794,\t\t test precision: 0.9728\n",
            "Epoch: 883,\t loss: 0.0009018,\t\t train precision: 0.9818,\t\t test precision: 0.9736\n",
            "Epoch: 884,\t loss: 0.0009407,\t\t train precision: 0.9811,\t\t test precision: 0.9753\n",
            "Epoch: 885,\t loss: 0.0009985,\t\t train precision: 0.9821,\t\t test precision: 0.9728\n",
            "Epoch: 886,\t loss: 0.0009431,\t\t train precision: 0.9814,\t\t test precision: 0.9753\n",
            "Epoch: 887,\t loss: 0.0009675,\t\t train precision: 0.9838,\t\t test precision: 0.9778\n",
            "Epoch: 888,\t loss: 0.0009928,\t\t train precision: 0.9787,\t\t test precision: 0.9736\n",
            "Epoch: 889,\t loss: 0.001083,\t\t train precision: 0.9797,\t\t test precision: 0.9753\n",
            "Epoch: 890,\t loss: 0.00104,\t\t train precision: 0.9818,\t\t test precision: 0.9736\n",
            "Epoch: 891,\t loss: 0.0009414,\t\t train precision: 0.9777,\t\t test precision: 0.9703\n",
            "Epoch: 892,\t loss: 0.0009656,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 893,\t loss: 0.0009646,\t\t train precision: 0.977,\t\t test precision: 0.972\n",
            "Epoch: 894,\t loss: 0.0009602,\t\t train precision: 0.9814,\t\t test precision: 0.9753\n",
            "Epoch: 895,\t loss: 0.0008888,\t\t train precision: 0.9814,\t\t test precision: 0.9728\n",
            "Epoch: 896,\t loss: 0.0009117,\t\t train precision: 0.9814,\t\t test precision: 0.9753\n",
            "Epoch: 897,\t loss: 0.0009726,\t\t train precision: 0.9825,\t\t test precision: 0.9778\n",
            "Epoch: 898,\t loss: 0.0009757,\t\t train precision: 0.9825,\t\t test precision: 0.9745\n",
            "Epoch: 899,\t loss: 0.001034,\t\t train precision: 0.9849,\t\t test precision: 0.9769\n",
            "Epoch: 900,\t loss: 0.001036,\t\t train precision: 0.9742,\t\t test precision: 0.9687\n",
            "Epoch: 901,\t loss: 0.0009699,\t\t train precision: 0.9766,\t\t test precision: 0.9736\n",
            "Epoch: 902,\t loss: 0.001051,\t\t train precision: 0.9821,\t\t test precision: 0.9778\n",
            "Epoch: 903,\t loss: 0.001038,\t\t train precision: 0.9766,\t\t test precision: 0.9736\n",
            "Epoch: 904,\t loss: 0.0009722,\t\t train precision: 0.9801,\t\t test precision: 0.9728\n",
            "Epoch: 905,\t loss: 0.0009819,\t\t train precision: 0.9777,\t\t test precision: 0.9695\n",
            "Epoch: 906,\t loss: 0.0008964,\t\t train precision: 0.9801,\t\t test precision: 0.9736\n",
            "Epoch: 907,\t loss: 0.0009124,\t\t train precision: 0.9828,\t\t test precision: 0.9778\n",
            "Epoch: 908,\t loss: 0.0009806,\t\t train precision: 0.979,\t\t test precision: 0.9745\n",
            "Epoch: 909,\t loss: 0.0009957,\t\t train precision: 0.9797,\t\t test precision: 0.9802\n",
            "Epoch: 910,\t loss: 0.0009552,\t\t train precision: 0.978,\t\t test precision: 0.9712\n",
            "Epoch: 911,\t loss: 0.0008583,\t\t train precision: 0.9818,\t\t test precision: 0.972\n",
            "Epoch: 912,\t loss: 0.0008747,\t\t train precision: 0.9801,\t\t test precision: 0.972\n",
            "Epoch: 913,\t loss: 0.0009705,\t\t train precision: 0.9804,\t\t test precision: 0.9778\n",
            "Epoch: 914,\t loss: 0.001115,\t\t train precision: 0.9797,\t\t test precision: 0.9687\n",
            "Epoch: 915,\t loss: 0.0009939,\t\t train precision: 0.9804,\t\t test precision: 0.9712\n",
            "Epoch: 916,\t loss: 0.0009538,\t\t train precision: 0.9828,\t\t test precision: 0.972\n",
            "Epoch: 917,\t loss: 0.0009929,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 918,\t loss: 0.000989,\t\t train precision: 0.978,\t\t test precision: 0.972\n",
            "Epoch: 919,\t loss: 0.001012,\t\t train precision: 0.9801,\t\t test precision: 0.9695\n",
            "Epoch: 920,\t loss: 0.001016,\t\t train precision: 0.9801,\t\t test precision: 0.9786\n",
            "Epoch: 921,\t loss: 0.0009797,\t\t train precision: 0.9784,\t\t test precision: 0.9761\n",
            "Epoch: 922,\t loss: 0.001007,\t\t train precision: 0.9797,\t\t test precision: 0.9712\n",
            "Epoch: 923,\t loss: 0.0008994,\t\t train precision: 0.9818,\t\t test precision: 0.9728\n",
            "Epoch: 924,\t loss: 0.0009159,\t\t train precision: 0.9804,\t\t test precision: 0.9736\n",
            "Epoch: 925,\t loss: 0.001033,\t\t train precision: 0.9801,\t\t test precision: 0.9753\n",
            "Epoch: 926,\t loss: 0.0009013,\t\t train precision: 0.9838,\t\t test precision: 0.9786\n",
            "Epoch: 927,\t loss: 0.0008924,\t\t train precision: 0.9821,\t\t test precision: 0.9736\n",
            "Epoch: 928,\t loss: 0.001034,\t\t train precision: 0.9794,\t\t test precision: 0.9728\n",
            "Epoch: 929,\t loss: 0.001014,\t\t train precision: 0.9828,\t\t test precision: 0.9745\n",
            "Epoch: 930,\t loss: 0.001018,\t\t train precision: 0.9784,\t\t test precision: 0.9745\n",
            "Epoch: 931,\t loss: 0.00106,\t\t train precision: 0.9801,\t\t test precision: 0.9753\n",
            "Epoch: 932,\t loss: 0.0009417,\t\t train precision: 0.9787,\t\t test precision: 0.9712\n",
            "Epoch: 933,\t loss: 0.0009398,\t\t train precision: 0.9811,\t\t test precision: 0.9745\n",
            "Epoch: 934,\t loss: 0.0009309,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 935,\t loss: 0.0009787,\t\t train precision: 0.9797,\t\t test precision: 0.9728\n",
            "Epoch: 936,\t loss: 0.0009795,\t\t train precision: 0.9756,\t\t test precision: 0.9703\n",
            "Epoch: 937,\t loss: 0.000907,\t\t train precision: 0.9808,\t\t test precision: 0.9769\n",
            "Epoch: 938,\t loss: 0.0009183,\t\t train precision: 0.9811,\t\t test precision: 0.9703\n",
            "Epoch: 939,\t loss: 0.0009942,\t\t train precision: 0.979,\t\t test precision: 0.9728\n",
            "Epoch: 940,\t loss: 0.0009549,\t\t train precision: 0.9811,\t\t test precision: 0.9778\n",
            "Epoch: 941,\t loss: 0.0009838,\t\t train precision: 0.9821,\t\t test precision: 0.9769\n",
            "Epoch: 942,\t loss: 0.0009067,\t\t train precision: 0.978,\t\t test precision: 0.9712\n",
            "Epoch: 943,\t loss: 0.001023,\t\t train precision: 0.9825,\t\t test precision: 0.9786\n",
            "Epoch: 944,\t loss: 0.001085,\t\t train precision: 0.9832,\t\t test precision: 0.9769\n",
            "Epoch: 945,\t loss: 0.0009824,\t\t train precision: 0.9787,\t\t test precision: 0.9753\n",
            "Epoch: 946,\t loss: 0.0009503,\t\t train precision: 0.9825,\t\t test precision: 0.9769\n",
            "Epoch: 947,\t loss: 0.0008942,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 948,\t loss: 0.0009039,\t\t train precision: 0.9838,\t\t test precision: 0.9769\n",
            "Epoch: 949,\t loss: 0.0009089,\t\t train precision: 0.9811,\t\t test precision: 0.972\n",
            "Epoch: 950,\t loss: 0.0009042,\t\t train precision: 0.9814,\t\t test precision: 0.9761\n",
            "Epoch: 951,\t loss: 0.001018,\t\t train precision: 0.9832,\t\t test precision: 0.9753\n",
            "Epoch: 952,\t loss: 0.0009145,\t\t train precision: 0.9794,\t\t test precision: 0.9712\n",
            "Epoch: 953,\t loss: 0.0009292,\t\t train precision: 0.9787,\t\t test precision: 0.9695\n",
            "Epoch: 954,\t loss: 0.0009071,\t\t train precision: 0.9804,\t\t test precision: 0.9761\n",
            "Epoch: 955,\t loss: 0.0008757,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 956,\t loss: 0.0009821,\t\t train precision: 0.9804,\t\t test precision: 0.9712\n",
            "Epoch: 957,\t loss: 0.0008462,\t\t train precision: 0.9797,\t\t test precision: 0.9712\n",
            "Epoch: 958,\t loss: 0.0008649,\t\t train precision: 0.9849,\t\t test precision: 0.9745\n",
            "Epoch: 959,\t loss: 0.0008939,\t\t train precision: 0.9797,\t\t test precision: 0.9712\n",
            "Epoch: 960,\t loss: 0.0008883,\t\t train precision: 0.979,\t\t test precision: 0.9736\n",
            "Epoch: 961,\t loss: 0.001041,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 962,\t loss: 0.001001,\t\t train precision: 0.9832,\t\t test precision: 0.9736\n",
            "Epoch: 963,\t loss: 0.0009692,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 964,\t loss: 0.0009872,\t\t train precision: 0.9825,\t\t test precision: 0.9745\n",
            "Epoch: 965,\t loss: 0.0009027,\t\t train precision: 0.9811,\t\t test precision: 0.9695\n",
            "Epoch: 966,\t loss: 0.001008,\t\t train precision: 0.9818,\t\t test precision: 0.9728\n",
            "Epoch: 967,\t loss: 0.0009587,\t\t train precision: 0.9818,\t\t test precision: 0.9736\n",
            "Epoch: 968,\t loss: 0.0009119,\t\t train precision: 0.9814,\t\t test precision: 0.9736\n",
            "Epoch: 969,\t loss: 0.0008723,\t\t train precision: 0.9766,\t\t test precision: 0.9679\n",
            "Epoch: 970,\t loss: 0.0008853,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 971,\t loss: 0.0009718,\t\t train precision: 0.9811,\t\t test precision: 0.9736\n",
            "Epoch: 972,\t loss: 0.0009352,\t\t train precision: 0.9801,\t\t test precision: 0.972\n",
            "Epoch: 973,\t loss: 0.001015,\t\t train precision: 0.9818,\t\t test precision: 0.9761\n",
            "Epoch: 974,\t loss: 0.000977,\t\t train precision: 0.9787,\t\t test precision: 0.9761\n",
            "Epoch: 975,\t loss: 0.001023,\t\t train precision: 0.9818,\t\t test precision: 0.9778\n",
            "Epoch: 976,\t loss: 0.00104,\t\t train precision: 0.9797,\t\t test precision: 0.9712\n",
            "Epoch: 977,\t loss: 0.001125,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 978,\t loss: 0.0009872,\t\t train precision: 0.9808,\t\t test precision: 0.9778\n",
            "Epoch: 979,\t loss: 0.00095,\t\t train precision: 0.9801,\t\t test precision: 0.9736\n",
            "Epoch: 980,\t loss: 0.0009766,\t\t train precision: 0.9838,\t\t test precision: 0.9753\n",
            "Epoch: 981,\t loss: 0.0009455,\t\t train precision: 0.9763,\t\t test precision: 0.9728\n",
            "Epoch: 982,\t loss: 0.0008931,\t\t train precision: 0.9808,\t\t test precision: 0.9753\n",
            "Epoch: 983,\t loss: 0.0008861,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 984,\t loss: 0.000983,\t\t train precision: 0.9804,\t\t test precision: 0.9753\n",
            "Epoch: 985,\t loss: 0.001009,\t\t train precision: 0.9825,\t\t test precision: 0.9728\n",
            "Epoch: 986,\t loss: 0.0009881,\t\t train precision: 0.9811,\t\t test precision: 0.9761\n",
            "Epoch: 987,\t loss: 0.0009224,\t\t train precision: 0.9825,\t\t test precision: 0.9769\n",
            "Epoch: 988,\t loss: 0.0009979,\t\t train precision: 0.9811,\t\t test precision: 0.9736\n",
            "Epoch: 989,\t loss: 0.0008813,\t\t train precision: 0.9818,\t\t test precision: 0.9728\n",
            "Epoch: 990,\t loss: 0.001119,\t\t train precision: 0.9777,\t\t test precision: 0.9703\n",
            "Epoch: 991,\t loss: 0.000961,\t\t train precision: 0.9828,\t\t test precision: 0.9769\n",
            "Epoch: 992,\t loss: 0.0009734,\t\t train precision: 0.9818,\t\t test precision: 0.9712\n",
            "Epoch: 993,\t loss: 0.0009166,\t\t train precision: 0.9811,\t\t test precision: 0.972\n",
            "Epoch: 994,\t loss: 0.0009585,\t\t train precision: 0.9825,\t\t test precision: 0.9745\n",
            "Epoch: 995,\t loss: 0.0009687,\t\t train precision: 0.9784,\t\t test precision: 0.9695\n",
            "Epoch: 996,\t loss: 0.0009579,\t\t train precision: 0.9777,\t\t test precision: 0.9736\n",
            "Epoch: 997,\t loss: 0.000945,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 998,\t loss: 0.000912,\t\t train precision: 0.9811,\t\t test precision: 0.9736\n",
            "Epoch: 999,\t loss: 0.000927,\t\t train precision: 0.9818,\t\t test precision: 0.9778\n",
            "Epoch: 1000,\t loss: 0.0009057,\t\t train precision: 0.9804,\t\t test precision: 0.972\n",
            "Epoch: 1001,\t loss: 0.001012,\t\t train precision: 0.9811,\t\t test precision: 0.972\n",
            "Epoch: 1002,\t loss: 0.0009204,\t\t train precision: 0.9814,\t\t test precision: 0.9769\n",
            "Epoch: 1003,\t loss: 0.0008429,\t\t train precision: 0.9811,\t\t test precision: 0.972\n",
            "Epoch: 1004,\t loss: 0.0008867,\t\t train precision: 0.9832,\t\t test precision: 0.9736\n",
            "Epoch: 1005,\t loss: 0.0009835,\t\t train precision: 0.9794,\t\t test precision: 0.9703\n",
            "Epoch: 1006,\t loss: 0.0009707,\t\t train precision: 0.9797,\t\t test precision: 0.9728\n",
            "Epoch: 1007,\t loss: 0.00089,\t\t train precision: 0.9835,\t\t test precision: 0.9728\n",
            "Epoch: 1008,\t loss: 0.0009549,\t\t train precision: 0.978,\t\t test precision: 0.9728\n",
            "Epoch: 1009,\t loss: 0.001038,\t\t train precision: 0.979,\t\t test precision: 0.9695\n",
            "Epoch: 1010,\t loss: 0.0009242,\t\t train precision: 0.9797,\t\t test precision: 0.9761\n",
            "Epoch: 1011,\t loss: 0.0009293,\t\t train precision: 0.9814,\t\t test precision: 0.9761\n",
            "Epoch: 1012,\t loss: 0.0009068,\t\t train precision: 0.9801,\t\t test precision: 0.9761\n",
            "Epoch: 1013,\t loss: 0.0009652,\t\t train precision: 0.9842,\t\t test precision: 0.9769\n",
            "Epoch: 1014,\t loss: 0.0009518,\t\t train precision: 0.9818,\t\t test precision: 0.9778\n",
            "Epoch: 1015,\t loss: 0.0009169,\t\t train precision: 0.9804,\t\t test precision: 0.9761\n",
            "Epoch: 1016,\t loss: 0.0009004,\t\t train precision: 0.9773,\t\t test precision: 0.9736\n",
            "Epoch: 1017,\t loss: 0.001004,\t\t train precision: 0.9787,\t\t test precision: 0.9753\n",
            "Epoch: 1018,\t loss: 0.001008,\t\t train precision: 0.9825,\t\t test precision: 0.9728\n",
            "Epoch: 1019,\t loss: 0.0009906,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 1020,\t loss: 0.0009153,\t\t train precision: 0.9784,\t\t test precision: 0.9679\n",
            "Epoch: 1021,\t loss: 0.0009366,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 1022,\t loss: 0.0008663,\t\t train precision: 0.9787,\t\t test precision: 0.9712\n",
            "Epoch: 1023,\t loss: 0.001037,\t\t train precision: 0.9808,\t\t test precision: 0.9736\n",
            "Epoch: 1024,\t loss: 0.0009067,\t\t train precision: 0.9808,\t\t test precision: 0.9736\n",
            "Epoch: 1025,\t loss: 0.0009652,\t\t train precision: 0.977,\t\t test precision: 0.9703\n",
            "Epoch: 1026,\t loss: 0.001015,\t\t train precision: 0.9821,\t\t test precision: 0.9728\n",
            "Epoch: 1027,\t loss: 0.001028,\t\t train precision: 0.9784,\t\t test precision: 0.972\n",
            "Epoch: 1028,\t loss: 0.0009388,\t\t train precision: 0.9818,\t\t test precision: 0.9769\n",
            "Epoch: 1029,\t loss: 0.0009635,\t\t train precision: 0.9777,\t\t test precision: 0.972\n",
            "Epoch: 1030,\t loss: 0.0009326,\t\t train precision: 0.9825,\t\t test precision: 0.9736\n",
            "Epoch: 1031,\t loss: 0.0008735,\t\t train precision: 0.9828,\t\t test precision: 0.9761\n",
            "Epoch: 1032,\t loss: 0.000942,\t\t train precision: 0.9845,\t\t test precision: 0.9778\n",
            "Epoch: 1033,\t loss: 0.0009219,\t\t train precision: 0.9811,\t\t test precision: 0.9736\n",
            "Epoch: 1034,\t loss: 0.001001,\t\t train precision: 0.9808,\t\t test precision: 0.9745\n",
            "Epoch: 1035,\t loss: 0.0009071,\t\t train precision: 0.9811,\t\t test precision: 0.9753\n",
            "Epoch: 1036,\t loss: 0.0009203,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 1037,\t loss: 0.0008084,\t\t train precision: 0.9828,\t\t test precision: 0.9736\n",
            "Epoch: 1038,\t loss: 0.0009964,\t\t train precision: 0.9759,\t\t test precision: 0.9695\n",
            "Epoch: 1039,\t loss: 0.0009763,\t\t train precision: 0.979,\t\t test precision: 0.9728\n",
            "Epoch: 1040,\t loss: 0.0008736,\t\t train precision: 0.9794,\t\t test precision: 0.9753\n",
            "Epoch: 1041,\t loss: 0.0009605,\t\t train precision: 0.978,\t\t test precision: 0.9753\n",
            "Epoch: 1042,\t loss: 0.0008843,\t\t train precision: 0.9797,\t\t test precision: 0.9728\n",
            "Epoch: 1043,\t loss: 0.0009217,\t\t train precision: 0.9825,\t\t test precision: 0.9761\n",
            "Epoch: 1044,\t loss: 0.0009018,\t\t train precision: 0.9828,\t\t test precision: 0.9728\n",
            "Epoch: 1045,\t loss: 0.0009928,\t\t train precision: 0.9814,\t\t test precision: 0.9761\n",
            "Epoch: 1046,\t loss: 0.000949,\t\t train precision: 0.9808,\t\t test precision: 0.9753\n",
            "Epoch: 1047,\t loss: 0.00106,\t\t train precision: 0.9842,\t\t test precision: 0.9761\n",
            "Epoch: 1048,\t loss: 0.000883,\t\t train precision: 0.979,\t\t test precision: 0.9728\n",
            "Epoch: 1049,\t loss: 0.000964,\t\t train precision: 0.9801,\t\t test precision: 0.9736\n",
            "Epoch: 1050,\t loss: 0.0009405,\t\t train precision: 0.9808,\t\t test precision: 0.9753\n",
            "Epoch: 1051,\t loss: 0.0009404,\t\t train precision: 0.9825,\t\t test precision: 0.9736\n",
            "Epoch: 1052,\t loss: 0.0009886,\t\t train precision: 0.9818,\t\t test precision: 0.9769\n",
            "Epoch: 1053,\t loss: 0.000948,\t\t train precision: 0.9821,\t\t test precision: 0.972\n",
            "Epoch: 1054,\t loss: 0.0008624,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 1055,\t loss: 0.0008935,\t\t train precision: 0.9808,\t\t test precision: 0.9695\n",
            "Epoch: 1056,\t loss: 0.0008803,\t\t train precision: 0.9832,\t\t test precision: 0.9753\n",
            "Epoch: 1057,\t loss: 0.0009301,\t\t train precision: 0.9794,\t\t test precision: 0.9728\n",
            "Epoch: 1058,\t loss: 0.001047,\t\t train precision: 0.978,\t\t test precision: 0.972\n",
            "Epoch: 1059,\t loss: 0.0009532,\t\t train precision: 0.978,\t\t test precision: 0.9745\n",
            "Epoch: 1060,\t loss: 0.0008364,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 1061,\t loss: 0.00096,\t\t train precision: 0.9804,\t\t test precision: 0.9745\n",
            "Epoch: 1062,\t loss: 0.0009193,\t\t train precision: 0.9811,\t\t test precision: 0.9712\n",
            "Epoch: 1063,\t loss: 0.0009244,\t\t train precision: 0.9804,\t\t test precision: 0.972\n",
            "Epoch: 1064,\t loss: 0.0009623,\t\t train precision: 0.9801,\t\t test precision: 0.9736\n",
            "Epoch: 1065,\t loss: 0.001121,\t\t train precision: 0.9811,\t\t test precision: 0.9753\n",
            "Epoch: 1066,\t loss: 0.0008888,\t\t train precision: 0.9804,\t\t test precision: 0.9761\n",
            "Epoch: 1067,\t loss: 0.0009169,\t\t train precision: 0.9811,\t\t test precision: 0.9703\n",
            "Epoch: 1068,\t loss: 0.0009248,\t\t train precision: 0.9821,\t\t test precision: 0.9753\n",
            "Epoch: 1069,\t loss: 0.0009426,\t\t train precision: 0.9804,\t\t test precision: 0.9712\n",
            "Epoch: 1070,\t loss: 0.0009924,\t\t train precision: 0.9828,\t\t test precision: 0.9769\n",
            "Epoch: 1071,\t loss: 0.000912,\t\t train precision: 0.9804,\t\t test precision: 0.9728\n",
            "Epoch: 1072,\t loss: 0.001002,\t\t train precision: 0.9784,\t\t test precision: 0.972\n",
            "Epoch: 1073,\t loss: 0.0008778,\t\t train precision: 0.9804,\t\t test precision: 0.9786\n",
            "Epoch: 1074,\t loss: 0.0008712,\t\t train precision: 0.9842,\t\t test precision: 0.9745\n",
            "Epoch: 1075,\t loss: 0.0008388,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 1076,\t loss: 0.0008807,\t\t train precision: 0.979,\t\t test precision: 0.9736\n",
            "Epoch: 1077,\t loss: 0.0009806,\t\t train precision: 0.9808,\t\t test precision: 0.9745\n",
            "Epoch: 1078,\t loss: 0.001011,\t\t train precision: 0.9828,\t\t test precision: 0.9753\n",
            "Epoch: 1079,\t loss: 0.001007,\t\t train precision: 0.9801,\t\t test precision: 0.9794\n",
            "Epoch: 1080,\t loss: 0.0009075,\t\t train precision: 0.9777,\t\t test precision: 0.9736\n",
            "Epoch: 1081,\t loss: 0.0009611,\t\t train precision: 0.9811,\t\t test precision: 0.9703\n",
            "Epoch: 1082,\t loss: 0.0008682,\t\t train precision: 0.9808,\t\t test precision: 0.9728\n",
            "Epoch: 1083,\t loss: 0.0008562,\t\t train precision: 0.9804,\t\t test precision: 0.9712\n",
            "Epoch: 1084,\t loss: 0.0008551,\t\t train precision: 0.9794,\t\t test precision: 0.9753\n",
            "Epoch: 1085,\t loss: 0.0008849,\t\t train precision: 0.9842,\t\t test precision: 0.9753\n",
            "Epoch: 1086,\t loss: 0.0009295,\t\t train precision: 0.9804,\t\t test precision: 0.9753\n",
            "Epoch: 1087,\t loss: 0.0009658,\t\t train precision: 0.9828,\t\t test precision: 0.9769\n",
            "Epoch: 1088,\t loss: 0.0008958,\t\t train precision: 0.9794,\t\t test precision: 0.9703\n",
            "Epoch: 1089,\t loss: 0.0009261,\t\t train precision: 0.9777,\t\t test precision: 0.9736\n",
            "Epoch: 1090,\t loss: 0.0009319,\t\t train precision: 0.9838,\t\t test precision: 0.9736\n",
            "Epoch: 1091,\t loss: 0.0009128,\t\t train precision: 0.9797,\t\t test precision: 0.9745\n",
            "Epoch: 1092,\t loss: 0.000919,\t\t train precision: 0.9801,\t\t test precision: 0.9769\n",
            "Epoch: 1093,\t loss: 0.0008923,\t\t train precision: 0.9794,\t\t test precision: 0.9728\n",
            "Epoch: 1094,\t loss: 0.0009356,\t\t train precision: 0.9835,\t\t test precision: 0.9769\n",
            "Epoch: 1095,\t loss: 0.0009389,\t\t train precision: 0.9794,\t\t test precision: 0.9736\n",
            "Epoch: 1096,\t loss: 0.0009649,\t\t train precision: 0.9835,\t\t test precision: 0.9761\n",
            "Epoch: 1097,\t loss: 0.0008537,\t\t train precision: 0.9838,\t\t test precision: 0.9753\n",
            "Epoch: 1098,\t loss: 0.0008663,\t\t train precision: 0.9835,\t\t test precision: 0.9769\n",
            "Epoch: 1099,\t loss: 0.0009081,\t\t train precision: 0.9808,\t\t test precision: 0.972\n",
            "Epoch: 1100,\t loss: 0.0009093,\t\t train precision: 0.9814,\t\t test precision: 0.972\n",
            "Epoch: 1101,\t loss: 0.0009578,\t\t train precision: 0.979,\t\t test precision: 0.9712\n",
            "Epoch: 1102,\t loss: 0.0009586,\t\t train precision: 0.979,\t\t test precision: 0.9736\n",
            "Epoch: 1103,\t loss: 0.0008968,\t\t train precision: 0.9801,\t\t test precision: 0.9728\n",
            "Epoch: 1104,\t loss: 0.0009199,\t\t train precision: 0.9845,\t\t test precision: 0.9769\n",
            "Epoch: 1105,\t loss: 0.0009258,\t\t train precision: 0.9821,\t\t test precision: 0.9736\n",
            "Epoch: 1106,\t loss: 0.0009433,\t\t train precision: 0.9811,\t\t test precision: 0.9745\n",
            "Epoch: 1107,\t loss: 0.0009059,\t\t train precision: 0.9835,\t\t test precision: 0.9769\n",
            "Epoch: 1108,\t loss: 0.00103,\t\t train precision: 0.9811,\t\t test precision: 0.9736\n",
            "Epoch: 1109,\t loss: 0.0009732,\t\t train precision: 0.9814,\t\t test precision: 0.9769\n",
            "Epoch: 1110,\t loss: 0.0008105,\t\t train precision: 0.9797,\t\t test precision: 0.9761\n",
            "Epoch: 1111,\t loss: 0.0009323,\t\t train precision: 0.9811,\t\t test precision: 0.9703\n",
            "Epoch: 1112,\t loss: 0.0008591,\t\t train precision: 0.9828,\t\t test precision: 0.9761\n",
            "Epoch: 1113,\t loss: 0.0008935,\t\t train precision: 0.9811,\t\t test precision: 0.9728\n",
            "Epoch: 1114,\t loss: 0.0008827,\t\t train precision: 0.9825,\t\t test precision: 0.9703\n",
            "Epoch: 1115,\t loss: 0.000846,\t\t train precision: 0.9808,\t\t test precision: 0.9745\n",
            "Epoch: 1116,\t loss: 0.0009833,\t\t train precision: 0.9804,\t\t test precision: 0.9761\n",
            "Epoch: 1117,\t loss: 0.0008282,\t\t train precision: 0.9811,\t\t test precision: 0.9736\n",
            "Epoch: 1118,\t loss: 0.0008835,\t\t train precision: 0.9832,\t\t test precision: 0.9761\n",
            "Epoch: 1119,\t loss: 0.0008775,\t\t train precision: 0.9787,\t\t test precision: 0.9728\n",
            "Epoch: 1120,\t loss: 0.0009926,\t\t train precision: 0.9794,\t\t test precision: 0.9703\n",
            "Epoch: 1121,\t loss: 0.0008985,\t\t train precision: 0.9818,\t\t test precision: 0.9736\n",
            "Epoch: 1122,\t loss: 0.0008591,\t\t train precision: 0.9832,\t\t test precision: 0.9769\n",
            "Epoch: 1123,\t loss: 0.0009087,\t\t train precision: 0.9818,\t\t test precision: 0.9761\n",
            "Epoch: 1124,\t loss: 0.0009659,\t\t train precision: 0.9842,\t\t test precision: 0.972\n",
            "Epoch: 1125,\t loss: 0.000863,\t\t train precision: 0.9828,\t\t test precision: 0.9778\n",
            "Epoch: 1126,\t loss: 0.0009472,\t\t train precision: 0.9804,\t\t test precision: 0.9778\n",
            "Epoch: 1127,\t loss: 0.0009958,\t\t train precision: 0.9838,\t\t test precision: 0.9761\n",
            "Epoch: 1128,\t loss: 0.0009098,\t\t train precision: 0.9804,\t\t test precision: 0.9745\n",
            "Epoch: 1129,\t loss: 0.0009947,\t\t train precision: 0.9801,\t\t test precision: 0.9712\n",
            "Epoch: 1130,\t loss: 0.0008907,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 1131,\t loss: 0.0009166,\t\t train precision: 0.9814,\t\t test precision: 0.9736\n",
            "Epoch: 1132,\t loss: 0.000877,\t\t train precision: 0.9845,\t\t test precision: 0.9761\n",
            "Epoch: 1133,\t loss: 0.0009399,\t\t train precision: 0.9818,\t\t test precision: 0.9728\n",
            "Epoch: 1134,\t loss: 0.0009886,\t\t train precision: 0.9838,\t\t test precision: 0.9761\n",
            "Epoch: 1135,\t loss: 0.0009596,\t\t train precision: 0.9825,\t\t test precision: 0.9769\n",
            "Epoch: 1136,\t loss: 0.0009953,\t\t train precision: 0.9794,\t\t test precision: 0.9745\n",
            "Epoch: 1137,\t loss: 0.0009215,\t\t train precision: 0.9814,\t\t test precision: 0.9728\n",
            "Epoch: 1138,\t loss: 0.0008611,\t\t train precision: 0.9838,\t\t test precision: 0.9778\n",
            "Epoch: 1139,\t loss: 0.0009023,\t\t train precision: 0.9811,\t\t test precision: 0.9769\n",
            "Epoch: 1140,\t loss: 0.0008602,\t\t train precision: 0.9797,\t\t test precision: 0.9703\n",
            "Epoch: 1141,\t loss: 0.001072,\t\t train precision: 0.9784,\t\t test precision: 0.972\n",
            "Epoch: 1142,\t loss: 0.0009099,\t\t train precision: 0.9832,\t\t test precision: 0.9761\n",
            "Epoch: 1143,\t loss: 0.0008858,\t\t train precision: 0.9804,\t\t test precision: 0.9745\n",
            "Epoch: 1144,\t loss: 0.0009039,\t\t train precision: 0.9797,\t\t test precision: 0.9728\n",
            "Epoch: 1145,\t loss: 0.0009291,\t\t train precision: 0.9814,\t\t test precision: 0.9761\n",
            "Epoch: 1146,\t loss: 0.0009488,\t\t train precision: 0.9828,\t\t test precision: 0.9778\n",
            "Epoch: 1147,\t loss: 0.0009619,\t\t train precision: 0.979,\t\t test precision: 0.9712\n",
            "Epoch: 1148,\t loss: 0.0009282,\t\t train precision: 0.9835,\t\t test precision: 0.9778\n",
            "Epoch: 1149,\t loss: 0.0008728,\t\t train precision: 0.979,\t\t test precision: 0.9712\n",
            "Epoch: 1150,\t loss: 0.0009198,\t\t train precision: 0.9832,\t\t test precision: 0.9769\n",
            "Epoch: 1151,\t loss: 0.0008754,\t\t train precision: 0.9838,\t\t test precision: 0.9712\n",
            "Epoch: 1152,\t loss: 0.0009606,\t\t train precision: 0.9708,\t\t test precision: 0.9662\n",
            "Epoch: 1153,\t loss: 0.0009004,\t\t train precision: 0.9821,\t\t test precision: 0.9769\n",
            "Epoch: 1154,\t loss: 0.0008833,\t\t train precision: 0.9814,\t\t test precision: 0.9736\n",
            "Epoch: 1155,\t loss: 0.0008516,\t\t train precision: 0.9808,\t\t test precision: 0.9728\n",
            "Epoch: 1156,\t loss: 0.001003,\t\t train precision: 0.979,\t\t test precision: 0.9745\n",
            "Epoch: 1157,\t loss: 0.001085,\t\t train precision: 0.978,\t\t test precision: 0.9728\n",
            "Epoch: 1158,\t loss: 0.0009714,\t\t train precision: 0.9818,\t\t test precision: 0.9728\n",
            "Epoch: 1159,\t loss: 0.0009476,\t\t train precision: 0.9821,\t\t test precision: 0.9745\n",
            "Epoch: 1160,\t loss: 0.000905,\t\t train precision: 0.9821,\t\t test precision: 0.9786\n",
            "Epoch: 1161,\t loss: 0.0009176,\t\t train precision: 0.9832,\t\t test precision: 0.9736\n",
            "Epoch: 1162,\t loss: 0.0009302,\t\t train precision: 0.9811,\t\t test precision: 0.9703\n",
            "Epoch: 1163,\t loss: 0.0009048,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 1164,\t loss: 0.0008818,\t\t train precision: 0.9811,\t\t test precision: 0.9745\n",
            "Epoch: 1165,\t loss: 0.0009187,\t\t train precision: 0.9804,\t\t test precision: 0.9745\n",
            "Epoch: 1166,\t loss: 0.001025,\t\t train precision: 0.9797,\t\t test precision: 0.9769\n",
            "Epoch: 1167,\t loss: 0.0009104,\t\t train precision: 0.9818,\t\t test precision: 0.9736\n",
            "Epoch: 1168,\t loss: 0.0009603,\t\t train precision: 0.9808,\t\t test precision: 0.9761\n",
            "Epoch: 1169,\t loss: 0.0008438,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 1170,\t loss: 0.0009079,\t\t train precision: 0.9845,\t\t test precision: 0.9753\n",
            "Epoch: 1171,\t loss: 0.0008991,\t\t train precision: 0.9838,\t\t test precision: 0.9769\n",
            "Epoch: 1172,\t loss: 0.0008622,\t\t train precision: 0.9849,\t\t test precision: 0.9769\n",
            "Epoch: 1173,\t loss: 0.001023,\t\t train precision: 0.9787,\t\t test precision: 0.972\n",
            "Epoch: 1174,\t loss: 0.000908,\t\t train precision: 0.9842,\t\t test precision: 0.9745\n",
            "Epoch: 1175,\t loss: 0.000837,\t\t train precision: 0.9821,\t\t test precision: 0.9753\n",
            "Epoch: 1176,\t loss: 0.0008467,\t\t train precision: 0.9832,\t\t test precision: 0.9769\n",
            "Epoch: 1177,\t loss: 0.0008385,\t\t train precision: 0.979,\t\t test precision: 0.9745\n",
            "Epoch: 1178,\t loss: 0.0008743,\t\t train precision: 0.9763,\t\t test precision: 0.9745\n",
            "Epoch: 1179,\t loss: 0.000852,\t\t train precision: 0.9828,\t\t test precision: 0.9761\n",
            "Epoch: 1180,\t loss: 0.000888,\t\t train precision: 0.9801,\t\t test precision: 0.9753\n",
            "Epoch: 1181,\t loss: 0.0008976,\t\t train precision: 0.9818,\t\t test precision: 0.9745\n",
            "Epoch: 1182,\t loss: 0.0009125,\t\t train precision: 0.9849,\t\t test precision: 0.9769\n",
            "Epoch: 1183,\t loss: 0.0009304,\t\t train precision: 0.9777,\t\t test precision: 0.972\n",
            "Epoch: 1184,\t loss: 0.001071,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 1185,\t loss: 0.0009788,\t\t train precision: 0.9828,\t\t test precision: 0.9769\n",
            "Epoch: 1186,\t loss: 0.0008844,\t\t train precision: 0.9825,\t\t test precision: 0.972\n",
            "Epoch: 1187,\t loss: 0.0009561,\t\t train precision: 0.9773,\t\t test precision: 0.972\n",
            "Epoch: 1188,\t loss: 0.0009231,\t\t train precision: 0.9856,\t\t test precision: 0.9794\n",
            "Epoch: 1189,\t loss: 0.0008499,\t\t train precision: 0.9852,\t\t test precision: 0.9761\n",
            "Epoch: 1190,\t loss: 0.000931,\t\t train precision: 0.9821,\t\t test precision: 0.9753\n",
            "Epoch: 1191,\t loss: 0.0008254,\t\t train precision: 0.9808,\t\t test precision: 0.9712\n",
            "Epoch: 1192,\t loss: 0.001009,\t\t train precision: 0.9801,\t\t test precision: 0.9769\n",
            "Epoch: 1193,\t loss: 0.0008645,\t\t train precision: 0.9766,\t\t test precision: 0.9736\n",
            "Epoch: 1194,\t loss: 0.0009237,\t\t train precision: 0.9784,\t\t test precision: 0.9728\n",
            "Epoch: 1195,\t loss: 0.0009906,\t\t train precision: 0.9784,\t\t test precision: 0.9703\n",
            "Epoch: 1196,\t loss: 0.0008741,\t\t train precision: 0.9838,\t\t test precision: 0.9753\n",
            "Epoch: 1197,\t loss: 0.0008475,\t\t train precision: 0.9811,\t\t test precision: 0.9769\n",
            "Epoch: 1198,\t loss: 0.0009918,\t\t train precision: 0.9832,\t\t test precision: 0.9769\n",
            "Epoch: 1199,\t loss: 0.0008608,\t\t train precision: 0.9828,\t\t test precision: 0.9745\n",
            "Epoch: 1200,\t loss: 0.0009293,\t\t train precision: 0.9801,\t\t test precision: 0.972\n",
            "Epoch: 1201,\t loss: 0.0008564,\t\t train precision: 0.9828,\t\t test precision: 0.9745\n",
            "Epoch: 1202,\t loss: 0.0008257,\t\t train precision: 0.9811,\t\t test precision: 0.9712\n",
            "Epoch: 1203,\t loss: 0.0009697,\t\t train precision: 0.977,\t\t test precision: 0.9679\n",
            "Epoch: 1204,\t loss: 0.0008647,\t\t train precision: 0.9804,\t\t test precision: 0.9712\n",
            "Epoch: 1205,\t loss: 0.0008776,\t\t train precision: 0.9828,\t\t test precision: 0.9761\n",
            "Epoch: 1206,\t loss: 0.001014,\t\t train precision: 0.9811,\t\t test precision: 0.9761\n",
            "Epoch: 1207,\t loss: 0.0009223,\t\t train precision: 0.9845,\t\t test precision: 0.9753\n",
            "Epoch: 1208,\t loss: 0.0009148,\t\t train precision: 0.9801,\t\t test precision: 0.9745\n",
            "Epoch: 1209,\t loss: 0.0009065,\t\t train precision: 0.9821,\t\t test precision: 0.9745\n",
            "Epoch: 1210,\t loss: 0.0008704,\t\t train precision: 0.9804,\t\t test precision: 0.9703\n",
            "Epoch: 1211,\t loss: 0.0008613,\t\t train precision: 0.9832,\t\t test precision: 0.9786\n",
            "Epoch: 1212,\t loss: 0.0009026,\t\t train precision: 0.9784,\t\t test precision: 0.9728\n",
            "Epoch: 1213,\t loss: 0.000871,\t\t train precision: 0.9818,\t\t test precision: 0.9794\n",
            "Epoch: 1214,\t loss: 0.001014,\t\t train precision: 0.9828,\t\t test precision: 0.9745\n",
            "Epoch: 1215,\t loss: 0.0009769,\t\t train precision: 0.9845,\t\t test precision: 0.9786\n",
            "Epoch: 1216,\t loss: 0.0009398,\t\t train precision: 0.9821,\t\t test precision: 0.9753\n",
            "Epoch: 1217,\t loss: 0.0008794,\t\t train precision: 0.9808,\t\t test precision: 0.9712\n",
            "Epoch: 1218,\t loss: 0.0009609,\t\t train precision: 0.9808,\t\t test precision: 0.9745\n",
            "Epoch: 1219,\t loss: 0.0008251,\t\t train precision: 0.9828,\t\t test precision: 0.9786\n",
            "Epoch: 1220,\t loss: 0.0008759,\t\t train precision: 0.979,\t\t test precision: 0.972\n",
            "Epoch: 1221,\t loss: 0.0008598,\t\t train precision: 0.9821,\t\t test precision: 0.9736\n",
            "Epoch: 1222,\t loss: 0.0008512,\t\t train precision: 0.9835,\t\t test precision: 0.9728\n",
            "Epoch: 1223,\t loss: 0.0009311,\t\t train precision: 0.979,\t\t test precision: 0.9753\n",
            "Epoch: 1224,\t loss: 0.0008481,\t\t train precision: 0.9811,\t\t test precision: 0.9753\n",
            "Epoch: 1225,\t loss: 0.0008838,\t\t train precision: 0.9828,\t\t test precision: 0.9753\n",
            "Epoch: 1226,\t loss: 0.0008603,\t\t train precision: 0.9821,\t\t test precision: 0.9753\n",
            "Epoch: 1227,\t loss: 0.00082,\t\t train precision: 0.9804,\t\t test precision: 0.9736\n",
            "Epoch: 1228,\t loss: 0.0009201,\t\t train precision: 0.9828,\t\t test precision: 0.9753\n",
            "Epoch: 1229,\t loss: 0.0008943,\t\t train precision: 0.9797,\t\t test precision: 0.9712\n",
            "Epoch: 1230,\t loss: 0.0008522,\t\t train precision: 0.9804,\t\t test precision: 0.9753\n",
            "Epoch: 1231,\t loss: 0.0009137,\t\t train precision: 0.9838,\t\t test precision: 0.9778\n",
            "Epoch: 1232,\t loss: 0.0009012,\t\t train precision: 0.9845,\t\t test precision: 0.9761\n",
            "Epoch: 1233,\t loss: 0.0009316,\t\t train precision: 0.9814,\t\t test precision: 0.972\n",
            "Epoch: 1234,\t loss: 0.0008116,\t\t train precision: 0.9821,\t\t test precision: 0.972\n",
            "Epoch: 1235,\t loss: 0.000981,\t\t train precision: 0.9787,\t\t test precision: 0.9671\n",
            "Epoch: 1236,\t loss: 0.0009373,\t\t train precision: 0.9838,\t\t test precision: 0.9745\n",
            "Epoch: 1237,\t loss: 0.0008994,\t\t train precision: 0.9825,\t\t test precision: 0.9687\n",
            "Epoch: 1238,\t loss: 0.0009949,\t\t train precision: 0.9811,\t\t test precision: 0.9745\n",
            "Epoch: 1239,\t loss: 0.0008264,\t\t train precision: 0.9838,\t\t test precision: 0.9769\n",
            "Epoch: 1240,\t loss: 0.000883,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 1241,\t loss: 0.0009073,\t\t train precision: 0.9784,\t\t test precision: 0.9703\n",
            "Epoch: 1242,\t loss: 0.0008035,\t\t train precision: 0.979,\t\t test precision: 0.9703\n",
            "Epoch: 1243,\t loss: 0.0008974,\t\t train precision: 0.9811,\t\t test precision: 0.9745\n",
            "Epoch: 1244,\t loss: 0.0008835,\t\t train precision: 0.9811,\t\t test precision: 0.9745\n",
            "Epoch: 1245,\t loss: 0.0008656,\t\t train precision: 0.9818,\t\t test precision: 0.972\n",
            "Epoch: 1246,\t loss: 0.000814,\t\t train precision: 0.9832,\t\t test precision: 0.9778\n",
            "Epoch: 1247,\t loss: 0.000857,\t\t train precision: 0.9811,\t\t test precision: 0.9745\n",
            "Epoch: 1248,\t loss: 0.0009182,\t\t train precision: 0.9801,\t\t test precision: 0.9712\n",
            "Epoch: 1249,\t loss: 0.0008837,\t\t train precision: 0.9804,\t\t test precision: 0.9786\n",
            "Epoch: 1250,\t loss: 0.0009338,\t\t train precision: 0.9838,\t\t test precision: 0.9745\n",
            "Epoch: 1251,\t loss: 0.0009155,\t\t train precision: 0.9821,\t\t test precision: 0.9769\n",
            "Epoch: 1252,\t loss: 0.0009042,\t\t train precision: 0.9818,\t\t test precision: 0.9769\n",
            "Epoch: 1253,\t loss: 0.0009511,\t\t train precision: 0.9811,\t\t test precision: 0.9712\n",
            "Epoch: 1254,\t loss: 0.0009013,\t\t train precision: 0.9821,\t\t test precision: 0.9769\n",
            "Epoch: 1255,\t loss: 0.0009259,\t\t train precision: 0.9808,\t\t test precision: 0.9736\n",
            "Epoch: 1256,\t loss: 0.0008753,\t\t train precision: 0.9821,\t\t test precision: 0.9745\n",
            "Epoch: 1257,\t loss: 0.0008553,\t\t train precision: 0.9794,\t\t test precision: 0.9712\n",
            "Epoch: 1258,\t loss: 0.000813,\t\t train precision: 0.9794,\t\t test precision: 0.9703\n",
            "Epoch: 1259,\t loss: 0.0009438,\t\t train precision: 0.9811,\t\t test precision: 0.9753\n",
            "Epoch: 1260,\t loss: 0.0008606,\t\t train precision: 0.9773,\t\t test precision: 0.9695\n",
            "Epoch: 1261,\t loss: 0.0008789,\t\t train precision: 0.9808,\t\t test precision: 0.9745\n",
            "Epoch: 1262,\t loss: 0.0009263,\t\t train precision: 0.9832,\t\t test precision: 0.9769\n",
            "Epoch: 1263,\t loss: 0.0008963,\t\t train precision: 0.9832,\t\t test precision: 0.9769\n",
            "Epoch: 1264,\t loss: 0.0009292,\t\t train precision: 0.9825,\t\t test precision: 0.9745\n",
            "Epoch: 1265,\t loss: 0.0009147,\t\t train precision: 0.9794,\t\t test precision: 0.972\n",
            "Epoch: 1266,\t loss: 0.0009063,\t\t train precision: 0.9832,\t\t test precision: 0.9753\n",
            "Epoch: 1267,\t loss: 0.0008597,\t\t train precision: 0.9804,\t\t test precision: 0.9712\n",
            "Epoch: 1268,\t loss: 0.00088,\t\t train precision: 0.9818,\t\t test precision: 0.9761\n",
            "Epoch: 1269,\t loss: 0.0008907,\t\t train precision: 0.9773,\t\t test precision: 0.9753\n",
            "Epoch: 1270,\t loss: 0.0008947,\t\t train precision: 0.9787,\t\t test precision: 0.9753\n",
            "Epoch: 1271,\t loss: 0.000929,\t\t train precision: 0.9838,\t\t test precision: 0.9753\n",
            "Epoch: 1272,\t loss: 0.0008991,\t\t train precision: 0.9784,\t\t test precision: 0.9687\n",
            "Epoch: 1273,\t loss: 0.0008419,\t\t train precision: 0.9849,\t\t test precision: 0.9753\n",
            "Epoch: 1274,\t loss: 0.0008686,\t\t train precision: 0.9808,\t\t test precision: 0.972\n",
            "Epoch: 1275,\t loss: 0.0008382,\t\t train precision: 0.9825,\t\t test precision: 0.9695\n",
            "Epoch: 1276,\t loss: 0.0009253,\t\t train precision: 0.9849,\t\t test precision: 0.9753\n",
            "Epoch: 1277,\t loss: 0.0007882,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 1278,\t loss: 0.0008362,\t\t train precision: 0.9825,\t\t test precision: 0.9728\n",
            "Epoch: 1279,\t loss: 0.0008218,\t\t train precision: 0.9832,\t\t test precision: 0.9753\n",
            "Epoch: 1280,\t loss: 0.0009402,\t\t train precision: 0.9794,\t\t test precision: 0.9736\n",
            "Epoch: 1281,\t loss: 0.0009507,\t\t train precision: 0.9832,\t\t test precision: 0.972\n",
            "Epoch: 1282,\t loss: 0.0009196,\t\t train precision: 0.9804,\t\t test precision: 0.9728\n",
            "Epoch: 1283,\t loss: 0.000895,\t\t train precision: 0.9828,\t\t test precision: 0.9761\n",
            "Epoch: 1284,\t loss: 0.0009237,\t\t train precision: 0.9828,\t\t test precision: 0.9753\n",
            "Epoch: 1285,\t loss: 0.0008909,\t\t train precision: 0.9832,\t\t test precision: 0.9745\n",
            "Epoch: 1286,\t loss: 0.0009137,\t\t train precision: 0.9852,\t\t test precision: 0.9745\n",
            "Epoch: 1287,\t loss: 0.0008816,\t\t train precision: 0.9838,\t\t test precision: 0.9745\n",
            "Epoch: 1288,\t loss: 0.0008245,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 1289,\t loss: 0.0009041,\t\t train precision: 0.9821,\t\t test precision: 0.9753\n",
            "Epoch: 1290,\t loss: 0.0009162,\t\t train precision: 0.978,\t\t test precision: 0.9671\n",
            "Epoch: 1291,\t loss: 0.0008692,\t\t train precision: 0.9818,\t\t test precision: 0.9761\n",
            "Epoch: 1292,\t loss: 0.0008938,\t\t train precision: 0.9811,\t\t test precision: 0.9703\n",
            "Epoch: 1293,\t loss: 0.0008333,\t\t train precision: 0.9832,\t\t test precision: 0.9761\n",
            "Epoch: 1294,\t loss: 0.0008517,\t\t train precision: 0.9787,\t\t test precision: 0.9703\n",
            "Epoch: 1295,\t loss: 0.0008642,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 1296,\t loss: 0.0008089,\t\t train precision: 0.9808,\t\t test precision: 0.9761\n",
            "Epoch: 1297,\t loss: 0.0009064,\t\t train precision: 0.9821,\t\t test precision: 0.9769\n",
            "Epoch: 1298,\t loss: 0.0008065,\t\t train precision: 0.9811,\t\t test precision: 0.9736\n",
            "Epoch: 1299,\t loss: 0.0008683,\t\t train precision: 0.9821,\t\t test precision: 0.9769\n",
            "Epoch: 1300,\t loss: 0.000881,\t\t train precision: 0.9804,\t\t test precision: 0.9745\n",
            "Epoch: 1301,\t loss: 0.0007922,\t\t train precision: 0.9835,\t\t test precision: 0.9761\n",
            "Epoch: 1302,\t loss: 0.0008227,\t\t train precision: 0.9821,\t\t test precision: 0.9745\n",
            "Epoch: 1303,\t loss: 0.00081,\t\t train precision: 0.9814,\t\t test precision: 0.9786\n",
            "Epoch: 1304,\t loss: 0.0008521,\t\t train precision: 0.9821,\t\t test precision: 0.9769\n",
            "Epoch: 1305,\t loss: 0.000885,\t\t train precision: 0.9832,\t\t test precision: 0.9778\n",
            "Epoch: 1306,\t loss: 0.0008451,\t\t train precision: 0.9835,\t\t test precision: 0.9753\n",
            "Epoch: 1307,\t loss: 0.000949,\t\t train precision: 0.9763,\t\t test precision: 0.9736\n",
            "Epoch: 1308,\t loss: 0.0009313,\t\t train precision: 0.9838,\t\t test precision: 0.9769\n",
            "Epoch: 1309,\t loss: 0.0009087,\t\t train precision: 0.9797,\t\t test precision: 0.9769\n",
            "Epoch: 1310,\t loss: 0.0008331,\t\t train precision: 0.9814,\t\t test precision: 0.972\n",
            "Epoch: 1311,\t loss: 0.0008972,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 1312,\t loss: 0.0008876,\t\t train precision: 0.9825,\t\t test precision: 0.9745\n",
            "Epoch: 1313,\t loss: 0.0009057,\t\t train precision: 0.9811,\t\t test precision: 0.9728\n",
            "Epoch: 1314,\t loss: 0.0009231,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 1315,\t loss: 0.0008924,\t\t train precision: 0.9821,\t\t test precision: 0.9778\n",
            "Epoch: 1316,\t loss: 0.0008729,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 1317,\t loss: 0.0007552,\t\t train precision: 0.9811,\t\t test precision: 0.9728\n",
            "Epoch: 1318,\t loss: 0.0008033,\t\t train precision: 0.9804,\t\t test precision: 0.972\n",
            "Epoch: 1319,\t loss: 0.0008649,\t\t train precision: 0.9821,\t\t test precision: 0.9745\n",
            "Epoch: 1320,\t loss: 0.0008034,\t\t train precision: 0.9832,\t\t test precision: 0.9753\n",
            "Epoch: 1321,\t loss: 0.0008456,\t\t train precision: 0.9808,\t\t test precision: 0.9753\n",
            "Epoch: 1322,\t loss: 0.0008651,\t\t train precision: 0.9825,\t\t test precision: 0.9769\n",
            "Epoch: 1323,\t loss: 0.0009452,\t\t train precision: 0.9835,\t\t test precision: 0.9761\n",
            "Epoch: 1324,\t loss: 0.0008338,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 1325,\t loss: 0.0008882,\t\t train precision: 0.9835,\t\t test precision: 0.9778\n",
            "Epoch: 1326,\t loss: 0.0008692,\t\t train precision: 0.9804,\t\t test precision: 0.9703\n",
            "Epoch: 1327,\t loss: 0.0007986,\t\t train precision: 0.9825,\t\t test precision: 0.9778\n",
            "Epoch: 1328,\t loss: 0.0008545,\t\t train precision: 0.9842,\t\t test precision: 0.9769\n",
            "Epoch: 1329,\t loss: 0.000821,\t\t train precision: 0.9825,\t\t test precision: 0.9703\n",
            "Epoch: 1330,\t loss: 0.0009338,\t\t train precision: 0.9804,\t\t test precision: 0.9786\n",
            "Epoch: 1331,\t loss: 0.0008472,\t\t train precision: 0.9811,\t\t test precision: 0.9745\n",
            "Epoch: 1332,\t loss: 0.0008587,\t\t train precision: 0.9777,\t\t test precision: 0.9695\n",
            "Epoch: 1333,\t loss: 0.0008472,\t\t train precision: 0.9825,\t\t test precision: 0.9736\n",
            "Epoch: 1334,\t loss: 0.0008397,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 1335,\t loss: 0.0009438,\t\t train precision: 0.9838,\t\t test precision: 0.9753\n",
            "Epoch: 1336,\t loss: 0.0009552,\t\t train precision: 0.9852,\t\t test precision: 0.9778\n",
            "Epoch: 1337,\t loss: 0.0008742,\t\t train precision: 0.9808,\t\t test precision: 0.9753\n",
            "Epoch: 1338,\t loss: 0.0008618,\t\t train precision: 0.9794,\t\t test precision: 0.9769\n",
            "Epoch: 1339,\t loss: 0.0009021,\t\t train precision: 0.9856,\t\t test precision: 0.9745\n",
            "Epoch: 1340,\t loss: 0.0008188,\t\t train precision: 0.9794,\t\t test precision: 0.9728\n",
            "Epoch: 1341,\t loss: 0.0008635,\t\t train precision: 0.9832,\t\t test precision: 0.9802\n",
            "Epoch: 1342,\t loss: 0.0009443,\t\t train precision: 0.9835,\t\t test precision: 0.9769\n",
            "Epoch: 1343,\t loss: 0.0009139,\t\t train precision: 0.9835,\t\t test precision: 0.9745\n",
            "Epoch: 1344,\t loss: 0.0008227,\t\t train precision: 0.9801,\t\t test precision: 0.9695\n",
            "Epoch: 1345,\t loss: 0.0007825,\t\t train precision: 0.979,\t\t test precision: 0.9703\n",
            "Epoch: 1346,\t loss: 0.0009025,\t\t train precision: 0.9828,\t\t test precision: 0.9753\n",
            "Epoch: 1347,\t loss: 0.000802,\t\t train precision: 0.9814,\t\t test precision: 0.9786\n",
            "Epoch: 1348,\t loss: 0.0008378,\t\t train precision: 0.9832,\t\t test precision: 0.9761\n",
            "Epoch: 1349,\t loss: 0.0008824,\t\t train precision: 0.9838,\t\t test precision: 0.9745\n",
            "Epoch: 1350,\t loss: 0.0009198,\t\t train precision: 0.9801,\t\t test precision: 0.9753\n",
            "Epoch: 1351,\t loss: 0.0008279,\t\t train precision: 0.9814,\t\t test precision: 0.9728\n",
            "Epoch: 1352,\t loss: 0.0008558,\t\t train precision: 0.9766,\t\t test precision: 0.9679\n",
            "Epoch: 1353,\t loss: 0.0008791,\t\t train precision: 0.9787,\t\t test precision: 0.9695\n",
            "Epoch: 1354,\t loss: 0.000845,\t\t train precision: 0.9794,\t\t test precision: 0.9736\n",
            "Epoch: 1355,\t loss: 0.0008532,\t\t train precision: 0.9821,\t\t test precision: 0.9753\n",
            "Epoch: 1356,\t loss: 0.0008678,\t\t train precision: 0.9825,\t\t test precision: 0.972\n",
            "Epoch: 1357,\t loss: 0.0007802,\t\t train precision: 0.9832,\t\t test precision: 0.9753\n",
            "Epoch: 1358,\t loss: 0.0008703,\t\t train precision: 0.9797,\t\t test precision: 0.9769\n",
            "Epoch: 1359,\t loss: 0.0008866,\t\t train precision: 0.9804,\t\t test precision: 0.9769\n",
            "Epoch: 1360,\t loss: 0.000849,\t\t train precision: 0.9784,\t\t test precision: 0.9736\n",
            "Epoch: 1361,\t loss: 0.0009005,\t\t train precision: 0.9814,\t\t test precision: 0.9728\n",
            "Epoch: 1362,\t loss: 0.0008725,\t\t train precision: 0.9804,\t\t test precision: 0.9736\n",
            "Epoch: 1363,\t loss: 0.0008663,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 1364,\t loss: 0.0008691,\t\t train precision: 0.9835,\t\t test precision: 0.9769\n",
            "Epoch: 1365,\t loss: 0.0008402,\t\t train precision: 0.9845,\t\t test precision: 0.9736\n",
            "Epoch: 1366,\t loss: 0.000874,\t\t train precision: 0.9835,\t\t test precision: 0.9753\n",
            "Epoch: 1367,\t loss: 0.000982,\t\t train precision: 0.9818,\t\t test precision: 0.9769\n",
            "Epoch: 1368,\t loss: 0.0008517,\t\t train precision: 0.9838,\t\t test precision: 0.9745\n",
            "Epoch: 1369,\t loss: 0.000894,\t\t train precision: 0.9818,\t\t test precision: 0.9745\n",
            "Epoch: 1370,\t loss: 0.0008942,\t\t train precision: 0.9804,\t\t test precision: 0.9736\n",
            "Epoch: 1371,\t loss: 0.0009551,\t\t train precision: 0.9808,\t\t test precision: 0.972\n",
            "Epoch: 1372,\t loss: 0.0008509,\t\t train precision: 0.9808,\t\t test precision: 0.9794\n",
            "Epoch: 1373,\t loss: 0.0009389,\t\t train precision: 0.9832,\t\t test precision: 0.9753\n",
            "Epoch: 1374,\t loss: 0.0008209,\t\t train precision: 0.9804,\t\t test precision: 0.9745\n",
            "Epoch: 1375,\t loss: 0.0008749,\t\t train precision: 0.9825,\t\t test precision: 0.9736\n",
            "Epoch: 1376,\t loss: 0.0008671,\t\t train precision: 0.9832,\t\t test precision: 0.9736\n",
            "Epoch: 1377,\t loss: 0.0008813,\t\t train precision: 0.9832,\t\t test precision: 0.9761\n",
            "Epoch: 1378,\t loss: 0.0008227,\t\t train precision: 0.9794,\t\t test precision: 0.9712\n",
            "Epoch: 1379,\t loss: 0.0008507,\t\t train precision: 0.9838,\t\t test precision: 0.9745\n",
            "Epoch: 1380,\t loss: 0.0008042,\t\t train precision: 0.9845,\t\t test precision: 0.9778\n",
            "Epoch: 1381,\t loss: 0.0009249,\t\t train precision: 0.9835,\t\t test precision: 0.9753\n",
            "Epoch: 1382,\t loss: 0.0008211,\t\t train precision: 0.9856,\t\t test precision: 0.9761\n",
            "Epoch: 1383,\t loss: 0.0009127,\t\t train precision: 0.9821,\t\t test precision: 0.9745\n",
            "Epoch: 1384,\t loss: 0.0009194,\t\t train precision: 0.9818,\t\t test precision: 0.9712\n",
            "Epoch: 1385,\t loss: 0.0008341,\t\t train precision: 0.9852,\t\t test precision: 0.9761\n",
            "Epoch: 1386,\t loss: 0.0009175,\t\t train precision: 0.9801,\t\t test precision: 0.9712\n",
            "Epoch: 1387,\t loss: 0.0008572,\t\t train precision: 0.9821,\t\t test precision: 0.9745\n",
            "Epoch: 1388,\t loss: 0.000876,\t\t train precision: 0.9784,\t\t test precision: 0.9778\n",
            "Epoch: 1389,\t loss: 0.0008036,\t\t train precision: 0.9828,\t\t test precision: 0.9761\n",
            "Epoch: 1390,\t loss: 0.0008626,\t\t train precision: 0.9797,\t\t test precision: 0.9728\n",
            "Epoch: 1391,\t loss: 0.0008319,\t\t train precision: 0.9811,\t\t test precision: 0.9786\n",
            "Epoch: 1392,\t loss: 0.0008944,\t\t train precision: 0.9825,\t\t test precision: 0.9761\n",
            "Epoch: 1393,\t loss: 0.00087,\t\t train precision: 0.9801,\t\t test precision: 0.9736\n",
            "Epoch: 1394,\t loss: 0.0007905,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 1395,\t loss: 0.0009509,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 1396,\t loss: 0.0008886,\t\t train precision: 0.9835,\t\t test precision: 0.9769\n",
            "Epoch: 1397,\t loss: 0.0008812,\t\t train precision: 0.9818,\t\t test precision: 0.9736\n",
            "Epoch: 1398,\t loss: 0.0008513,\t\t train precision: 0.9811,\t\t test precision: 0.972\n",
            "Epoch: 1399,\t loss: 0.0008618,\t\t train precision: 0.9801,\t\t test precision: 0.972\n",
            "Epoch: 1400,\t loss: 0.0008894,\t\t train precision: 0.9814,\t\t test precision: 0.9736\n",
            "Epoch: 1401,\t loss: 0.0008304,\t\t train precision: 0.9794,\t\t test precision: 0.9753\n",
            "Epoch: 1402,\t loss: 0.0008089,\t\t train precision: 0.9845,\t\t test precision: 0.9761\n",
            "Epoch: 1403,\t loss: 0.0008253,\t\t train precision: 0.9811,\t\t test precision: 0.9753\n",
            "Epoch: 1404,\t loss: 0.0009146,\t\t train precision: 0.9794,\t\t test precision: 0.9703\n",
            "Epoch: 1405,\t loss: 0.0009031,\t\t train precision: 0.9828,\t\t test precision: 0.9761\n",
            "Epoch: 1406,\t loss: 0.001025,\t\t train precision: 0.9794,\t\t test precision: 0.9736\n",
            "Epoch: 1407,\t loss: 0.0008714,\t\t train precision: 0.9818,\t\t test precision: 0.9778\n",
            "Epoch: 1408,\t loss: 0.0009792,\t\t train precision: 0.9825,\t\t test precision: 0.9728\n",
            "Epoch: 1409,\t loss: 0.0008689,\t\t train precision: 0.9845,\t\t test precision: 0.9769\n",
            "Epoch: 1410,\t loss: 0.0008104,\t\t train precision: 0.9801,\t\t test precision: 0.9745\n",
            "Epoch: 1411,\t loss: 0.0008502,\t\t train precision: 0.9835,\t\t test precision: 0.9745\n",
            "Epoch: 1412,\t loss: 0.0007939,\t\t train precision: 0.9804,\t\t test precision: 0.9736\n",
            "Epoch: 1413,\t loss: 0.0008635,\t\t train precision: 0.9852,\t\t test precision: 0.9794\n",
            "Epoch: 1414,\t loss: 0.0008421,\t\t train precision: 0.9804,\t\t test precision: 0.972\n",
            "Epoch: 1415,\t loss: 0.0009107,\t\t train precision: 0.9808,\t\t test precision: 0.9728\n",
            "Epoch: 1416,\t loss: 0.0009348,\t\t train precision: 0.9828,\t\t test precision: 0.9728\n",
            "Epoch: 1417,\t loss: 0.0009182,\t\t train precision: 0.9794,\t\t test precision: 0.9703\n",
            "Epoch: 1418,\t loss: 0.0008322,\t\t train precision: 0.9811,\t\t test precision: 0.9778\n",
            "Epoch: 1419,\t loss: 0.000795,\t\t train precision: 0.9842,\t\t test precision: 0.9761\n",
            "Epoch: 1420,\t loss: 0.0008052,\t\t train precision: 0.9838,\t\t test precision: 0.9786\n",
            "Epoch: 1421,\t loss: 0.0008551,\t\t train precision: 0.9828,\t\t test precision: 0.9712\n",
            "Epoch: 1422,\t loss: 0.0008499,\t\t train precision: 0.9801,\t\t test precision: 0.9728\n",
            "Epoch: 1423,\t loss: 0.0008103,\t\t train precision: 0.9808,\t\t test precision: 0.9753\n",
            "Epoch: 1424,\t loss: 0.0007929,\t\t train precision: 0.9825,\t\t test precision: 0.9736\n",
            "Epoch: 1425,\t loss: 0.0008669,\t\t train precision: 0.9828,\t\t test precision: 0.9769\n",
            "Epoch: 1426,\t loss: 0.0008255,\t\t train precision: 0.9811,\t\t test precision: 0.9753\n",
            "Epoch: 1427,\t loss: 0.0008664,\t\t train precision: 0.9835,\t\t test precision: 0.9736\n",
            "Epoch: 1428,\t loss: 0.0007931,\t\t train precision: 0.9842,\t\t test precision: 0.9745\n",
            "Epoch: 1429,\t loss: 0.0007648,\t\t train precision: 0.9821,\t\t test precision: 0.9786\n",
            "Epoch: 1430,\t loss: 0.000752,\t\t train precision: 0.9821,\t\t test precision: 0.9736\n",
            "Epoch: 1431,\t loss: 0.0009537,\t\t train precision: 0.9825,\t\t test precision: 0.9736\n",
            "Epoch: 1432,\t loss: 0.0008781,\t\t train precision: 0.9832,\t\t test precision: 0.9769\n",
            "Epoch: 1433,\t loss: 0.0008675,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 1434,\t loss: 0.0009669,\t\t train precision: 0.9842,\t\t test precision: 0.9745\n",
            "Epoch: 1435,\t loss: 0.0008549,\t\t train precision: 0.9777,\t\t test precision: 0.9687\n",
            "Epoch: 1436,\t loss: 0.0007901,\t\t train precision: 0.9828,\t\t test precision: 0.9745\n",
            "Epoch: 1437,\t loss: 0.0008452,\t\t train precision: 0.9801,\t\t test precision: 0.9728\n",
            "Epoch: 1438,\t loss: 0.0008547,\t\t train precision: 0.9849,\t\t test precision: 0.9761\n",
            "Epoch: 1439,\t loss: 0.0008384,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 1440,\t loss: 0.0008259,\t\t train precision: 0.9804,\t\t test precision: 0.9712\n",
            "Epoch: 1441,\t loss: 0.0008051,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 1442,\t loss: 0.000847,\t\t train precision: 0.9832,\t\t test precision: 0.9753\n",
            "Epoch: 1443,\t loss: 0.0008971,\t\t train precision: 0.9828,\t\t test precision: 0.9745\n",
            "Epoch: 1444,\t loss: 0.0007812,\t\t train precision: 0.9804,\t\t test precision: 0.9753\n",
            "Epoch: 1445,\t loss: 0.00076,\t\t train precision: 0.9835,\t\t test precision: 0.9728\n",
            "Epoch: 1446,\t loss: 0.0008373,\t\t train precision: 0.9784,\t\t test precision: 0.9736\n",
            "Epoch: 1447,\t loss: 0.0008728,\t\t train precision: 0.9825,\t\t test precision: 0.9736\n",
            "Epoch: 1448,\t loss: 0.0009363,\t\t train precision: 0.9804,\t\t test precision: 0.9753\n",
            "Epoch: 1449,\t loss: 0.0008339,\t\t train precision: 0.9818,\t\t test precision: 0.9745\n",
            "Epoch: 1450,\t loss: 0.000802,\t\t train precision: 0.9804,\t\t test precision: 0.9736\n",
            "Epoch: 1451,\t loss: 0.0008742,\t\t train precision: 0.9811,\t\t test precision: 0.9753\n",
            "Epoch: 1452,\t loss: 0.000894,\t\t train precision: 0.9804,\t\t test precision: 0.9753\n",
            "Epoch: 1453,\t loss: 0.0009956,\t\t train precision: 0.9832,\t\t test precision: 0.9761\n",
            "Epoch: 1454,\t loss: 0.0007749,\t\t train precision: 0.9814,\t\t test precision: 0.9769\n",
            "Epoch: 1455,\t loss: 0.0008985,\t\t train precision: 0.9825,\t\t test precision: 0.9769\n",
            "Epoch: 1456,\t loss: 0.0008536,\t\t train precision: 0.9801,\t\t test precision: 0.9728\n",
            "Epoch: 1457,\t loss: 0.0009129,\t\t train precision: 0.9811,\t\t test precision: 0.9728\n",
            "Epoch: 1458,\t loss: 0.0009138,\t\t train precision: 0.9818,\t\t test precision: 0.9745\n",
            "Epoch: 1459,\t loss: 0.0007812,\t\t train precision: 0.9845,\t\t test precision: 0.9736\n",
            "Epoch: 1460,\t loss: 0.0007836,\t\t train precision: 0.9852,\t\t test precision: 0.9761\n",
            "Epoch: 1461,\t loss: 0.000842,\t\t train precision: 0.9794,\t\t test precision: 0.9736\n",
            "Epoch: 1462,\t loss: 0.0008587,\t\t train precision: 0.9842,\t\t test precision: 0.9753\n",
            "Epoch: 1463,\t loss: 0.0009558,\t\t train precision: 0.9821,\t\t test precision: 0.9728\n",
            "Epoch: 1464,\t loss: 0.0008234,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 1465,\t loss: 0.000841,\t\t train precision: 0.9763,\t\t test precision: 0.9679\n",
            "Epoch: 1466,\t loss: 0.000892,\t\t train precision: 0.9787,\t\t test precision: 0.9753\n",
            "Epoch: 1467,\t loss: 0.00085,\t\t train precision: 0.9804,\t\t test precision: 0.9753\n",
            "Epoch: 1468,\t loss: 0.0007712,\t\t train precision: 0.9828,\t\t test precision: 0.9736\n",
            "Epoch: 1469,\t loss: 0.0007829,\t\t train precision: 0.9811,\t\t test precision: 0.9728\n",
            "Epoch: 1470,\t loss: 0.0008303,\t\t train precision: 0.9804,\t\t test precision: 0.9745\n",
            "Epoch: 1471,\t loss: 0.0007792,\t\t train precision: 0.9828,\t\t test precision: 0.9761\n",
            "Epoch: 1472,\t loss: 0.0008924,\t\t train precision: 0.9814,\t\t test precision: 0.9736\n",
            "Epoch: 1473,\t loss: 0.0008147,\t\t train precision: 0.9832,\t\t test precision: 0.9769\n",
            "Epoch: 1474,\t loss: 0.0008598,\t\t train precision: 0.9842,\t\t test precision: 0.9761\n",
            "Epoch: 1475,\t loss: 0.0008021,\t\t train precision: 0.9797,\t\t test precision: 0.972\n",
            "Epoch: 1476,\t loss: 0.0009546,\t\t train precision: 0.9814,\t\t test precision: 0.9728\n",
            "Epoch: 1477,\t loss: 0.0008897,\t\t train precision: 0.978,\t\t test precision: 0.9703\n",
            "Epoch: 1478,\t loss: 0.0007548,\t\t train precision: 0.9811,\t\t test precision: 0.9745\n",
            "Epoch: 1479,\t loss: 0.0009471,\t\t train precision: 0.9787,\t\t test precision: 0.9703\n",
            "Epoch: 1480,\t loss: 0.0008438,\t\t train precision: 0.9852,\t\t test precision: 0.9778\n",
            "Epoch: 1481,\t loss: 0.0007766,\t\t train precision: 0.9763,\t\t test precision: 0.9671\n",
            "Epoch: 1482,\t loss: 0.0007915,\t\t train precision: 0.9828,\t\t test precision: 0.9745\n",
            "Epoch: 1483,\t loss: 0.0008595,\t\t train precision: 0.9825,\t\t test precision: 0.9769\n",
            "Epoch: 1484,\t loss: 0.0008799,\t\t train precision: 0.9845,\t\t test precision: 0.9745\n",
            "Epoch: 1485,\t loss: 0.0007919,\t\t train precision: 0.9845,\t\t test precision: 0.9761\n",
            "Epoch: 1486,\t loss: 0.0009177,\t\t train precision: 0.9804,\t\t test precision: 0.9736\n",
            "Epoch: 1487,\t loss: 0.0009378,\t\t train precision: 0.9845,\t\t test precision: 0.9745\n",
            "Epoch: 1488,\t loss: 0.0008006,\t\t train precision: 0.9797,\t\t test precision: 0.9695\n",
            "Epoch: 1489,\t loss: 0.0007595,\t\t train precision: 0.9818,\t\t test precision: 0.9728\n",
            "Epoch: 1490,\t loss: 0.0009245,\t\t train precision: 0.9835,\t\t test precision: 0.9728\n",
            "Epoch: 1491,\t loss: 0.0009501,\t\t train precision: 0.9773,\t\t test precision: 0.972\n",
            "Epoch: 1492,\t loss: 0.000938,\t\t train precision: 0.9804,\t\t test precision: 0.9703\n",
            "Epoch: 1493,\t loss: 0.0008163,\t\t train precision: 0.9797,\t\t test precision: 0.972\n",
            "Epoch: 1494,\t loss: 0.0008032,\t\t train precision: 0.9801,\t\t test precision: 0.9695\n",
            "Epoch: 1495,\t loss: 0.0008657,\t\t train precision: 0.9825,\t\t test precision: 0.9745\n",
            "Epoch: 1496,\t loss: 0.0008854,\t\t train precision: 0.9814,\t\t test precision: 0.9753\n",
            "Epoch: 1497,\t loss: 0.0008836,\t\t train precision: 0.9794,\t\t test precision: 0.9761\n",
            "Epoch: 1498,\t loss: 0.0008952,\t\t train precision: 0.9821,\t\t test precision: 0.9728\n",
            "Epoch: 1499,\t loss: 0.0009065,\t\t train precision: 0.9794,\t\t test precision: 0.9703\n",
            "Epoch: 1500,\t loss: 0.0009511,\t\t train precision: 0.9808,\t\t test precision: 0.9745\n",
            "Epoch: 1501,\t loss: 0.0008985,\t\t train precision: 0.9818,\t\t test precision: 0.9728\n",
            "Epoch: 1502,\t loss: 0.0008437,\t\t train precision: 0.9814,\t\t test precision: 0.9728\n",
            "Epoch: 1503,\t loss: 0.0009391,\t\t train precision: 0.9814,\t\t test precision: 0.9736\n",
            "Epoch: 1504,\t loss: 0.0008518,\t\t train precision: 0.9801,\t\t test precision: 0.9728\n",
            "Epoch: 1505,\t loss: 0.000782,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 1506,\t loss: 0.0008623,\t\t train precision: 0.9784,\t\t test precision: 0.9703\n",
            "Epoch: 1507,\t loss: 0.000855,\t\t train precision: 0.9845,\t\t test precision: 0.9769\n",
            "Epoch: 1508,\t loss: 0.0008354,\t\t train precision: 0.9804,\t\t test precision: 0.9703\n",
            "Epoch: 1509,\t loss: 0.0009307,\t\t train precision: 0.9804,\t\t test precision: 0.9679\n",
            "Epoch: 1510,\t loss: 0.0009608,\t\t train precision: 0.9818,\t\t test precision: 0.9728\n",
            "Epoch: 1511,\t loss: 0.0007893,\t\t train precision: 0.9825,\t\t test precision: 0.9745\n",
            "Epoch: 1512,\t loss: 0.0008998,\t\t train precision: 0.9828,\t\t test precision: 0.9753\n",
            "Epoch: 1513,\t loss: 0.0009062,\t\t train precision: 0.9821,\t\t test precision: 0.9728\n",
            "Epoch: 1514,\t loss: 0.0009517,\t\t train precision: 0.9821,\t\t test precision: 0.9769\n",
            "Epoch: 1515,\t loss: 0.0008924,\t\t train precision: 0.9825,\t\t test precision: 0.9745\n",
            "Epoch: 1516,\t loss: 0.000831,\t\t train precision: 0.9838,\t\t test precision: 0.9761\n",
            "Epoch: 1517,\t loss: 0.0008094,\t\t train precision: 0.9835,\t\t test precision: 0.9769\n",
            "Epoch: 1518,\t loss: 0.0007937,\t\t train precision: 0.9808,\t\t test precision: 0.9745\n",
            "Epoch: 1519,\t loss: 0.0007766,\t\t train precision: 0.9856,\t\t test precision: 0.9778\n",
            "Epoch: 1520,\t loss: 0.0008452,\t\t train precision: 0.9784,\t\t test precision: 0.9703\n",
            "Epoch: 1521,\t loss: 0.000963,\t\t train precision: 0.978,\t\t test precision: 0.9703\n",
            "Epoch: 1522,\t loss: 0.0008267,\t\t train precision: 0.979,\t\t test precision: 0.9695\n",
            "Epoch: 1523,\t loss: 0.0008814,\t\t train precision: 0.9818,\t\t test precision: 0.9778\n",
            "Epoch: 1524,\t loss: 0.0008481,\t\t train precision: 0.9804,\t\t test precision: 0.972\n",
            "Epoch: 1525,\t loss: 0.0008977,\t\t train precision: 0.9811,\t\t test precision: 0.9712\n",
            "Epoch: 1526,\t loss: 0.0008714,\t\t train precision: 0.9818,\t\t test precision: 0.9736\n",
            "Epoch: 1527,\t loss: 0.000898,\t\t train precision: 0.9856,\t\t test precision: 0.9753\n",
            "Epoch: 1528,\t loss: 0.000929,\t\t train precision: 0.9818,\t\t test precision: 0.9703\n",
            "Epoch: 1529,\t loss: 0.0008889,\t\t train precision: 0.9818,\t\t test precision: 0.9745\n",
            "Epoch: 1530,\t loss: 0.0008048,\t\t train precision: 0.9808,\t\t test precision: 0.9761\n",
            "Epoch: 1531,\t loss: 0.0008553,\t\t train precision: 0.9825,\t\t test precision: 0.9794\n",
            "Epoch: 1532,\t loss: 0.0007704,\t\t train precision: 0.9811,\t\t test precision: 0.9753\n",
            "Epoch: 1533,\t loss: 0.0008285,\t\t train precision: 0.9821,\t\t test precision: 0.9736\n",
            "Epoch: 1534,\t loss: 0.0008087,\t\t train precision: 0.9808,\t\t test precision: 0.9728\n",
            "Epoch: 1535,\t loss: 0.0008352,\t\t train precision: 0.9804,\t\t test precision: 0.9753\n",
            "Epoch: 1536,\t loss: 0.0007983,\t\t train precision: 0.9845,\t\t test precision: 0.9745\n",
            "Epoch: 1537,\t loss: 0.0008418,\t\t train precision: 0.9811,\t\t test precision: 0.9736\n",
            "Epoch: 1538,\t loss: 0.0007867,\t\t train precision: 0.9821,\t\t test precision: 0.9745\n",
            "Epoch: 1539,\t loss: 0.0007702,\t\t train precision: 0.9814,\t\t test precision: 0.9703\n",
            "Epoch: 1540,\t loss: 0.0008954,\t\t train precision: 0.9759,\t\t test precision: 0.9703\n",
            "Epoch: 1541,\t loss: 0.0007995,\t\t train precision: 0.979,\t\t test precision: 0.9712\n",
            "Epoch: 1542,\t loss: 0.0008454,\t\t train precision: 0.9814,\t\t test precision: 0.9761\n",
            "Epoch: 1543,\t loss: 0.0008046,\t\t train precision: 0.9835,\t\t test precision: 0.9778\n",
            "Epoch: 1544,\t loss: 0.0008631,\t\t train precision: 0.9801,\t\t test precision: 0.9745\n",
            "Epoch: 1545,\t loss: 0.0008103,\t\t train precision: 0.9828,\t\t test precision: 0.9736\n",
            "Epoch: 1546,\t loss: 0.0007647,\t\t train precision: 0.9801,\t\t test precision: 0.9761\n",
            "Epoch: 1547,\t loss: 0.0008246,\t\t train precision: 0.9797,\t\t test precision: 0.9728\n",
            "Epoch: 1548,\t loss: 0.0008539,\t\t train precision: 0.9832,\t\t test precision: 0.9786\n",
            "Epoch: 1549,\t loss: 0.0007464,\t\t train precision: 0.9828,\t\t test precision: 0.9736\n",
            "Epoch: 1550,\t loss: 0.0007658,\t\t train precision: 0.9859,\t\t test precision: 0.9753\n",
            "Epoch: 1551,\t loss: 0.0008609,\t\t train precision: 0.9838,\t\t test precision: 0.9736\n",
            "Epoch: 1552,\t loss: 0.0007671,\t\t train precision: 0.9811,\t\t test precision: 0.9761\n",
            "Epoch: 1553,\t loss: 0.0008465,\t\t train precision: 0.9825,\t\t test precision: 0.9761\n",
            "Epoch: 1554,\t loss: 0.0008204,\t\t train precision: 0.9821,\t\t test precision: 0.9728\n",
            "Epoch: 1555,\t loss: 0.0008645,\t\t train precision: 0.9787,\t\t test precision: 0.9753\n",
            "Epoch: 1556,\t loss: 0.0007594,\t\t train precision: 0.9832,\t\t test precision: 0.9745\n",
            "Epoch: 1557,\t loss: 0.0007787,\t\t train precision: 0.9828,\t\t test precision: 0.9753\n",
            "Epoch: 1558,\t loss: 0.0009653,\t\t train precision: 0.9821,\t\t test precision: 0.9712\n",
            "Epoch: 1559,\t loss: 0.0008905,\t\t train precision: 0.9825,\t\t test precision: 0.9769\n",
            "Epoch: 1560,\t loss: 0.0007978,\t\t train precision: 0.9784,\t\t test precision: 0.972\n",
            "Epoch: 1561,\t loss: 0.0008678,\t\t train precision: 0.9845,\t\t test precision: 0.9745\n",
            "Epoch: 1562,\t loss: 0.0008632,\t\t train precision: 0.9821,\t\t test precision: 0.9753\n",
            "Epoch: 1563,\t loss: 0.0008613,\t\t train precision: 0.9828,\t\t test precision: 0.9761\n",
            "Epoch: 1564,\t loss: 0.0008165,\t\t train precision: 0.9797,\t\t test precision: 0.9736\n",
            "Epoch: 1565,\t loss: 0.0008684,\t\t train precision: 0.9838,\t\t test precision: 0.9769\n",
            "Epoch: 1566,\t loss: 0.0007995,\t\t train precision: 0.9835,\t\t test precision: 0.9728\n",
            "Epoch: 1567,\t loss: 0.0008071,\t\t train precision: 0.9845,\t\t test precision: 0.9786\n",
            "Epoch: 1568,\t loss: 0.0008297,\t\t train precision: 0.9828,\t\t test precision: 0.9753\n",
            "Epoch: 1569,\t loss: 0.0007938,\t\t train precision: 0.9832,\t\t test precision: 0.9769\n",
            "Epoch: 1570,\t loss: 0.0007709,\t\t train precision: 0.9787,\t\t test precision: 0.972\n",
            "Epoch: 1571,\t loss: 0.0008818,\t\t train precision: 0.9808,\t\t test precision: 0.9745\n",
            "Epoch: 1572,\t loss: 0.0008405,\t\t train precision: 0.9832,\t\t test precision: 0.9761\n",
            "Epoch: 1573,\t loss: 0.0008693,\t\t train precision: 0.9828,\t\t test precision: 0.9778\n",
            "Epoch: 1574,\t loss: 0.0008738,\t\t train precision: 0.9808,\t\t test precision: 0.9778\n",
            "Epoch: 1575,\t loss: 0.0009365,\t\t train precision: 0.9787,\t\t test precision: 0.9712\n",
            "Epoch: 1576,\t loss: 0.0008378,\t\t train precision: 0.9801,\t\t test precision: 0.9753\n",
            "Epoch: 1577,\t loss: 0.0007769,\t\t train precision: 0.9842,\t\t test precision: 0.9761\n",
            "Epoch: 1578,\t loss: 0.0008715,\t\t train precision: 0.9801,\t\t test precision: 0.9794\n",
            "Epoch: 1579,\t loss: 0.0009077,\t\t train precision: 0.9821,\t\t test precision: 0.972\n",
            "Epoch: 1580,\t loss: 0.0008302,\t\t train precision: 0.9814,\t\t test precision: 0.9753\n",
            "Epoch: 1581,\t loss: 0.000881,\t\t train precision: 0.9825,\t\t test precision: 0.9745\n",
            "Epoch: 1582,\t loss: 0.0007991,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 1583,\t loss: 0.0008321,\t\t train precision: 0.9856,\t\t test precision: 0.9794\n",
            "Epoch: 1584,\t loss: 0.0008048,\t\t train precision: 0.9797,\t\t test precision: 0.9769\n",
            "Epoch: 1585,\t loss: 0.0007956,\t\t train precision: 0.9832,\t\t test precision: 0.9769\n",
            "Epoch: 1586,\t loss: 0.000819,\t\t train precision: 0.9804,\t\t test precision: 0.9761\n",
            "Epoch: 1587,\t loss: 0.0008291,\t\t train precision: 0.979,\t\t test precision: 0.9753\n",
            "Epoch: 1588,\t loss: 0.0008614,\t\t train precision: 0.9818,\t\t test precision: 0.9761\n",
            "Epoch: 1589,\t loss: 0.0008412,\t\t train precision: 0.9811,\t\t test precision: 0.9769\n",
            "Epoch: 1590,\t loss: 0.0009003,\t\t train precision: 0.9859,\t\t test precision: 0.9728\n",
            "Epoch: 1591,\t loss: 0.0007703,\t\t train precision: 0.9821,\t\t test precision: 0.9745\n",
            "Epoch: 1592,\t loss: 0.0008986,\t\t train precision: 0.9842,\t\t test precision: 0.9769\n",
            "Epoch: 1593,\t loss: 0.0008156,\t\t train precision: 0.9849,\t\t test precision: 0.9769\n",
            "Epoch: 1594,\t loss: 0.0007596,\t\t train precision: 0.9842,\t\t test precision: 0.9761\n",
            "Epoch: 1595,\t loss: 0.0008474,\t\t train precision: 0.9808,\t\t test precision: 0.9769\n",
            "Epoch: 1596,\t loss: 0.0008079,\t\t train precision: 0.9832,\t\t test precision: 0.9761\n",
            "Epoch: 1597,\t loss: 0.0007495,\t\t train precision: 0.9808,\t\t test precision: 0.9745\n",
            "Epoch: 1598,\t loss: 0.0008394,\t\t train precision: 0.9814,\t\t test precision: 0.9761\n",
            "Epoch: 1599,\t loss: 0.0008338,\t\t train precision: 0.9808,\t\t test precision: 0.9753\n",
            "Epoch: 1600,\t loss: 0.0008166,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 1601,\t loss: 0.0008575,\t\t train precision: 0.9825,\t\t test precision: 0.9786\n",
            "Epoch: 1602,\t loss: 0.0008977,\t\t train precision: 0.9828,\t\t test precision: 0.9769\n",
            "Epoch: 1603,\t loss: 0.0008234,\t\t train precision: 0.9784,\t\t test precision: 0.9687\n",
            "Epoch: 1604,\t loss: 0.0008591,\t\t train precision: 0.9794,\t\t test precision: 0.9703\n",
            "Epoch: 1605,\t loss: 0.0007537,\t\t train precision: 0.9749,\t\t test precision: 0.9703\n",
            "Epoch: 1606,\t loss: 0.0009098,\t\t train precision: 0.9804,\t\t test precision: 0.972\n",
            "Epoch: 1607,\t loss: 0.0007725,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 1608,\t loss: 0.0008428,\t\t train precision: 0.9832,\t\t test precision: 0.9778\n",
            "Epoch: 1609,\t loss: 0.0008503,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 1610,\t loss: 0.0007583,\t\t train precision: 0.9808,\t\t test precision: 0.9769\n",
            "Epoch: 1611,\t loss: 0.0008499,\t\t train precision: 0.9811,\t\t test precision: 0.9728\n",
            "Epoch: 1612,\t loss: 0.0007925,\t\t train precision: 0.9804,\t\t test precision: 0.9769\n",
            "Epoch: 1613,\t loss: 0.0008683,\t\t train precision: 0.9835,\t\t test precision: 0.972\n",
            "Epoch: 1614,\t loss: 0.000799,\t\t train precision: 0.9845,\t\t test precision: 0.9728\n",
            "Epoch: 1615,\t loss: 0.0008297,\t\t train precision: 0.9828,\t\t test precision: 0.9753\n",
            "Epoch: 1616,\t loss: 0.0007655,\t\t train precision: 0.9835,\t\t test precision: 0.9778\n",
            "Epoch: 1617,\t loss: 0.000839,\t\t train precision: 0.9794,\t\t test precision: 0.9745\n",
            "Epoch: 1618,\t loss: 0.0008258,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 1619,\t loss: 0.0008519,\t\t train precision: 0.9787,\t\t test precision: 0.9753\n",
            "Epoch: 1620,\t loss: 0.0007626,\t\t train precision: 0.9832,\t\t test precision: 0.9745\n",
            "Epoch: 1621,\t loss: 0.0007951,\t\t train precision: 0.9808,\t\t test precision: 0.9794\n",
            "Epoch: 1622,\t loss: 0.000801,\t\t train precision: 0.9842,\t\t test precision: 0.9769\n",
            "Epoch: 1623,\t loss: 0.0007976,\t\t train precision: 0.9811,\t\t test precision: 0.9769\n",
            "Epoch: 1624,\t loss: 0.00086,\t\t train precision: 0.9797,\t\t test precision: 0.9728\n",
            "Epoch: 1625,\t loss: 0.0008364,\t\t train precision: 0.9842,\t\t test precision: 0.9761\n",
            "Epoch: 1626,\t loss: 0.0007667,\t\t train precision: 0.9814,\t\t test precision: 0.9769\n",
            "Epoch: 1627,\t loss: 0.0008247,\t\t train precision: 0.9818,\t\t test precision: 0.9786\n",
            "Epoch: 1628,\t loss: 0.0008346,\t\t train precision: 0.9838,\t\t test precision: 0.9761\n",
            "Epoch: 1629,\t loss: 0.0008147,\t\t train precision: 0.9818,\t\t test precision: 0.9712\n",
            "Epoch: 1630,\t loss: 0.0008229,\t\t train precision: 0.9801,\t\t test precision: 0.972\n",
            "Epoch: 1631,\t loss: 0.0008369,\t\t train precision: 0.9808,\t\t test precision: 0.9728\n",
            "Epoch: 1632,\t loss: 0.0008394,\t\t train precision: 0.9835,\t\t test precision: 0.9778\n",
            "Epoch: 1633,\t loss: 0.0007256,\t\t train precision: 0.9794,\t\t test precision: 0.9753\n",
            "Epoch: 1634,\t loss: 0.0007801,\t\t train precision: 0.9794,\t\t test precision: 0.9786\n",
            "Epoch: 1635,\t loss: 0.0007847,\t\t train precision: 0.9842,\t\t test precision: 0.9769\n",
            "Epoch: 1636,\t loss: 0.0008387,\t\t train precision: 0.9842,\t\t test precision: 0.9753\n",
            "Epoch: 1637,\t loss: 0.0008211,\t\t train precision: 0.9808,\t\t test precision: 0.9786\n",
            "Epoch: 1638,\t loss: 0.0008472,\t\t train precision: 0.9794,\t\t test precision: 0.9753\n",
            "Epoch: 1639,\t loss: 0.0007804,\t\t train precision: 0.9835,\t\t test precision: 0.9761\n",
            "Epoch: 1640,\t loss: 0.0007869,\t\t train precision: 0.9794,\t\t test precision: 0.9736\n",
            "Epoch: 1641,\t loss: 0.0008001,\t\t train precision: 0.9821,\t\t test precision: 0.9728\n",
            "Epoch: 1642,\t loss: 0.0008269,\t\t train precision: 0.9797,\t\t test precision: 0.972\n",
            "Epoch: 1643,\t loss: 0.0008259,\t\t train precision: 0.9838,\t\t test precision: 0.9786\n",
            "Epoch: 1644,\t loss: 0.0007877,\t\t train precision: 0.9811,\t\t test precision: 0.9761\n",
            "Epoch: 1645,\t loss: 0.0007981,\t\t train precision: 0.9784,\t\t test precision: 0.9753\n",
            "Epoch: 1646,\t loss: 0.0007667,\t\t train precision: 0.9818,\t\t test precision: 0.9778\n",
            "Epoch: 1647,\t loss: 0.000866,\t\t train precision: 0.9828,\t\t test precision: 0.9745\n",
            "Epoch: 1648,\t loss: 0.0008891,\t\t train precision: 0.9808,\t\t test precision: 0.9728\n",
            "Epoch: 1649,\t loss: 0.000721,\t\t train precision: 0.9821,\t\t test precision: 0.9745\n",
            "Epoch: 1650,\t loss: 0.0007666,\t\t train precision: 0.9825,\t\t test precision: 0.972\n",
            "Epoch: 1651,\t loss: 0.0007678,\t\t train precision: 0.9842,\t\t test precision: 0.9745\n",
            "Epoch: 1652,\t loss: 0.0007611,\t\t train precision: 0.9842,\t\t test precision: 0.9745\n",
            "Epoch: 1653,\t loss: 0.0007813,\t\t train precision: 0.9842,\t\t test precision: 0.9778\n",
            "Epoch: 1654,\t loss: 0.0008235,\t\t train precision: 0.9821,\t\t test precision: 0.9778\n",
            "Epoch: 1655,\t loss: 0.0007871,\t\t train precision: 0.9821,\t\t test precision: 0.9753\n",
            "Epoch: 1656,\t loss: 0.0007457,\t\t train precision: 0.9797,\t\t test precision: 0.9712\n",
            "Epoch: 1657,\t loss: 0.0008204,\t\t train precision: 0.9808,\t\t test precision: 0.9753\n",
            "Epoch: 1658,\t loss: 0.0008106,\t\t train precision: 0.9838,\t\t test precision: 0.9778\n",
            "Epoch: 1659,\t loss: 0.0008099,\t\t train precision: 0.9828,\t\t test precision: 0.9769\n",
            "Epoch: 1660,\t loss: 0.0008541,\t\t train precision: 0.9828,\t\t test precision: 0.9761\n",
            "Epoch: 1661,\t loss: 0.000822,\t\t train precision: 0.9784,\t\t test precision: 0.972\n",
            "Epoch: 1662,\t loss: 0.0008335,\t\t train precision: 0.9835,\t\t test precision: 0.9786\n",
            "Epoch: 1663,\t loss: 0.0007939,\t\t train precision: 0.979,\t\t test precision: 0.9695\n",
            "Epoch: 1664,\t loss: 0.0008339,\t\t train precision: 0.9784,\t\t test precision: 0.9753\n",
            "Epoch: 1665,\t loss: 0.0008249,\t\t train precision: 0.9797,\t\t test precision: 0.9745\n",
            "Epoch: 1666,\t loss: 0.0008563,\t\t train precision: 0.9797,\t\t test precision: 0.9712\n",
            "Epoch: 1667,\t loss: 0.0007874,\t\t train precision: 0.9804,\t\t test precision: 0.9728\n",
            "Epoch: 1668,\t loss: 0.0008059,\t\t train precision: 0.9818,\t\t test precision: 0.9728\n",
            "Epoch: 1669,\t loss: 0.0008414,\t\t train precision: 0.9811,\t\t test precision: 0.9736\n",
            "Epoch: 1670,\t loss: 0.0008239,\t\t train precision: 0.9845,\t\t test precision: 0.9778\n",
            "Epoch: 1671,\t loss: 0.0007273,\t\t train precision: 0.9838,\t\t test precision: 0.9753\n",
            "Epoch: 1672,\t loss: 0.0008014,\t\t train precision: 0.9784,\t\t test precision: 0.9728\n",
            "Epoch: 1673,\t loss: 0.0008359,\t\t train precision: 0.9842,\t\t test precision: 0.9736\n",
            "Epoch: 1674,\t loss: 0.0007523,\t\t train precision: 0.9849,\t\t test precision: 0.9761\n",
            "Epoch: 1675,\t loss: 0.0007512,\t\t train precision: 0.9814,\t\t test precision: 0.9753\n",
            "Epoch: 1676,\t loss: 0.0008768,\t\t train precision: 0.978,\t\t test precision: 0.9736\n",
            "Epoch: 1677,\t loss: 0.0008358,\t\t train precision: 0.9808,\t\t test precision: 0.9778\n",
            "Epoch: 1678,\t loss: 0.0008282,\t\t train precision: 0.9856,\t\t test precision: 0.9769\n",
            "Epoch: 1679,\t loss: 0.0007801,\t\t train precision: 0.9797,\t\t test precision: 0.9753\n",
            "Epoch: 1680,\t loss: 0.0008117,\t\t train precision: 0.9859,\t\t test precision: 0.9769\n",
            "Epoch: 1681,\t loss: 0.0008289,\t\t train precision: 0.9818,\t\t test precision: 0.9769\n",
            "Epoch: 1682,\t loss: 0.0008665,\t\t train precision: 0.9821,\t\t test precision: 0.9769\n",
            "Epoch: 1683,\t loss: 0.0009109,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 1684,\t loss: 0.0008425,\t\t train precision: 0.9821,\t\t test precision: 0.9736\n",
            "Epoch: 1685,\t loss: 0.0007669,\t\t train precision: 0.9832,\t\t test precision: 0.9745\n",
            "Epoch: 1686,\t loss: 0.0008586,\t\t train precision: 0.9735,\t\t test precision: 0.9712\n",
            "Epoch: 1687,\t loss: 0.0007884,\t\t train precision: 0.979,\t\t test precision: 0.9753\n",
            "Epoch: 1688,\t loss: 0.0008763,\t\t train precision: 0.9818,\t\t test precision: 0.9728\n",
            "Epoch: 1689,\t loss: 0.0007557,\t\t train precision: 0.9811,\t\t test precision: 0.972\n",
            "Epoch: 1690,\t loss: 0.0008114,\t\t train precision: 0.9808,\t\t test precision: 0.9753\n",
            "Epoch: 1691,\t loss: 0.0008087,\t\t train precision: 0.9838,\t\t test precision: 0.9778\n",
            "Epoch: 1692,\t loss: 0.0008053,\t\t train precision: 0.9821,\t\t test precision: 0.972\n",
            "Epoch: 1693,\t loss: 0.0008614,\t\t train precision: 0.979,\t\t test precision: 0.972\n",
            "Epoch: 1694,\t loss: 0.000861,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 1695,\t loss: 0.0008124,\t\t train precision: 0.9838,\t\t test precision: 0.9761\n",
            "Epoch: 1696,\t loss: 0.0007965,\t\t train precision: 0.9849,\t\t test precision: 0.9745\n",
            "Epoch: 1697,\t loss: 0.0007778,\t\t train precision: 0.9804,\t\t test precision: 0.9745\n",
            "Epoch: 1698,\t loss: 0.0008154,\t\t train precision: 0.9825,\t\t test precision: 0.9728\n",
            "Epoch: 1699,\t loss: 0.0008525,\t\t train precision: 0.9832,\t\t test precision: 0.9753\n",
            "Epoch: 1700,\t loss: 0.0008607,\t\t train precision: 0.9814,\t\t test precision: 0.9769\n",
            "Epoch: 1701,\t loss: 0.0008151,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 1702,\t loss: 0.000821,\t\t train precision: 0.9845,\t\t test precision: 0.9778\n",
            "Epoch: 1703,\t loss: 0.000766,\t\t train precision: 0.9821,\t\t test precision: 0.9778\n",
            "Epoch: 1704,\t loss: 0.000805,\t\t train precision: 0.9832,\t\t test precision: 0.9753\n",
            "Epoch: 1705,\t loss: 0.0007935,\t\t train precision: 0.9835,\t\t test precision: 0.9736\n",
            "Epoch: 1706,\t loss: 0.000809,\t\t train precision: 0.9804,\t\t test precision: 0.9769\n",
            "Epoch: 1707,\t loss: 0.0007225,\t\t train precision: 0.9821,\t\t test precision: 0.9753\n",
            "Epoch: 1708,\t loss: 0.000769,\t\t train precision: 0.9818,\t\t test precision: 0.9769\n",
            "Epoch: 1709,\t loss: 0.0008152,\t\t train precision: 0.9811,\t\t test precision: 0.9769\n",
            "Epoch: 1710,\t loss: 0.0007052,\t\t train precision: 0.9835,\t\t test precision: 0.9753\n",
            "Epoch: 1711,\t loss: 0.0008001,\t\t train precision: 0.9821,\t\t test precision: 0.9753\n",
            "Epoch: 1712,\t loss: 0.0008228,\t\t train precision: 0.9825,\t\t test precision: 0.9778\n",
            "Epoch: 1713,\t loss: 0.0007706,\t\t train precision: 0.9797,\t\t test precision: 0.9736\n",
            "Epoch: 1714,\t loss: 0.0007442,\t\t train precision: 0.9818,\t\t test precision: 0.972\n",
            "Epoch: 1715,\t loss: 0.0007714,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 1716,\t loss: 0.0007668,\t\t train precision: 0.9832,\t\t test precision: 0.9769\n",
            "Epoch: 1717,\t loss: 0.0007772,\t\t train precision: 0.9832,\t\t test precision: 0.9769\n",
            "Epoch: 1718,\t loss: 0.0007608,\t\t train precision: 0.9828,\t\t test precision: 0.9736\n",
            "Epoch: 1719,\t loss: 0.0007964,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 1720,\t loss: 0.0007677,\t\t train precision: 0.9777,\t\t test precision: 0.972\n",
            "Epoch: 1721,\t loss: 0.0008494,\t\t train precision: 0.9818,\t\t test precision: 0.9736\n",
            "Epoch: 1722,\t loss: 0.000786,\t\t train precision: 0.9797,\t\t test precision: 0.9736\n",
            "Epoch: 1723,\t loss: 0.0008524,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 1724,\t loss: 0.0007909,\t\t train precision: 0.9814,\t\t test precision: 0.9753\n",
            "Epoch: 1725,\t loss: 0.000746,\t\t train precision: 0.9835,\t\t test precision: 0.9745\n",
            "Epoch: 1726,\t loss: 0.0008109,\t\t train precision: 0.9811,\t\t test precision: 0.9728\n",
            "Epoch: 1727,\t loss: 0.0008032,\t\t train precision: 0.9801,\t\t test precision: 0.9712\n",
            "Epoch: 1728,\t loss: 0.0008413,\t\t train precision: 0.9808,\t\t test precision: 0.9769\n",
            "Epoch: 1729,\t loss: 0.0007813,\t\t train precision: 0.9825,\t\t test precision: 0.9769\n",
            "Epoch: 1730,\t loss: 0.0008698,\t\t train precision: 0.9838,\t\t test precision: 0.972\n",
            "Epoch: 1731,\t loss: 0.0007836,\t\t train precision: 0.9859,\t\t test precision: 0.9745\n",
            "Epoch: 1732,\t loss: 0.0007852,\t\t train precision: 0.9842,\t\t test precision: 0.9769\n",
            "Epoch: 1733,\t loss: 0.0008128,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 1734,\t loss: 0.0007681,\t\t train precision: 0.9835,\t\t test precision: 0.9736\n",
            "Epoch: 1735,\t loss: 0.0008874,\t\t train precision: 0.9838,\t\t test precision: 0.9778\n",
            "Epoch: 1736,\t loss: 0.000832,\t\t train precision: 0.9787,\t\t test precision: 0.9695\n",
            "Epoch: 1737,\t loss: 0.0007481,\t\t train precision: 0.9838,\t\t test precision: 0.9778\n",
            "Epoch: 1738,\t loss: 0.000907,\t\t train precision: 0.9821,\t\t test precision: 0.9736\n",
            "Epoch: 1739,\t loss: 0.0008293,\t\t train precision: 0.9814,\t\t test precision: 0.9769\n",
            "Epoch: 1740,\t loss: 0.0008412,\t\t train precision: 0.979,\t\t test precision: 0.9769\n",
            "Epoch: 1741,\t loss: 0.0007706,\t\t train precision: 0.9811,\t\t test precision: 0.9769\n",
            "Epoch: 1742,\t loss: 0.0008303,\t\t train precision: 0.9794,\t\t test precision: 0.9761\n",
            "Epoch: 1743,\t loss: 0.0008682,\t\t train precision: 0.9845,\t\t test precision: 0.972\n",
            "Epoch: 1744,\t loss: 0.0008273,\t\t train precision: 0.9804,\t\t test precision: 0.9778\n",
            "Epoch: 1745,\t loss: 0.0008348,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 1746,\t loss: 0.0007993,\t\t train precision: 0.9852,\t\t test precision: 0.9778\n",
            "Epoch: 1747,\t loss: 0.0008214,\t\t train precision: 0.9808,\t\t test precision: 0.9736\n",
            "Epoch: 1748,\t loss: 0.0008126,\t\t train precision: 0.9821,\t\t test precision: 0.9778\n",
            "Epoch: 1749,\t loss: 0.0008769,\t\t train precision: 0.9845,\t\t test precision: 0.9778\n",
            "Epoch: 1750,\t loss: 0.0007776,\t\t train precision: 0.9784,\t\t test precision: 0.9736\n",
            "Epoch: 1751,\t loss: 0.0007972,\t\t train precision: 0.9784,\t\t test precision: 0.9712\n",
            "Epoch: 1752,\t loss: 0.000828,\t\t train precision: 0.9825,\t\t test precision: 0.972\n",
            "Epoch: 1753,\t loss: 0.0008541,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 1754,\t loss: 0.0008377,\t\t train precision: 0.9801,\t\t test precision: 0.9769\n",
            "Epoch: 1755,\t loss: 0.0009143,\t\t train precision: 0.9814,\t\t test precision: 0.9728\n",
            "Epoch: 1756,\t loss: 0.0007714,\t\t train precision: 0.9821,\t\t test precision: 0.9786\n",
            "Epoch: 1757,\t loss: 0.0008411,\t\t train precision: 0.9811,\t\t test precision: 0.9769\n",
            "Epoch: 1758,\t loss: 0.0008911,\t\t train precision: 0.9808,\t\t test precision: 0.9728\n",
            "Epoch: 1759,\t loss: 0.0007403,\t\t train precision: 0.9859,\t\t test precision: 0.9761\n",
            "Epoch: 1760,\t loss: 0.0007987,\t\t train precision: 0.9808,\t\t test precision: 0.9728\n",
            "Epoch: 1761,\t loss: 0.0008791,\t\t train precision: 0.9773,\t\t test precision: 0.9703\n",
            "Epoch: 1762,\t loss: 0.0007846,\t\t train precision: 0.9784,\t\t test precision: 0.972\n",
            "Epoch: 1763,\t loss: 0.0008324,\t\t train precision: 0.9825,\t\t test precision: 0.9778\n",
            "Epoch: 1764,\t loss: 0.0008524,\t\t train precision: 0.9821,\t\t test precision: 0.9745\n",
            "Epoch: 1765,\t loss: 0.0007265,\t\t train precision: 0.9849,\t\t test precision: 0.9753\n",
            "Epoch: 1766,\t loss: 0.0008602,\t\t train precision: 0.9838,\t\t test precision: 0.9761\n",
            "Epoch: 1767,\t loss: 0.0008597,\t\t train precision: 0.9818,\t\t test precision: 0.9778\n",
            "Epoch: 1768,\t loss: 0.0008352,\t\t train precision: 0.9797,\t\t test precision: 0.9753\n",
            "Epoch: 1769,\t loss: 0.0007704,\t\t train precision: 0.9835,\t\t test precision: 0.9761\n",
            "Epoch: 1770,\t loss: 0.0007525,\t\t train precision: 0.9838,\t\t test precision: 0.9745\n",
            "Epoch: 1771,\t loss: 0.0008528,\t\t train precision: 0.9811,\t\t test precision: 0.9778\n",
            "Epoch: 1772,\t loss: 0.0007817,\t\t train precision: 0.9808,\t\t test precision: 0.9745\n",
            "Epoch: 1773,\t loss: 0.0007916,\t\t train precision: 0.9804,\t\t test precision: 0.9761\n",
            "Epoch: 1774,\t loss: 0.0008089,\t\t train precision: 0.9818,\t\t test precision: 0.9736\n",
            "Epoch: 1775,\t loss: 0.0008007,\t\t train precision: 0.9804,\t\t test precision: 0.9728\n",
            "Epoch: 1776,\t loss: 0.0007461,\t\t train precision: 0.9838,\t\t test precision: 0.9778\n",
            "Epoch: 1777,\t loss: 0.0007609,\t\t train precision: 0.978,\t\t test precision: 0.9728\n",
            "Epoch: 1778,\t loss: 0.0007501,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 1779,\t loss: 0.0008495,\t\t train precision: 0.9821,\t\t test precision: 0.9745\n",
            "Epoch: 1780,\t loss: 0.0007333,\t\t train precision: 0.9794,\t\t test precision: 0.9745\n",
            "Epoch: 1781,\t loss: 0.0008247,\t\t train precision: 0.9832,\t\t test precision: 0.9736\n",
            "Epoch: 1782,\t loss: 0.0008768,\t\t train precision: 0.9777,\t\t test precision: 0.9712\n",
            "Epoch: 1783,\t loss: 0.0008012,\t\t train precision: 0.9825,\t\t test precision: 0.9745\n",
            "Epoch: 1784,\t loss: 0.0007677,\t\t train precision: 0.9797,\t\t test precision: 0.9778\n",
            "Epoch: 1785,\t loss: 0.0008912,\t\t train precision: 0.9838,\t\t test precision: 0.9728\n",
            "Epoch: 1786,\t loss: 0.0008397,\t\t train precision: 0.9852,\t\t test precision: 0.9794\n",
            "Epoch: 1787,\t loss: 0.000803,\t\t train precision: 0.9828,\t\t test precision: 0.9703\n",
            "Epoch: 1788,\t loss: 0.0008373,\t\t train precision: 0.9818,\t\t test precision: 0.9728\n",
            "Epoch: 1789,\t loss: 0.0007443,\t\t train precision: 0.9852,\t\t test precision: 0.9745\n",
            "Epoch: 1790,\t loss: 0.0007659,\t\t train precision: 0.9811,\t\t test precision: 0.9753\n",
            "Epoch: 1791,\t loss: 0.0008436,\t\t train precision: 0.9849,\t\t test precision: 0.9745\n",
            "Epoch: 1792,\t loss: 0.0007967,\t\t train precision: 0.9804,\t\t test precision: 0.9736\n",
            "Epoch: 1793,\t loss: 0.0008394,\t\t train precision: 0.9828,\t\t test precision: 0.9745\n",
            "Epoch: 1794,\t loss: 0.0007895,\t\t train precision: 0.9821,\t\t test precision: 0.9745\n",
            "Epoch: 1795,\t loss: 0.0007852,\t\t train precision: 0.9801,\t\t test precision: 0.9728\n",
            "Epoch: 1796,\t loss: 0.0007878,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 1797,\t loss: 0.0008265,\t\t train precision: 0.9832,\t\t test precision: 0.9736\n",
            "Epoch: 1798,\t loss: 0.0008286,\t\t train precision: 0.9835,\t\t test precision: 0.9753\n",
            "Epoch: 1799,\t loss: 0.0007411,\t\t train precision: 0.9801,\t\t test precision: 0.9745\n",
            "Epoch: 1800,\t loss: 0.0007472,\t\t train precision: 0.9808,\t\t test precision: 0.9703\n",
            "Epoch: 1801,\t loss: 0.0007527,\t\t train precision: 0.9838,\t\t test precision: 0.9736\n",
            "Epoch: 1802,\t loss: 0.0008091,\t\t train precision: 0.9808,\t\t test precision: 0.9745\n",
            "Epoch: 1803,\t loss: 0.0008038,\t\t train precision: 0.9821,\t\t test precision: 0.9687\n",
            "Epoch: 1804,\t loss: 0.000826,\t\t train precision: 0.9859,\t\t test precision: 0.9778\n",
            "Epoch: 1805,\t loss: 0.0007574,\t\t train precision: 0.9814,\t\t test precision: 0.9753\n",
            "Epoch: 1806,\t loss: 0.0007877,\t\t train precision: 0.9835,\t\t test precision: 0.9769\n",
            "Epoch: 1807,\t loss: 0.0007558,\t\t train precision: 0.9797,\t\t test precision: 0.9703\n",
            "Epoch: 1808,\t loss: 0.0008746,\t\t train precision: 0.9801,\t\t test precision: 0.9761\n",
            "Epoch: 1809,\t loss: 0.0008539,\t\t train precision: 0.9773,\t\t test precision: 0.9736\n",
            "Epoch: 1810,\t loss: 0.0007921,\t\t train precision: 0.9797,\t\t test precision: 0.9695\n",
            "Epoch: 1811,\t loss: 0.0008085,\t\t train precision: 0.9832,\t\t test precision: 0.9769\n",
            "Epoch: 1812,\t loss: 0.0008618,\t\t train precision: 0.9811,\t\t test precision: 0.9761\n",
            "Epoch: 1813,\t loss: 0.0008337,\t\t train precision: 0.9842,\t\t test precision: 0.9778\n",
            "Epoch: 1814,\t loss: 0.000817,\t\t train precision: 0.9811,\t\t test precision: 0.972\n",
            "Epoch: 1815,\t loss: 0.0008357,\t\t train precision: 0.9814,\t\t test precision: 0.9736\n",
            "Epoch: 1816,\t loss: 0.0007511,\t\t train precision: 0.9832,\t\t test precision: 0.9736\n",
            "Epoch: 1817,\t loss: 0.0007851,\t\t train precision: 0.9832,\t\t test precision: 0.9761\n",
            "Epoch: 1818,\t loss: 0.0008208,\t\t train precision: 0.9787,\t\t test precision: 0.9745\n",
            "Epoch: 1819,\t loss: 0.0008246,\t\t train precision: 0.9766,\t\t test precision: 0.9703\n",
            "Epoch: 1820,\t loss: 0.0008295,\t\t train precision: 0.9832,\t\t test precision: 0.972\n",
            "Epoch: 1821,\t loss: 0.0007808,\t\t train precision: 0.9832,\t\t test precision: 0.9753\n",
            "Epoch: 1822,\t loss: 0.0007644,\t\t train precision: 0.9835,\t\t test precision: 0.9761\n",
            "Epoch: 1823,\t loss: 0.0007389,\t\t train precision: 0.9838,\t\t test precision: 0.9736\n",
            "Epoch: 1824,\t loss: 0.0008249,\t\t train precision: 0.9773,\t\t test precision: 0.9654\n",
            "Epoch: 1825,\t loss: 0.0007833,\t\t train precision: 0.9832,\t\t test precision: 0.9736\n",
            "Epoch: 1826,\t loss: 0.0007648,\t\t train precision: 0.9845,\t\t test precision: 0.9736\n",
            "Epoch: 1827,\t loss: 0.0007355,\t\t train precision: 0.9821,\t\t test precision: 0.9745\n",
            "Epoch: 1828,\t loss: 0.0008703,\t\t train precision: 0.9832,\t\t test precision: 0.9769\n",
            "Epoch: 1829,\t loss: 0.000756,\t\t train precision: 0.9801,\t\t test precision: 0.9745\n",
            "Epoch: 1830,\t loss: 0.000787,\t\t train precision: 0.9842,\t\t test precision: 0.9736\n",
            "Epoch: 1831,\t loss: 0.0008245,\t\t train precision: 0.9835,\t\t test precision: 0.9753\n",
            "Epoch: 1832,\t loss: 0.0008151,\t\t train precision: 0.9832,\t\t test precision: 0.9769\n",
            "Epoch: 1833,\t loss: 0.0008093,\t\t train precision: 0.9825,\t\t test precision: 0.9728\n",
            "Epoch: 1834,\t loss: 0.000858,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 1835,\t loss: 0.0008327,\t\t train precision: 0.9784,\t\t test precision: 0.9745\n",
            "Epoch: 1836,\t loss: 0.000878,\t\t train precision: 0.9797,\t\t test precision: 0.9786\n",
            "Epoch: 1837,\t loss: 0.0007744,\t\t train precision: 0.9825,\t\t test precision: 0.9778\n",
            "Epoch: 1838,\t loss: 0.0007648,\t\t train precision: 0.9801,\t\t test precision: 0.9745\n",
            "Epoch: 1839,\t loss: 0.0008206,\t\t train precision: 0.9828,\t\t test precision: 0.9761\n",
            "Epoch: 1840,\t loss: 0.0007873,\t\t train precision: 0.9784,\t\t test precision: 0.9703\n",
            "Epoch: 1841,\t loss: 0.0008574,\t\t train precision: 0.9832,\t\t test precision: 0.9778\n",
            "Epoch: 1842,\t loss: 0.0007939,\t\t train precision: 0.9818,\t\t test precision: 0.9769\n",
            "Epoch: 1843,\t loss: 0.0006815,\t\t train precision: 0.9821,\t\t test precision: 0.9753\n",
            "Epoch: 1844,\t loss: 0.0008249,\t\t train precision: 0.9838,\t\t test precision: 0.9745\n",
            "Epoch: 1845,\t loss: 0.0008404,\t\t train precision: 0.9832,\t\t test precision: 0.9753\n",
            "Epoch: 1846,\t loss: 0.0007958,\t\t train precision: 0.9811,\t\t test precision: 0.972\n",
            "Epoch: 1847,\t loss: 0.0007188,\t\t train precision: 0.9828,\t\t test precision: 0.9753\n",
            "Epoch: 1848,\t loss: 0.0008764,\t\t train precision: 0.9818,\t\t test precision: 0.9761\n",
            "Epoch: 1849,\t loss: 0.0007838,\t\t train precision: 0.9821,\t\t test precision: 0.972\n",
            "Epoch: 1850,\t loss: 0.000741,\t\t train precision: 0.9808,\t\t test precision: 0.9728\n",
            "Epoch: 1851,\t loss: 0.0007703,\t\t train precision: 0.9801,\t\t test precision: 0.9745\n",
            "Epoch: 1852,\t loss: 0.000789,\t\t train precision: 0.9797,\t\t test precision: 0.9728\n",
            "Epoch: 1853,\t loss: 0.0008161,\t\t train precision: 0.9804,\t\t test precision: 0.9728\n",
            "Epoch: 1854,\t loss: 0.0008102,\t\t train precision: 0.9838,\t\t test precision: 0.9761\n",
            "Epoch: 1855,\t loss: 0.0007637,\t\t train precision: 0.9832,\t\t test precision: 0.9753\n",
            "Epoch: 1856,\t loss: 0.0007265,\t\t train precision: 0.9835,\t\t test precision: 0.9761\n",
            "Epoch: 1857,\t loss: 0.0007626,\t\t train precision: 0.9856,\t\t test precision: 0.9778\n",
            "Epoch: 1858,\t loss: 0.0007526,\t\t train precision: 0.9845,\t\t test precision: 0.9761\n",
            "Epoch: 1859,\t loss: 0.0008182,\t\t train precision: 0.9811,\t\t test precision: 0.9769\n",
            "Epoch: 1860,\t loss: 0.0008304,\t\t train precision: 0.9856,\t\t test precision: 0.9786\n",
            "Epoch: 1861,\t loss: 0.0007422,\t\t train precision: 0.9849,\t\t test precision: 0.9786\n",
            "Epoch: 1862,\t loss: 0.0007167,\t\t train precision: 0.9828,\t\t test precision: 0.9769\n",
            "Epoch: 1863,\t loss: 0.0008529,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 1864,\t loss: 0.0008851,\t\t train precision: 0.9801,\t\t test precision: 0.9736\n",
            "Epoch: 1865,\t loss: 0.0007074,\t\t train precision: 0.9797,\t\t test precision: 0.9712\n",
            "Epoch: 1866,\t loss: 0.0008684,\t\t train precision: 0.9814,\t\t test precision: 0.9736\n",
            "Epoch: 1867,\t loss: 0.0007209,\t\t train precision: 0.9838,\t\t test precision: 0.9761\n",
            "Epoch: 1868,\t loss: 0.0008451,\t\t train precision: 0.9825,\t\t test precision: 0.9736\n",
            "Epoch: 1869,\t loss: 0.0007816,\t\t train precision: 0.9818,\t\t test precision: 0.9728\n",
            "Epoch: 1870,\t loss: 0.0007427,\t\t train precision: 0.9825,\t\t test precision: 0.9745\n",
            "Epoch: 1871,\t loss: 0.000726,\t\t train precision: 0.9842,\t\t test precision: 0.9761\n",
            "Epoch: 1872,\t loss: 0.0007462,\t\t train precision: 0.9825,\t\t test precision: 0.9761\n",
            "Epoch: 1873,\t loss: 0.0007352,\t\t train precision: 0.9828,\t\t test precision: 0.9761\n",
            "Epoch: 1874,\t loss: 0.0008103,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 1875,\t loss: 0.0008144,\t\t train precision: 0.9808,\t\t test precision: 0.9753\n",
            "Epoch: 1876,\t loss: 0.0007733,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 1877,\t loss: 0.0007881,\t\t train precision: 0.979,\t\t test precision: 0.972\n",
            "Epoch: 1878,\t loss: 0.0007825,\t\t train precision: 0.9856,\t\t test precision: 0.9769\n",
            "Epoch: 1879,\t loss: 0.0008095,\t\t train precision: 0.9825,\t\t test precision: 0.9778\n",
            "Epoch: 1880,\t loss: 0.0008692,\t\t train precision: 0.9811,\t\t test precision: 0.9753\n",
            "Epoch: 1881,\t loss: 0.0007926,\t\t train precision: 0.9814,\t\t test precision: 0.9736\n",
            "Epoch: 1882,\t loss: 0.0008052,\t\t train precision: 0.9835,\t\t test precision: 0.9736\n",
            "Epoch: 1883,\t loss: 0.0007738,\t\t train precision: 0.9842,\t\t test precision: 0.9769\n",
            "Epoch: 1884,\t loss: 0.0007359,\t\t train precision: 0.9838,\t\t test precision: 0.9745\n",
            "Epoch: 1885,\t loss: 0.0007806,\t\t train precision: 0.9818,\t\t test precision: 0.9736\n",
            "Epoch: 1886,\t loss: 0.0007661,\t\t train precision: 0.9784,\t\t test precision: 0.9736\n",
            "Epoch: 1887,\t loss: 0.0007341,\t\t train precision: 0.9797,\t\t test precision: 0.9728\n",
            "Epoch: 1888,\t loss: 0.0007795,\t\t train precision: 0.9821,\t\t test precision: 0.9769\n",
            "Epoch: 1889,\t loss: 0.0008444,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 1890,\t loss: 0.0007496,\t\t train precision: 0.9845,\t\t test precision: 0.9786\n",
            "Epoch: 1891,\t loss: 0.0007248,\t\t train precision: 0.9838,\t\t test precision: 0.9753\n",
            "Epoch: 1892,\t loss: 0.0007572,\t\t train precision: 0.9856,\t\t test precision: 0.9778\n",
            "Epoch: 1893,\t loss: 0.0007528,\t\t train precision: 0.9804,\t\t test precision: 0.9761\n",
            "Epoch: 1894,\t loss: 0.0008305,\t\t train precision: 0.9832,\t\t test precision: 0.9753\n",
            "Epoch: 1895,\t loss: 0.000754,\t\t train precision: 0.9832,\t\t test precision: 0.9761\n",
            "Epoch: 1896,\t loss: 0.0008525,\t\t train precision: 0.9825,\t\t test precision: 0.9761\n",
            "Epoch: 1897,\t loss: 0.0008255,\t\t train precision: 0.9777,\t\t test precision: 0.9695\n",
            "Epoch: 1898,\t loss: 0.0007631,\t\t train precision: 0.9828,\t\t test precision: 0.9745\n",
            "Epoch: 1899,\t loss: 0.0007443,\t\t train precision: 0.9832,\t\t test precision: 0.9703\n",
            "Epoch: 1900,\t loss: 0.0007761,\t\t train precision: 0.9821,\t\t test precision: 0.9712\n",
            "Epoch: 1901,\t loss: 0.0007226,\t\t train precision: 0.9773,\t\t test precision: 0.9687\n",
            "Epoch: 1902,\t loss: 0.0007826,\t\t train precision: 0.9835,\t\t test precision: 0.9753\n",
            "Epoch: 1903,\t loss: 0.0007883,\t\t train precision: 0.9849,\t\t test precision: 0.9761\n",
            "Epoch: 1904,\t loss: 0.0008379,\t\t train precision: 0.9811,\t\t test precision: 0.9728\n",
            "Epoch: 1905,\t loss: 0.0007783,\t\t train precision: 0.9794,\t\t test precision: 0.9745\n",
            "Epoch: 1906,\t loss: 0.0007446,\t\t train precision: 0.979,\t\t test precision: 0.9736\n",
            "Epoch: 1907,\t loss: 0.0007177,\t\t train precision: 0.9832,\t\t test precision: 0.9761\n",
            "Epoch: 1908,\t loss: 0.0008061,\t\t train precision: 0.9856,\t\t test precision: 0.9761\n",
            "Epoch: 1909,\t loss: 0.0007985,\t\t train precision: 0.9842,\t\t test precision: 0.9736\n",
            "Epoch: 1910,\t loss: 0.0008146,\t\t train precision: 0.9842,\t\t test precision: 0.9736\n",
            "Epoch: 1911,\t loss: 0.0007627,\t\t train precision: 0.9825,\t\t test precision: 0.9745\n",
            "Epoch: 1912,\t loss: 0.0007462,\t\t train precision: 0.9828,\t\t test precision: 0.972\n",
            "Epoch: 1913,\t loss: 0.0007261,\t\t train precision: 0.9801,\t\t test precision: 0.9753\n",
            "Epoch: 1914,\t loss: 0.0008863,\t\t train precision: 0.9814,\t\t test precision: 0.9712\n",
            "Epoch: 1915,\t loss: 0.0007614,\t\t train precision: 0.9787,\t\t test precision: 0.9745\n",
            "Epoch: 1916,\t loss: 0.000799,\t\t train precision: 0.9804,\t\t test precision: 0.9761\n",
            "Epoch: 1917,\t loss: 0.0008097,\t\t train precision: 0.9825,\t\t test precision: 0.9769\n",
            "Epoch: 1918,\t loss: 0.000775,\t\t train precision: 0.9763,\t\t test precision: 0.9671\n",
            "Epoch: 1919,\t loss: 0.0008162,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 1920,\t loss: 0.0007681,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 1921,\t loss: 0.0008866,\t\t train precision: 0.9804,\t\t test precision: 0.9728\n",
            "Epoch: 1922,\t loss: 0.0008059,\t\t train precision: 0.9835,\t\t test precision: 0.9761\n",
            "Epoch: 1923,\t loss: 0.0007809,\t\t train precision: 0.9821,\t\t test precision: 0.9753\n",
            "Epoch: 1924,\t loss: 0.0006867,\t\t train precision: 0.9835,\t\t test precision: 0.9769\n",
            "Epoch: 1925,\t loss: 0.0008975,\t\t train precision: 0.9828,\t\t test precision: 0.9778\n",
            "Epoch: 1926,\t loss: 0.0006861,\t\t train precision: 0.9835,\t\t test precision: 0.9736\n",
            "Epoch: 1927,\t loss: 0.0007567,\t\t train precision: 0.9811,\t\t test precision: 0.9736\n",
            "Epoch: 1928,\t loss: 0.000747,\t\t train precision: 0.9814,\t\t test precision: 0.972\n",
            "Epoch: 1929,\t loss: 0.000764,\t\t train precision: 0.9859,\t\t test precision: 0.9736\n",
            "Epoch: 1930,\t loss: 0.0008053,\t\t train precision: 0.9811,\t\t test precision: 0.9745\n",
            "Epoch: 1931,\t loss: 0.000784,\t\t train precision: 0.9797,\t\t test precision: 0.9753\n",
            "Epoch: 1932,\t loss: 0.0007683,\t\t train precision: 0.9811,\t\t test precision: 0.9769\n",
            "Epoch: 1933,\t loss: 0.000788,\t\t train precision: 0.9821,\t\t test precision: 0.9753\n",
            "Epoch: 1934,\t loss: 0.0007237,\t\t train precision: 0.9832,\t\t test precision: 0.972\n",
            "Epoch: 1935,\t loss: 0.0007223,\t\t train precision: 0.9818,\t\t test precision: 0.9745\n",
            "Epoch: 1936,\t loss: 0.0007534,\t\t train precision: 0.9804,\t\t test precision: 0.9761\n",
            "Epoch: 1937,\t loss: 0.0008559,\t\t train precision: 0.9825,\t\t test precision: 0.9728\n",
            "Epoch: 1938,\t loss: 0.0008131,\t\t train precision: 0.9828,\t\t test precision: 0.9736\n",
            "Epoch: 1939,\t loss: 0.0008153,\t\t train precision: 0.9835,\t\t test precision: 0.9712\n",
            "Epoch: 1940,\t loss: 0.0008295,\t\t train precision: 0.9828,\t\t test precision: 0.9753\n",
            "Epoch: 1941,\t loss: 0.0007953,\t\t train precision: 0.9832,\t\t test precision: 0.9769\n",
            "Epoch: 1942,\t loss: 0.0007786,\t\t train precision: 0.9825,\t\t test precision: 0.9761\n",
            "Epoch: 1943,\t loss: 0.0007396,\t\t train precision: 0.9814,\t\t test precision: 0.9761\n",
            "Epoch: 1944,\t loss: 0.0007473,\t\t train precision: 0.9842,\t\t test precision: 0.9761\n",
            "Epoch: 1945,\t loss: 0.0008275,\t\t train precision: 0.9842,\t\t test precision: 0.9761\n",
            "Epoch: 1946,\t loss: 0.0007722,\t\t train precision: 0.979,\t\t test precision: 0.972\n",
            "Epoch: 1947,\t loss: 0.0007768,\t\t train precision: 0.9845,\t\t test precision: 0.9753\n",
            "Epoch: 1948,\t loss: 0.0007699,\t\t train precision: 0.9828,\t\t test precision: 0.9745\n",
            "Epoch: 1949,\t loss: 0.0007009,\t\t train precision: 0.9845,\t\t test precision: 0.9761\n",
            "Epoch: 1950,\t loss: 0.0007651,\t\t train precision: 0.9821,\t\t test precision: 0.9753\n",
            "Epoch: 1951,\t loss: 0.0008644,\t\t train precision: 0.9835,\t\t test precision: 0.9769\n",
            "Epoch: 1952,\t loss: 0.000737,\t\t train precision: 0.9832,\t\t test precision: 0.9745\n",
            "Epoch: 1953,\t loss: 0.0008261,\t\t train precision: 0.9825,\t\t test precision: 0.9728\n",
            "Epoch: 1954,\t loss: 0.0008286,\t\t train precision: 0.9821,\t\t test precision: 0.9712\n",
            "Epoch: 1955,\t loss: 0.0008705,\t\t train precision: 0.9825,\t\t test precision: 0.9753\n",
            "Epoch: 1956,\t loss: 0.0007916,\t\t train precision: 0.9825,\t\t test precision: 0.9736\n",
            "Epoch: 1957,\t loss: 0.0007752,\t\t train precision: 0.9801,\t\t test precision: 0.9728\n",
            "Epoch: 1958,\t loss: 0.000688,\t\t train precision: 0.9828,\t\t test precision: 0.972\n",
            "Epoch: 1959,\t loss: 0.0007615,\t\t train precision: 0.9777,\t\t test precision: 0.972\n",
            "Epoch: 1960,\t loss: 0.0008294,\t\t train precision: 0.9845,\t\t test precision: 0.9745\n",
            "Epoch: 1961,\t loss: 0.0008051,\t\t train precision: 0.9797,\t\t test precision: 0.9728\n",
            "Epoch: 1962,\t loss: 0.0007498,\t\t train precision: 0.9818,\t\t test precision: 0.9679\n",
            "Epoch: 1963,\t loss: 0.0008048,\t\t train precision: 0.9814,\t\t test precision: 0.9703\n",
            "Epoch: 1964,\t loss: 0.0007483,\t\t train precision: 0.9825,\t\t test precision: 0.9769\n",
            "Epoch: 1965,\t loss: 0.0008367,\t\t train precision: 0.9787,\t\t test precision: 0.9745\n",
            "Epoch: 1966,\t loss: 0.0007041,\t\t train precision: 0.9849,\t\t test precision: 0.9728\n",
            "Epoch: 1967,\t loss: 0.0007207,\t\t train precision: 0.9828,\t\t test precision: 0.9761\n",
            "Epoch: 1968,\t loss: 0.0008053,\t\t train precision: 0.9825,\t\t test precision: 0.9728\n",
            "Epoch: 1969,\t loss: 0.0007738,\t\t train precision: 0.9849,\t\t test precision: 0.9745\n",
            "Epoch: 1970,\t loss: 0.0007265,\t\t train precision: 0.9832,\t\t test precision: 0.9736\n",
            "Epoch: 1971,\t loss: 0.0007788,\t\t train precision: 0.9811,\t\t test precision: 0.9753\n",
            "Epoch: 1972,\t loss: 0.0008138,\t\t train precision: 0.9828,\t\t test precision: 0.9745\n",
            "Epoch: 1973,\t loss: 0.0007571,\t\t train precision: 0.979,\t\t test precision: 0.9712\n",
            "Epoch: 1974,\t loss: 0.0008227,\t\t train precision: 0.9808,\t\t test precision: 0.9736\n",
            "Epoch: 1975,\t loss: 0.0007222,\t\t train precision: 0.9818,\t\t test precision: 0.9753\n",
            "Epoch: 1976,\t loss: 0.0008142,\t\t train precision: 0.9828,\t\t test precision: 0.972\n",
            "Epoch: 1977,\t loss: 0.0007417,\t\t train precision: 0.9825,\t\t test precision: 0.9736\n",
            "Epoch: 1978,\t loss: 0.0007387,\t\t train precision: 0.9821,\t\t test precision: 0.9786\n",
            "Epoch: 1979,\t loss: 0.0006971,\t\t train precision: 0.9818,\t\t test precision: 0.9769\n",
            "Epoch: 1980,\t loss: 0.0006991,\t\t train precision: 0.9808,\t\t test precision: 0.9769\n",
            "Epoch: 1981,\t loss: 0.0007777,\t\t train precision: 0.9811,\t\t test precision: 0.9712\n",
            "Epoch: 1982,\t loss: 0.0008912,\t\t train precision: 0.9814,\t\t test precision: 0.9745\n",
            "Epoch: 1983,\t loss: 0.000853,\t\t train precision: 0.9832,\t\t test precision: 0.9778\n",
            "Epoch: 1984,\t loss: 0.0008169,\t\t train precision: 0.9818,\t\t test precision: 0.9745\n",
            "Epoch: 1985,\t loss: 0.0008049,\t\t train precision: 0.9808,\t\t test precision: 0.9769\n",
            "Epoch: 1986,\t loss: 0.0008164,\t\t train precision: 0.9828,\t\t test precision: 0.9753\n",
            "Epoch: 1987,\t loss: 0.0007597,\t\t train precision: 0.9808,\t\t test precision: 0.9761\n",
            "Epoch: 1988,\t loss: 0.0007357,\t\t train precision: 0.9818,\t\t test precision: 0.972\n",
            "Epoch: 1989,\t loss: 0.0007787,\t\t train precision: 0.9801,\t\t test precision: 0.9745\n",
            "Epoch: 1990,\t loss: 0.0007736,\t\t train precision: 0.9801,\t\t test precision: 0.9778\n",
            "Epoch: 1991,\t loss: 0.0007535,\t\t train precision: 0.9828,\t\t test precision: 0.9761\n",
            "Epoch: 1992,\t loss: 0.000751,\t\t train precision: 0.9808,\t\t test precision: 0.9794\n",
            "Epoch: 1993,\t loss: 0.0008864,\t\t train precision: 0.9801,\t\t test precision: 0.972\n",
            "Epoch: 1994,\t loss: 0.0008694,\t\t train precision: 0.9777,\t\t test precision: 0.9728\n",
            "Epoch: 1995,\t loss: 0.0007907,\t\t train precision: 0.9832,\t\t test precision: 0.9761\n",
            "Epoch: 1996,\t loss: 0.0008387,\t\t train precision: 0.9845,\t\t test precision: 0.972\n",
            "Epoch: 1997,\t loss: 0.0008197,\t\t train precision: 0.9849,\t\t test precision: 0.9728\n",
            "Epoch: 1998,\t loss: 0.0007229,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n",
            "Epoch: 1999,\t loss: 0.0006731,\t\t train precision: 0.9821,\t\t test precision: 0.9761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLoYQYPMT6HT",
        "outputId": "dc6a3633-556b-4fbe-879c-3fdf684650d5"
      },
      "source": [
        "for i in range(280000, 320000, 2000):\n",
        "  threshold = i\n",
        "  prec = evaluate(model, [test_numerical_data, test_categorical_ht_data, test_categorical_substation_data], test_targets, scale)\n",
        "  print(i, ': ', prec)"
      ],
      "id": "HLoYQYPMT6HT",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "280000 :  0.9530477759472817\n",
            "282000 :  0.9555189456342669\n",
            "284000 :  0.957166392092257\n",
            "286000 :  0.9596375617792422\n",
            "288000 :  0.9621087314662273\n",
            "290000 :  0.9654036243822076\n",
            "292000 :  0.9686985172981878\n",
            "294000 :  0.9703459637561779\n",
            "296000 :  0.9719934102141681\n",
            "298000 :  0.9761120263591433\n",
            "300000 :  0.9761120263591433\n",
            "302000 :  0.9769357495881383\n",
            "304000 :  0.9752883031301482\n",
            "306000 :  0.9744645799011532\n",
            "308000 :  0.9736408566721582\n",
            "310000 :  0.9719934102141681\n",
            "312000 :  0.9736408566721582\n",
            "314000 :  0.9695222405271828\n",
            "316000 :  0.9670510708401977\n",
            "318000 :  0.9670510708401977\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MxR8HAyBG_J",
        "outputId": "f64912cb-63ba-483e-fff2-6353cf5f2594"
      },
      "source": [
        "for i in range(300000, 302000, 200):\n",
        "  threshold = i\n",
        "  prec = evaluate(model, [test_numerical_data, test_categorical_ht_data, test_categorical_substation_data], test_targets, scale)\n",
        "  print(i, ': ', prec)"
      ],
      "id": "4MxR8HAyBG_J",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300000 :  0.9761120263591433\n",
            "300200 :  0.9761120263591433\n",
            "300400 :  0.9761120263591433\n",
            "300600 :  0.9761120263591433\n",
            "300800 :  0.9761120263591433\n",
            "301000 :  0.9769357495881383\n",
            "301200 :  0.9769357495881383\n",
            "301400 :  0.9769357495881383\n",
            "301600 :  0.9769357495881383\n",
            "301800 :  0.9769357495881383\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kK6pzaE6PCsT"
      },
      "source": [
        "found_threshold = 301000"
      ],
      "id": "kK6pzaE6PCsT",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBQedXBZKLzE"
      },
      "source": [
        "## Klasyfikacja zbioru testowego"
      ],
      "id": "GBQedXBZKLzE"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R-sI8pACimS"
      },
      "source": [
        "test_raw_data = pd.read_csv('test_data.csv')\n",
        "\n",
        "test_ht = test_raw_data[\"HallwayType\"].astype(\"category\")\n",
        "test_ht = pd.get_dummies(test_ht)\n",
        "\n",
        "test_substation = test_raw_data[\"SubwayStation\"].astype(\"category\")\n",
        "test_substation = pd.get_dummies(test_substation)\n",
        "\n",
        "test_raw_data['HeatingType'] = test_raw_data['HeatingType'].replace(['central_heating', 'individual_heating'], [0, 1])\n",
        "test_raw_data['AptManageType'] = test_raw_data['AptManageType'].replace(['management_in_trust', 'self_management'], [0, 1])\n",
        "test_raw_data['TimeToBusStop'] = test_raw_data['TimeToBusStop'].replace(['0~5min', '10min~15min', '5min~10min'], [0, 2, 1])\n",
        "test_raw_data['TimeToSubway'] = test_raw_data['TimeToSubway'].replace(['0-5min', '10min~15min', '15min~20min', '5min~10min',\n",
        "       'no_bus_stop_nearby'], [1, 3, 4, 2, 0])\n",
        "test_raw_data = test_raw_data.drop(['HallwayType', 'SubwayStation'], axis=1)\n",
        "\n",
        "for col in test_raw_data:\n",
        "  test_raw_data[col] = (test_raw_data[col] - means[col]) / (maxs[col] - mins[col])\n",
        "\n",
        "test_raw_data = torch.from_numpy(np.array(test_raw_data)).float()\n",
        "test_ht = torch.from_numpy(np.array(test_ht)).float()\n",
        "test_substation = torch.from_numpy(np.array(test_substation)).float()"
      ],
      "id": "6R-sI8pACimS",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dny4zuCM2YL"
      },
      "source": [
        "final_predictions = model(test_raw_data.to(device), test_ht.to(device), test_substation.to(device))"
      ],
      "id": "0dny4zuCM2YL",
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yZQkL5UNMsG"
      },
      "source": [
        "final_predictions = final_predictions*(max_targ - min_targ) + mean_targ\n",
        "final_classes = final_predictions > found_threshold"
      ],
      "id": "1yZQkL5UNMsG",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EMvc3oQaRNKI",
        "outputId": "bbbbe5c3-56d5-48fd-8a94-aa0e7c3c085a"
      },
      "source": [
        ""
      ],
      "id": "EMvc3oQaRNKI",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([False], device='cuda:0'),\n",
              " tensor([True], device='cuda:0'),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfbLh9OwO-gx",
        "outputId": "f4b36600-4a2d-4db6-f7cc-82971953deb3"
      },
      "source": [
        "to_file = zip(list(final_predictions), list(final_classes))\n",
        "list(to_file)"
      ],
      "id": "hfbLh9OwO-gx",
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor([126196.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([197784.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([146150.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([306252.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([225870.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([255424.4531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([152897.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([451499.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([193951.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([210648.2031], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([328672.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([178179.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([139107.5781], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([136866.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([150060.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([176472.4219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([356903.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([63829.7031], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([252484.6094], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([216887.3594], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([278838.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([132368.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([277928.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([144153.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([184846.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([238266.6562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([89717.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([180384.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([65504.2188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([86967.2344], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([147292.7031], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([170140.6406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([261910.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([162258.2656], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([234075.6562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([322320.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([239715.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([198172.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([64875.8438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([262589.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([147894.9219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([285449.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([364512.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([72651.5781], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([369361.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([148266.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([68957.7969], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([120770.1953], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([169436.5781], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([133397.0938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([402247.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([214261.6250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([207849.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([112391.3984], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([246137.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([205377.6406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([367077.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([440870.0938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([331257.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([264697.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([289049.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([65593.7188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([196745.8438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([340429.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([177011.2656], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([293172.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([395394.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([68750.8281], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([205116.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([198062.5781], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([335721.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([267451.1562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([183646.1406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([348448.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([197205.6406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([333555.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([342550.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([36977.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([260490.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([149383.7344], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([170855.1562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([304266.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([166068.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([218493.8438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([137352.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([127451.9219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([38296.6094], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([385232.5938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([177038.5156], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([222740.5469], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([278353.0938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([363622.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([200518.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([156169.6406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([207142.0469], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([230452.6094], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([213121.5156], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([276348.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([338559.7188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([123606.5469], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([341450.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([283106.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([146150.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([304953.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([265639.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([305405.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([181437.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([260430.5938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([80653.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([408242.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([245629.7969], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([167789.8438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([348754.5938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([400072.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([147952.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([315298.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([313794.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([182369.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([285891.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([239130.3281], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([276865.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([81314.3594], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([118737.0469], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([184861.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([298765.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([208416.6094], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([253699.8438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([239318.2188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([181524.7969], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([413241.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([69707.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([262974.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([233152.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([194917.0469], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([189138.0469], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([85949.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([280789.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([74358.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([276886.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([262333.6562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([76153.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([243652.9844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([280332.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([82494.9531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([366090.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([322715.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([170475.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([255290.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([234103.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([384285.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([260830.6406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([406640.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([263426.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([129059.6953], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([399693.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([152189.7969], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([149039.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([263193.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([314817.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([123745.6172], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([76765.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([212294.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([82474.5938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([280144.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([74112.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([213262.8438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([360899.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([225241.0469], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([367424.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([82559.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([295472.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([398592.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([183874.6406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([194700.8594], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([140572.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([326999.5938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([35049.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([505616.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([360197.2188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([147359.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([330679.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([215540.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([81214.5938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([220853.7031], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([254440.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([216046.7188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([198718.8906], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([53994.7188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([342730.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([143117.0469], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([303054.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([175331.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([263856.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([283033.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([81427.0938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([251264.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([178586.8906], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([160125.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([83323.5938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([241222.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([180341.3281], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([320071.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([386620.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([188700.6719], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([190011.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([145091.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([142765.6562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([356569.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([243396.8281], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([332305.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([66679.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([263027.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([85280.1406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([147122.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([272308.6250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([261208.5781], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([204875.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([84247.9531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([301067.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([56788.4531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([179030.8281], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([165113.5938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([355981.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([259018.6406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([66288.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([64536.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([220753.0156], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([321152.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([228415.0156], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([150943.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([380099.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([144515.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([460581.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([181705.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([76662.3906], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([142875.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([419308.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([55274.3594], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([354008.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([388921.0938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([227216.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([361377.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([253857.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([75832.3594], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([469158.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([81605.3906], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([57303.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([186002.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([330729.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([208747.3281], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([253016.3281], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([264153.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([229272.8281], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([478819.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([264078.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([378939.2188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([37701.8594], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([183665.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([194225.3906], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([146576.8906], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([251964.9844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([333794.6250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([219248.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([282222.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([65681.3281], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([83586.4219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([106799.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([67324.2188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([159057.0938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([329288.2188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([384475.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([273501.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([373274.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([209293.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([127747.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([159907.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([288936.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([254881.2656], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([522561.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([145660.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([189362.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([299622.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([329894.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([60223.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([63847.5156], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([113896.0547], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([195928.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([139272.7188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([430747.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([176574.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([214115.2188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([210156.1094], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([200986.9844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([144336.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([331184.8438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([357211.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([357096.1562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([333920.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([82494.9531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([123247.2188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([190949.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([358354.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([55157.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([209852.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([200192.0156], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([149956.8281], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([203614.4219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([264923.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([172113.1562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([39478.2188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([39889.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([472451.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([126667.6016], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([140741.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([245767.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([404331.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([142765.6562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([82494.9531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([64197.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([200332.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([351395.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([379667.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([91633.9922], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([200803.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([210386.5938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([142765.6562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([109084.6641], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([159065.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([84247.9531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([156410.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([180709.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([167777.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([283117.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([237080.5781], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([204790.5156], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([251207.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([146576.8906], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([272133.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([396651.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([152410.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([277335.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([212448.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([165617.1562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([76526.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([123531.1641], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([380945.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([80277.2969], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([186007.8906], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([167049.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([226658.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([337118.7188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([359617.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([353622.2188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([316696.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([364115.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([204455.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([275174.2188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([324560.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([55601.7344], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([348972.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([161833.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([189483.1719], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([244977.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([397130.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([197900.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([104244.3047], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([188255.9844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([292687.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([82265.0938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([76289.2969], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([383403.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([175718.1719], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([230098.3906], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([188931.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([437072.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([166691.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([237873.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([58750.2188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([153241.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([342832.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([293425.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([249547.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([128341.0078], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([235842.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([198222.8281], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([145660.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([282057.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([139324.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([91428.4766], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([159690.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([313934.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([363238.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([101025.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([282201.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([287252.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([329915.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([287972.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([327973.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([358607.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([59896.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([176683.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([323324.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([295692.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([180289.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([118058.1562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([168204.6406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([352792.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([511557.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([307985.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([331055.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([257077.4531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([441413.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([60560.8281], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([148478.0156], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([401589.5938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([222076.5156], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([351831.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([230289.6250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([428043.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([177649.7656], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([123478.4609], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([275603.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([329555.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([354475.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([194078.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([232831.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([178619.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([353900.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([77633.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([97460.9609], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([237289.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([222577.9531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([150075.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([292391.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([168172.2656], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([351785.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([187843.4219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([62033.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([57370.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([120717.8359], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([154654.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([72545.1094], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([271666.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([149150.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([215441.4844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([88372.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([269776.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([62728.8281], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([60093.4531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([172499.8594], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([337542.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([238372.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([378796.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([181083.9219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([77378.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([168397.7969], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([264272.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([259381.9844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([143975.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([539417.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([287528.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([202389.6562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([76423.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([84795.1719], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([334020.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([375320.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([82494.9531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([325020.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([289084.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([144153.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([36290.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([136427.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([169918.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([243899.2031], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([54167.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([299063.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([390500.1562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([57017.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([259181.2031], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([175812.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([191798.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([374638.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([127792.6328], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([137796.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([373952.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([153627.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([187232.8906], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([77926.7031], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([409214.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([351704.6562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([113488.0469], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([220721.4219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([139723.7188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([306041.6562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([314534.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([56774.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([253379.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([90425.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([81214.5938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([301040.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([276429.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([107145.4609], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([144836.0938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([76765.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([239943.9844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([265639.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([253999.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([235905.2031], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([37981.7656], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([360028.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([215861.0156], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([447936.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([290955.1562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([143172.4844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([163246.5938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([223042.2969], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([239911.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([366325.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([106598.9844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([84436.9531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([193604.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([35398.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([164646.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([121130.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([221451.8594], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([182020.2969], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([148762.1719], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([347319.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([218568.9531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([226854.6250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([357057.7188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([371817.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([203879.7031], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([297717.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([224567.4531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([161210.1094], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([85280.1406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([516066.1562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([96441.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([174512.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([64538.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([300388.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([107125.3203], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([208117.4219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([129059.6953], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([222822.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([277929.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([281880.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([39538.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([262216.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([352926.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([266688.8438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([185678.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([175978.6719], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([358976.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([208466.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([226867.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([76491.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([267005.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([82494.9531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([283750.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([208782.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([354043.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([364590.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([265637.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([463840.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([106635.2578], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([392080.6562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([204659.6719], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([161535.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([109078.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([276874.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([188114.2031], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([376531.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([301985.1562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([385329.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([78104.9219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([265664.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([181001.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([355937.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([256438.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([409616.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([318036.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([398611.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([239855.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([201077.9219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([192907.6406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([124986.1094], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([234979.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([195309.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([173541.0938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([82197.8438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([83538.5156], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([349694.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([213723.6250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([308500.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([235217.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([340530.7188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([179797.2969], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([87072.0781], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([146061.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([132297.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([265604.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([216632.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([387816.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([146150.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([496282.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([238583.9844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([169711.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([80353.1562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([195701.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([77378.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([209736.1719], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([147809.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([349184.1562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([377141.1562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([264188.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([55032.8594], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([227494.0469], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([170902.6406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([290946.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([207872.0469], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([484024.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([64061.4219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([125031.6094], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([78171.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([107477.4922], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([84247.9531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([168666.2656], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([145091.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([157755.8438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([259660.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([229727.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([253322.2188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([239701.0781], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([168201.0156], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([54627.6250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([102684.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([53079.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([356668.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([256116.5781], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([184870.2188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([324357.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([285794.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([159722.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([172658.4219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([80082.6094], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([343649.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([70083.6562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([203836.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([147604.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([359117.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([186392.2969], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([35662.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([152695.5469], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([255187.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([296177.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([264639.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([345197.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([67548.4219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([432707.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([210863.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([234629.9844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([56618.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([342508.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([263453.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([69702.1562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([130911.3047], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([62798.0156], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([251939.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([280113.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([224441.8281], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([91975.6172], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([432450.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([52461.5156], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([276270.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([270639.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([84247.9531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([176595.6562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([82635.2344], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([120258.4922], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([104532.6016], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([347689.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([205987.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([206403.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([433079.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([179257.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([171234.4844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([389110.6250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([123980.8594], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([164299.8438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([117529.1719], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([107282.2734], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([307948.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([332748.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([114020.5703], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([321407.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([395072.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([66315.1094], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([95482.3359], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([502273.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([216536.2656], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([373269.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([384547.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([53836.8438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([163593.1719], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([254068.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([310000.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([89689.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([204560.3906], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([144987.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([219819.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([307198.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([273000.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([192027.7344], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([247018.2656], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([271581.0938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([120086.7969], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([185691.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([168609.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([148496.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([144153.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([59897.1406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([141735.2188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([140584.5781], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([80082.6094], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([285796.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([192482.5938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([355707.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([260176.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([58715.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([359686.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([203475.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([343555.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([280789.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([75913.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([195701.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([218530.2344], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([200638.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([165818.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([183803.2031], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([95386.5781], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([53952.1719], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([165826.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([349852.6562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([300735.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([439197.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([309545.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([185290.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([280689.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([386214.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([479512.8438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([454329.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([141334.8281], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([156390.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([210703.0469], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([141468.7031], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([38926.8438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([376989.6250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([308194.6562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([138831.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([351092.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([181946.6719], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([340594.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([175495.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([149454.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([61411.2031], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([397266.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([429189.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([77907.1406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([77378.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([364960.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([261463.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([160623.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([200367.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([299497.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([110828.0156], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([121993.2109], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([78171.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([284024.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([194277.5469], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([79456.8438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([296127.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([180446.9219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([48282.1094], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([297144.7188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([144153.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([202670.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([191772.1562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([38058.7656], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([287772.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([333691.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([180531.4531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([174026.9844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([361063.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([39632.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([181338.9844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([284864.1562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([259826.2656], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([78882.2656], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([250509.8594], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([148266.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([383596.7188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([103925.8359], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([60537.7656], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([199754.2031], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([262321.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([240802.5469], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([334721.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([360654.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([96385.7188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([236614.8906], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([348655.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([414133.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([393093.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([346505.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([304058.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([186704.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([181818.7344], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([333618.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([363969.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([124869.4609], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([283846.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([127585.8359], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([204633.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([237421.6406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([76289.2969], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([210758.6094], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([421895.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([235811.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([248145.9844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([299953.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([252552.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([175305.7969], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([427818.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([81693.6094], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([102197.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([395677.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([177854.3906], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([382152.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([168424.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([259018.6406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([248121.0469], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([482782.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([214973.5938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([192676.4844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([52446.2031], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([190355.4531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([366742.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([46473.1719], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([201621.1094], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([225457.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([231096.5156], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([178021.0938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([152946.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([382054.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([174136.8594], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([195891.7188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([227630.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([325036.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([395240.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([193080.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([131449.0938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([177416.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([222232.6250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([141775.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([61182.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([384414.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([173461.1562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([206436.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([237857.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([175841.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([234981.7188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([277646.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([277113.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([343449.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([225753.3906], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([180424.7656], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([265757.5938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([283325.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([227523.5938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([264321.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([77410.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([248769.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([92998.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([129880.4766], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([78576.8594], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([137946.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([212853.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([140741.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([183874.6406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([262324.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([276395.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([125629.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([142727.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([348739.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([63268.2969], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([260725.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([325999.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([364529.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([144515.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([84292.4062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([282692.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([286287.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([217273.4375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([235488.9219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([84372.8594], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([244948.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([251284.6094], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([101488.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([292343.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([78848.4531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([187163.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([148836.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([189970.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([252425.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([249011.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([187183.8438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([147604.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([327459.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([137352.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([259198.8594], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([319631.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([182360.8594], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([206160.8281], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([142562.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([146405.1406], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([337669.8125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([255551.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([171656.1875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([124801.4141], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([204533.9844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([90803.0703], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([98817.7578], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([105811.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([232554.8438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([192355.7344], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([320984.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([265899.6562], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([266410.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([81214.5938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([66633.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([202693.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([256174.7031], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([168545.9219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([70196.9219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([225485.2656], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([298414.9375], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([328708.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([229724.2188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([150074.4844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([216311.7344], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([55806.9844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([185338.], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([153786.2812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([223783.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([130543.9609], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([144279.9062], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([165818.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([217646.4219], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([277783.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([122622.9297], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([265298.5625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([60053.0938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([245429.5312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([268338.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([320454.6250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([200562.6875], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([147604.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([235145.5000], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([338590.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([224410.9688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([167707.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([34281.2344], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([203820.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([185407.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([424264.0938], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([204086.7500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([234701.7969], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([327100.2500], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([209621.1250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([261638.4844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([216046.7188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([451434.0312], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([124642.4141], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([353406.6250], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([339019.2188], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([444986.7812], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([66212.3125], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([124554.4531], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([140959.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([168914.0625], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([282222.4688], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([356812.3438], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([202397.9844], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([181866.8281], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([406814.8750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " (tensor([124720.4297], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([203915.5469], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([False], device='cuda:0')),\n",
              " (tensor([436237.3750], device='cuda:0', grad_fn=<UnbindBackward>),\n",
              "  tensor([True], device='cuda:0')),\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6xdPHj0QKtL"
      },
      "source": [
        ""
      ],
      "id": "Y6xdPHj0QKtL",
      "execution_count": null,
      "outputs": []
    }
  ]
}